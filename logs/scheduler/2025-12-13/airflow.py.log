[2025-12-13T01:11:44.075+0000] {processor.py:186} INFO - Started process (PID=1367) to work on /opt/airflow/dags/airflow.py
[2025-12-13T01:11:44.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T01:11:44.083+0000] {logging_mixin.py:190} INFO - [2025-12-13T01:11:44.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T01:11:47.415+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T01:13:19.492+0000] {logging_mixin.py:190} INFO - [2025-12-13T01:13:19.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T01:13:20.106+0000] {logging_mixin.py:190} INFO - [2025-12-13T01:13:20.106+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-12 00:00:00+00:00, run_after=2025-12-13 00:00:00+00:00
[2025-12-13T09:47:58.021+0000] {processor.py:186} INFO - Started process (PID=1380) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:47:58.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:47:58.028+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:47:58.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:47:59.837+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:48:00.011+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:48:00.010+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:48:00.044+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:48:00.044+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-12 00:00:00+00:00, run_after=2025-12-13 00:00:00+00:00
[2025-12-13T09:48:00.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.073 seconds
[2025-12-13T09:49:34.707+0000] {processor.py:186} INFO - Started process (PID=1397) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:49:34.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:49:34.710+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:34.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:48:04.592+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:48:04.614+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:48:04.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:48:04.655+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:48:04.655+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:48:04.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.112 seconds
[2025-12-13T09:49:44.949+0000] {processor.py:186} INFO - Started process (PID=1424) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:49:44.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:49:44.953+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:44.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:48:15.789+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:48:15.806+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:48:15.805+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:48:15.838+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:48:15.837+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:48:15.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.628 seconds
[2025-12-13T09:49:49.662+0000] {processor.py:186} INFO - Started process (PID=1437) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:49:49.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:49:49.665+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:49.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:51.381+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:51.409+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:51.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:49:51.436+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:51.435+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:49:51.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.803 seconds
[2025-12-13T09:50:21.745+0000] {processor.py:186} INFO - Started process (PID=1456) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:50:21.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:50:21.749+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:21.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:50:23.087+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:50:23.117+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:23.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:50:23.140+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:23.140+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:50:23.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.428 seconds
[2025-12-13T09:50:59.636+0000] {processor.py:186} INFO - Started process (PID=1475) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:50:59.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:50:59.639+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:59.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:28.887+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:28.910+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:28.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:49:28.929+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:28.929+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:49:28.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.143 seconds
[2025-12-13T09:51:19.998+0000] {processor.py:186} INFO - Started process (PID=1494) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:51:20.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:51:20.002+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:51:20.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:49.591+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:49.613+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:49.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:49:49.633+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:49.633+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:49:49.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.332 seconds
[2025-12-13T09:49:52.743+0000] {processor.py:186} INFO - Started process (PID=1507) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:49:52.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:49:52.747+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:52.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:54.685+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:54.769+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:54.769+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:49:54.836+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:54.836+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:49:54.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.159 seconds
[2025-12-13T09:51:44.568+0000] {processor.py:186} INFO - Started process (PID=1526) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:51:44.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:51:44.571+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:51:44.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:50:14.122+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:50:14.154+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:14.154+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:50:14.180+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:14.180+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:50:14.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.445 seconds
[2025-12-13T09:51:50.102+0000] {processor.py:186} INFO - Started process (PID=1539) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:51:50.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:51:50.106+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:51:50.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:50:19.661+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:50:19.711+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:19.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:50:19.775+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:19.775+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:50:19.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.766 seconds
[2025-12-13T09:50:50.614+0000] {processor.py:186} INFO - Started process (PID=1558) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:50:50.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:50:50.619+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:50.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:04:19.456+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:04:19.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:04:19.460+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:04:19.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:07:23.641+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:05:51.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:05:51.498+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:05:51.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:05:52.849+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:05:52.980+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:05:52.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:05:53.000+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:05:53.000+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:05:53.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.531 seconds
[2025-12-13T10:07:50.919+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:07:50.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:07:50.921+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:07:50.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:06:20.105+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:06:20.118+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:06:20.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:06:20.146+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:06:20.146+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:06:20.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.407 seconds
[2025-12-13T10:06:38.827+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:06:38.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:06:38.829+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:06:38.829+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:06:40.162+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:06:40.189+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:06:40.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:06:40.208+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:06:40.208+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:06:40.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.402 seconds
[2025-12-13T10:08:23.468+0000] {processor.py:186} INFO - Started process (PID=141) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:08:23.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:08:23.471+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:23.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:06:52.531+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:06:52.556+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:06:52.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:06:52.576+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:06:52.576+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:06:52.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.283 seconds
[2025-12-13T10:07:13.852+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:07:13.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:07:13.855+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:07:13.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:07:14.994+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:07:15.018+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:07:15.018+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:07:15.038+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:07:15.038+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:07:15.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.220 seconds
[2025-12-13T10:07:45.188+0000] {processor.py:186} INFO - Started process (PID=179) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:07:45.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:07:45.191+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:07:45.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:07:46.315+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:07:46.338+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:07:46.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:07:46.357+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:07:46.357+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:07:46.380+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.200 seconds
[2025-12-13T10:08:16.686+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:08:16.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:08:16.688+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:16.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:17.833+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:17.855+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:17.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:08:17.875+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:17.874+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:08:17.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.210 seconds
[2025-12-13T10:10:11.067+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:11.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:11.069+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:11.069+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:40.172+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:40.197+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:40.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:08:40.219+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:40.219+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:08:40.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.326 seconds
[2025-12-13T10:10:16.100+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:16.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:16.103+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:16.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:45.055+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:45.079+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:45.079+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:08:45.098+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:45.098+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:08:45.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.173 seconds
[2025-12-13T10:08:48.995+0000] {processor.py:186} INFO - Started process (PID=243) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:08:48.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:08:48.997+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:48.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:50.305+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:50.327+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:50.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:08:50.346+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:50.345+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:08:50.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.372 seconds
[2025-12-13T10:09:15.992+0000] {processor.py:186} INFO - Started process (PID=262) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:15.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:15.995+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:15.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:17.298+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:17.400+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:17.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:17.421+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:17.421+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:17.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.475 seconds
[2025-12-13T10:09:17.519+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:17.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:17.522+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:17.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:19.027+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:51.192+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:51.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:51.217+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:51.217+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:51.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.581 seconds
[2025-12-13T10:09:19.171+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:19.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:19.173+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:19.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:20.378+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:20.387+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:20.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:20.406+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:20.406+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:20.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.263 seconds
[2025-12-13T10:09:20.479+0000] {processor.py:186} INFO - Started process (PID=301) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:20.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:20.482+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:20.482+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:21.693+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:21.712+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:21.712+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:21.745+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:21.745+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:21.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.303 seconds
[2025-12-13T10:09:21.877+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:21.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:21.885+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:21.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:24.437+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:24.454+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:24.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:24.490+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:24.490+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:24.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.680 seconds
[2025-12-13T10:09:24.652+0000] {processor.py:186} INFO - Started process (PID=333) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:24.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:24.660+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:24.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:25.922+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:25.933+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:25.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:25.956+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:25.956+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:25.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.331 seconds
[2025-12-13T10:09:26.027+0000] {processor.py:186} INFO - Started process (PID=346) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:26.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:26.030+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:26.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:27.239+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:27.251+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:27.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:27.279+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:27.279+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:27.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.281 seconds
[2025-12-13T10:09:27.362+0000] {processor.py:186} INFO - Started process (PID=359) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:27.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:27.364+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:27.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:28.700+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:28.711+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:28.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:28.732+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:28.732+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:28.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.397 seconds
[2025-12-13T10:09:28.802+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:28.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:28.804+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:28.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:29.922+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:29.933+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:29.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:29.958+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:29.957+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:29.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.179 seconds
[2025-12-13T10:09:30.039+0000] {processor.py:186} INFO - Started process (PID=385) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:30.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:30.043+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:30.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:31.132+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:31.141+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:31.141+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:31.161+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:31.161+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:31.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.144 seconds
[2025-12-13T10:09:31.225+0000] {processor.py:186} INFO - Started process (PID=398) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:31.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:31.228+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:31.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:32.328+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:32.339+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:32.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:32.359+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:32.359+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:32.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.157 seconds
[2025-12-13T10:09:32.425+0000] {processor.py:186} INFO - Started process (PID=411) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:32.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:32.428+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:32.427+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:33.430+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:33.440+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:33.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:33.460+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:33.459+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:33.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.056 seconds
[2025-12-13T10:09:33.530+0000] {processor.py:186} INFO - Started process (PID=424) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:33.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:33.532+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:33.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:34.571+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:34.580+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:34.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:34.599+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:34.599+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:34.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.095 seconds
[2025-12-13T10:09:34.665+0000] {processor.py:186} INFO - Started process (PID=437) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:34.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:34.668+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:34.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:35.774+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:35.784+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:35.784+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:35.803+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:35.803+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:35.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.161 seconds
[2025-12-13T10:09:35.869+0000] {processor.py:186} INFO - Started process (PID=450) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:35.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:35.871+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:35.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:36.898+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:36.907+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:36.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:36.926+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:36.926+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:36.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.080 seconds
[2025-12-13T10:09:36.996+0000] {processor.py:186} INFO - Started process (PID=463) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:36.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:36.998+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:36.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:38.059+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:38.069+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:38.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:38.094+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:38.094+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:38.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.125 seconds
[2025-12-13T10:09:38.171+0000] {processor.py:186} INFO - Started process (PID=476) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:38.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:38.173+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:38.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:39.742+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:39.757+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:39.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:39.801+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:39.800+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:39.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.671 seconds
[2025-12-13T10:09:39.929+0000] {processor.py:186} INFO - Started process (PID=489) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:39.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:39.933+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:39.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:42.016+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:42.028+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:42.028+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:42.057+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:42.056+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:42.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.159 seconds
[2025-12-13T10:09:42.137+0000] {processor.py:186} INFO - Started process (PID=502) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:42.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:42.140+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:42.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:43.423+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:43.435+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:43.435+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:43.459+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:43.459+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:43.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.349 seconds
[2025-12-13T10:09:43.535+0000] {processor.py:186} INFO - Started process (PID=515) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:43.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:43.538+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:43.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:44.376+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:44.385+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:44.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:44.406+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:44.406+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:44.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.179 seconds
[2025-12-13T10:09:44.483+0000] {processor.py:186} INFO - Started process (PID=528) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:44.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:44.487+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:44.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:45.615+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:45.625+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:45.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:45.644+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:45.644+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:45.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.200 seconds
[2025-12-13T10:09:45.731+0000] {processor.py:186} INFO - Started process (PID=541) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:45.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:45.733+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:45.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:46.932+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:46.943+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:46.943+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:46.966+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:46.966+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:46.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.258 seconds
[2025-12-13T10:09:47.040+0000] {processor.py:186} INFO - Started process (PID=554) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:47.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:47.042+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:47.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:48.216+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:48.245+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:48.244+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:48.270+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:48.269+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:48.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.266 seconds
[2025-12-13T10:09:48.364+0000] {processor.py:186} INFO - Started process (PID=567) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:48.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:48.367+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:48.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:49.296+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:49.322+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:49.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:49.348+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:49.347+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:49.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.432 seconds
[2025-12-13T10:09:49.438+0000] {processor.py:186} INFO - Started process (PID=580) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:49.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:49.441+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:49.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:50.606+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:50.633+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:50.633+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:50.655+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:50.655+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:50.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.310 seconds
[2025-12-13T10:09:50.730+0000] {processor.py:186} INFO - Started process (PID=593) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:50.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:50.732+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:50.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:52.050+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:52.072+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:52.072+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:52.091+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:52.091+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:52.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.392 seconds
[2025-12-13T10:09:52.167+0000] {processor.py:186} INFO - Started process (PID=612) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:52.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:52.169+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:52.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:53.297+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:53.319+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:53.319+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:53.340+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:53.340+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:53.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.200 seconds
[2025-12-13T10:09:53.413+0000] {processor.py:186} INFO - Started process (PID=625) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:53.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:53.416+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:53.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:54.222+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:54.242+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:54.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:54.264+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:54.263+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:54.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.221 seconds
[2025-12-13T10:09:54.333+0000] {processor.py:186} INFO - Started process (PID=638) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:54.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:54.336+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:54.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:55.469+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:55.493+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:55.492+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:55.517+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:55.517+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:55.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.206 seconds
[2025-12-13T10:09:55.584+0000] {processor.py:186} INFO - Started process (PID=651) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:55.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:55.587+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:55.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:56.745+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:56.766+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:56.766+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:56.786+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:56.786+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:56.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.225 seconds
[2025-12-13T10:09:56.857+0000] {processor.py:186} INFO - Started process (PID=664) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:56.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:56.859+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:56.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:57.973+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:57.999+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:57.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:58.021+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:58.020+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:58.047+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.196 seconds
[2025-12-13T10:09:58.099+0000] {processor.py:186} INFO - Started process (PID=677) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:58.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:58.101+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:58.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:59.185+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:59.207+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:59.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:59.226+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:59.226+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:59.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.154 seconds
[2025-12-13T10:09:59.290+0000] {processor.py:186} INFO - Started process (PID=690) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:59.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:59.293+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:59.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:00.334+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:00.355+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:00.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:00.373+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:00.373+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:00.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.111 seconds
[2025-12-13T10:10:00.445+0000] {processor.py:186} INFO - Started process (PID=703) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:00.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:00.448+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:00.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:01.513+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:01.551+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:01.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:01.576+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:01.576+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:01.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.158 seconds
[2025-12-13T10:10:01.653+0000] {processor.py:186} INFO - Started process (PID=716) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:01.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:01.656+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:01.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:02.735+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:02.759+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:02.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:02.779+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:02.779+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:02.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.161 seconds
[2025-12-13T10:10:02.859+0000] {processor.py:186} INFO - Started process (PID=729) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:02.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:02.862+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:02.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:03.932+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:03.956+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:03.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:03.977+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:03.977+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:04.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.148 seconds
[2025-12-13T10:10:04.051+0000] {processor.py:186} INFO - Started process (PID=742) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:04.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:04.053+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:04.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:05.245+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:05.273+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:05.273+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:05.299+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:05.298+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:05.317+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.268 seconds
[2025-12-13T10:10:05.372+0000] {processor.py:186} INFO - Started process (PID=755) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:05.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:05.375+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:05.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:06.445+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:06.466+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:06.466+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:06.483+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:06.483+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:06.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.135 seconds
[2025-12-13T10:10:06.548+0000] {processor.py:186} INFO - Started process (PID=768) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:06.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:06.550+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:06.550+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:07.554+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:07.574+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:07.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:07.593+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:07.593+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:07.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.074 seconds
[2025-12-13T10:10:07.664+0000] {processor.py:186} INFO - Started process (PID=781) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:07.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:07.666+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:07.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:08.693+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:08.714+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:08.714+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:08.733+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:08.733+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:08.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.091 seconds
[2025-12-13T10:10:08.797+0000] {processor.py:186} INFO - Started process (PID=794) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:08.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:08.799+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:08.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:09.835+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:09.856+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:09.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:09.876+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:09.875+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:09.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.103 seconds
[2025-12-13T10:10:09.950+0000] {processor.py:186} INFO - Started process (PID=807) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:09.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:09.952+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:09.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:10.977+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:10.996+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:10.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:11.016+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:11.016+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:11.036+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.093 seconds
[2025-12-13T10:10:11.085+0000] {processor.py:186} INFO - Started process (PID=820) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:11.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:11.087+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:11.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:12.113+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:12.136+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:12.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:12.157+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:12.157+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:12.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.096 seconds
[2025-12-13T10:10:12.225+0000] {processor.py:186} INFO - Started process (PID=833) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:12.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:12.227+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:12.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:13.315+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:13.338+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:13.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:13.357+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:13.357+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:13.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.155 seconds
[2025-12-13T10:10:13.426+0000] {processor.py:186} INFO - Started process (PID=846) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:13.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:13.428+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:13.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:14.579+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:14.606+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:14.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:14.626+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:14.626+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:14.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.223 seconds
[2025-12-13T10:10:14.697+0000] {processor.py:186} INFO - Started process (PID=859) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:14.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:14.699+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:14.699+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:15.816+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:15.843+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:15.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:15.866+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:15.866+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:15.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.193 seconds
[2025-12-13T10:10:15.936+0000] {processor.py:186} INFO - Started process (PID=872) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:15.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:15.938+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:15.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:16.979+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:17.000+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:16.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:17.018+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:17.018+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:17.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.110 seconds
[2025-12-13T10:10:17.089+0000] {processor.py:186} INFO - Started process (PID=885) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:17.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:17.091+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:17.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:18.190+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:18.210+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:18.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:18.228+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:18.228+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:18.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.170 seconds
[2025-12-13T10:10:18.340+0000] {processor.py:186} INFO - Started process (PID=898) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:18.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:18.344+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:18.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:19.500+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:19.527+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:19.527+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:19.553+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:19.553+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:19.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.252 seconds
[2025-12-13T10:13:11.405+0000] {processor.py:186} INFO - Started process (PID=929) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:13:11.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:13:11.408+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:11.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:11:40.349+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:11:40.441+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:11:40.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:11:40.458+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:11:40.458+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:11:40.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.232 seconds
[2025-12-13T10:11:44.293+0000] {processor.py:186} INFO - Started process (PID=942) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:11:44.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:11:44.295+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:11:44.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:11:45.390+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:11:45.400+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:11:45.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:11:45.421+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:11:45.420+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:11:45.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.156 seconds
[2025-12-13T10:12:15.633+0000] {processor.py:186} INFO - Started process (PID=961) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:12:15.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:12:15.636+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:12:15.636+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:12:16.705+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:12:16.727+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:12:16.727+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:12:16.747+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:12:16.747+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:12:16.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.143 seconds
[2025-12-13T10:12:46.987+0000] {processor.py:186} INFO - Started process (PID=980) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:12:46.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:12:46.990+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:12:46.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:12:48.070+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:12:48.092+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:12:48.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:12:48.111+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:12:48.111+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:12:48.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.153 seconds
[2025-12-13T10:14:41.483+0000] {processor.py:186} INFO - Started process (PID=999) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:41.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:41.485+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:41.485+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:13:10.370+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:13:10.392+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:10.392+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:13:10.412+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:10.412+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:13:10.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.120 seconds
[2025-12-13T10:14:46.526+0000] {processor.py:186} INFO - Started process (PID=1012) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:46.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:46.528+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:46.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:13:15.408+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:13:15.430+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:15.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:13:15.451+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:15.451+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:13:15.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.130 seconds
[2025-12-13T10:13:45.619+0000] {processor.py:186} INFO - Started process (PID=1031) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:13:45.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:13:45.621+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:45.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:13:46.798+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:13:46.832+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:46.831+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:13:46.856+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:46.855+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:13:46.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.271 seconds
[2025-12-13T10:14:00.854+0000] {processor.py:186} INFO - Started process (PID=1050) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:00.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:00.857+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:00.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:02.618+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:02.643+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:02.643+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:02.666+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:02.666+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:02.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.847 seconds
[2025-12-13T10:14:02.752+0000] {processor.py:186} INFO - Started process (PID=1063) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:02.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:02.755+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:02.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:03.891+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:03.924+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:03.924+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:03.946+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:03.946+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:03.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.219 seconds
[2025-12-13T10:14:04.024+0000] {processor.py:186} INFO - Started process (PID=1076) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:04.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:04.026+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:04.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:05.141+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:05.162+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:05.162+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:05.181+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:05.181+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:05.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.180 seconds
[2025-12-13T10:14:05.245+0000] {processor.py:186} INFO - Started process (PID=1089) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:05.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:05.247+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:05.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:06.266+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:06.289+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:06.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:06.309+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:06.309+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:06.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.086 seconds
[2025-12-13T10:14:06.384+0000] {processor.py:186} INFO - Started process (PID=1102) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:06.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:06.387+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:06.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:07.436+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:07.457+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:07.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:07.475+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:07.475+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:07.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.119 seconds
[2025-12-13T10:14:07.547+0000] {processor.py:186} INFO - Started process (PID=1115) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:07.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:07.550+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:07.549+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:08.670+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:08.693+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:08.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:08.713+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:08.712+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:08.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.192 seconds
[2025-12-13T10:14:08.784+0000] {processor.py:186} INFO - Started process (PID=1128) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:08.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:08.786+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:08.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:09.885+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:09.911+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:09.911+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:09.935+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:09.935+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:09.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.181 seconds
[2025-12-13T10:14:10.011+0000] {processor.py:186} INFO - Started process (PID=1141) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:10.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:10.015+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:10.014+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:11.203+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:11.232+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:11.231+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:11.259+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:11.259+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:11.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.275 seconds
[2025-12-13T10:14:11.341+0000] {processor.py:186} INFO - Started process (PID=1154) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:11.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:11.345+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:11.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:12.622+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:12.647+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:12.647+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:12.687+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:12.684+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:12.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.378 seconds
[2025-12-13T10:14:12.761+0000] {processor.py:186} INFO - Started process (PID=1167) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:12.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:12.763+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:12.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:14.381+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:14.410+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:14.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:14.435+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:14.434+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:14.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.700 seconds
[2025-12-13T10:15:46.545+0000] {processor.py:186} INFO - Started process (PID=1180) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:15:46.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:15:46.548+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:15:46.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:15.528+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:15.553+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:15.553+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:15.572+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:15.572+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:15.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.211 seconds
[2025-12-13T10:14:15.647+0000] {processor.py:186} INFO - Started process (PID=1193) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:15.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:15.649+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:15.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:16.794+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:16.823+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:16.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:16.850+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:16.850+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:16.874+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.234 seconds
[2025-12-13T10:14:16.934+0000] {processor.py:186} INFO - Started process (PID=1206) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:16.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:16.936+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:16.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:18.198+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:18.227+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:18.227+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:18.253+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:18.253+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:18.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.352 seconds
[2025-12-13T10:14:18.342+0000] {processor.py:186} INFO - Started process (PID=1219) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:18.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:18.344+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:18.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:17:11.755+0000] {processor.py:186} INFO - Started process (PID=1250) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:17:11.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:17:11.758+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:17:11.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:15:40.750+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:15:40.847+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:15:40.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:15:40.865+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:15:40.865+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:15:40.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.291 seconds
[2025-12-13T10:15:44.646+0000] {processor.py:186} INFO - Started process (PID=1263) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:15:44.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:15:44.649+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:15:44.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:15:45.712+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:15:45.723+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:15:45.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:15:45.744+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:15:45.744+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:15:45.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.129 seconds
[2025-12-13T10:16:15.951+0000] {processor.py:186} INFO - Started process (PID=1282) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:16:15.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:16:15.953+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:16:15.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:16:16.981+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:16:17.003+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:16:17.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:16:17.022+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:16:17.021+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:16:17.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.094 seconds
[2025-12-13T10:16:47.374+0000] {processor.py:186} INFO - Started process (PID=1301) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:16:47.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:16:47.376+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:16:47.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:16:48.421+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:16:48.444+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:16:48.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:16:48.465+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:16:48.465+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:16:48.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.121 seconds
[2025-12-13T10:17:14.781+0000] {processor.py:186} INFO - Started process (PID=1320) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:17:14.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:17:14.784+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:17:14.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:17:15.799+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:17:15.820+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:17:15.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:17:15.838+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:17:15.838+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:17:15.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.078 seconds
[2025-12-13T10:17:46.139+0000] {processor.py:186} INFO - Started process (PID=1339) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:17:46.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:17:46.141+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:17:46.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:17:47.209+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:17:47.233+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:17:47.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:17:47.254+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:17:47.254+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:17:47.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.146 seconds
[2025-12-13T10:18:17.497+0000] {processor.py:186} INFO - Started process (PID=1358) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:18:17.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:18:17.499+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:18:17.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:18:18.570+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:18:18.593+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:18:18.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:18:18.619+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:18:18.619+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:18:18.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.151 seconds
[2025-12-13T10:19:28.133+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:19:28.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:19:28.139+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:19:28.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:19:31.322+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:19:31.362+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:19:31.362+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:19:31.383+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:19:31.383+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:19:31.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.293 seconds
[2025-12-13T10:20:01.678+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:20:01.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:20:01.685+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:01.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:03.695+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:03.744+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:03.744+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:20:03.781+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:03.780+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:20:03.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.145 seconds
[2025-12-13T10:21:51.096+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:21:51.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:21:51.100+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:21:51.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:20.285+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:20.313+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:20.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:20:20.352+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:20.351+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:20:20.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.443 seconds
[2025-12-13T10:22:02.184+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:22:02.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:22:02.189+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:22:02.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:32.029+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:32.052+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:32.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:20:32.073+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:32.073+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:20:32.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.068 seconds
[2025-12-13T10:20:35.082+0000] {processor.py:186} INFO - Started process (PID=141) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:20:35.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:20:35.086+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:35.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:36.312+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:36.335+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:36.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:20:36.354+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:36.354+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:20:36.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.308 seconds
[2025-12-13T10:21:06.648+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:21:06.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:21:06.656+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:21:06.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:21:07.829+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:21:07.849+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:21:07.849+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:21:07.869+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:21:07.869+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:21:07.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.250 seconds
[2025-12-13T10:21:19.006+0000] {processor.py:186} INFO - Started process (PID=173) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:21:19.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:21:19.009+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:21:19.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:21:20.250+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:21:20.270+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:21:20.270+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:21:20.290+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:21:20.290+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:21:20.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.309 seconds
[2025-12-13T10:22:45.091+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:22:45.093+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:22:45.095+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:22:45.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:22:48.105+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:22:48.149+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:22:48.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:22:48.191+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:22:48.191+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:22:48.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.147 seconds
[2025-12-13T10:24:27.365+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:24:27.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:24:27.370+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:27.370+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:22:56.710+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:22:56.732+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:22:56.732+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:22:56.755+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:22:56.754+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:22:56.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.570 seconds
[2025-12-13T10:23:27.043+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:23:27.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:23:27.047+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:23:27.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:23:28.434+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:23:28.456+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:23:28.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:23:28.477+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:23:28.477+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:23:28.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.457 seconds
[2025-12-13T10:23:58.770+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:23:58.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:23:58.774+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:23:58.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:23:59.955+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:23:59.976+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:23:59.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:23:59.994+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:23:59.994+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:24:00.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.244 seconds
[2025-12-13T10:24:30.464+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:24:30.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:24:30.468+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:30.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:24:31.453+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:24:31.489+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:31.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:24:31.520+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:31.520+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:24:31.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.503 seconds
[2025-12-13T10:26:22.511+0000] {processor.py:186} INFO - Started process (PID=167) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:26:22.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:26:22.515+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:26:22.514+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:24:51.927+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:24:51.950+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:51.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:24:51.974+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:51.974+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:24:51.995+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.649 seconds
[2025-12-13T10:24:55.444+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:24:55.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:24:55.448+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:55.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:24:56.710+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:24:56.731+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:56.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:24:56.749+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:56.749+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:24:56.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.334 seconds
[2025-12-13T10:25:27.139+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:25:27.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:25:27.144+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:25:27.143+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:25:28.351+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:25:28.386+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:25:28.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:25:28.422+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:25:28.422+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:25:28.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.318 seconds
[2025-12-13T10:25:58.676+0000] {processor.py:186} INFO - Started process (PID=218) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:25:58.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:25:58.680+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:25:58.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:27:32.582+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:27:32.625+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:32.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:26:00.505+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:26:00.505+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:26:00.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.898 seconds
[2025-12-13T10:27:47.654+0000] {processor.py:186} INFO - Started process (PID=231) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:27:47.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:27:47.658+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:47.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:26:16.807+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:26:16.836+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:26:16.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:26:16.860+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:26:16.860+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:26:16.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.392 seconds
[2025-12-13T10:26:47.089+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:26:47.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:26:47.093+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:26:47.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:26:48.503+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:26:48.540+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:26:48.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:26:48.572+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:26:48.572+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:26:48.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.495 seconds
[2025-12-13T10:27:17.279+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:27:17.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:27:17.284+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:17.284+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:27:18.672+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:27:18.695+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:18.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:27:18.715+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:18.715+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:27:18.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.464 seconds
[2025-12-13T10:27:48.953+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:27:48.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:27:48.956+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:48.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:27:50.215+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:27:50.237+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:50.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:27:50.258+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:50.258+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:27:50.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.330 seconds
[2025-12-13T10:28:20.587+0000] {processor.py:186} INFO - Started process (PID=314) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:28:20.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:28:20.593+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:20.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:28:21.749+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:28:21.772+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:21.772+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:28:21.791+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:21.791+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:28:21.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.235 seconds
[2025-12-13T10:30:02.832+0000] {processor.py:186} INFO - Started process (PID=327) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:30:02.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:30:02.836+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:30:02.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:28:31.822+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:28:31.844+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:31.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:28:31.863+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:31.863+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:28:31.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.213 seconds
[2025-12-13T10:28:35.738+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:28:35.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:28:35.748+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:35.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:28:36.871+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:28:36.892+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:36.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:28:36.910+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:36.910+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:28:36.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.203 seconds
[2025-12-13T10:29:07.041+0000] {processor.py:186} INFO - Started process (PID=359) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:29:07.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:29:07.048+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:07.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:29:08.325+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:29:08.368+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:08.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:29:08.398+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:08.398+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:29:08.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.402 seconds
[2025-12-13T10:29:38.529+0000] {processor.py:186} INFO - Started process (PID=378) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:29:38.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:29:38.536+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:38.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:29:39.846+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:29:39.867+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:39.867+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:29:39.887+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:39.887+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:29:39.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.384 seconds
[2025-12-13T10:29:45.887+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:29:45.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:29:45.890+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:45.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:29:46.962+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:29:46.984+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:46.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:29:47.005+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:47.005+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:29:47.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.148 seconds
[2025-12-13T10:31:48.863+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:31:48.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:30:16.704+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:30:16.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:30:18.017+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:30:18.049+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:30:18.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:30:18.080+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:30:18.080+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:30:18.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.415 seconds
[2025-12-13T10:30:48.526+0000] {processor.py:186} INFO - Started process (PID=435) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:30:48.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:30:48.531+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:30:48.530+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:30:49.669+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:30:49.691+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:30:49.691+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:30:49.710+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:30:49.710+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:30:49.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.209 seconds
[2025-12-13T10:31:19.945+0000] {processor.py:186} INFO - Started process (PID=454) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:31:19.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:31:19.949+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:31:19.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:31:21.185+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:31:21.210+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:31:21.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:31:21.238+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:31:21.238+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:31:21.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.311 seconds
[2025-12-13T10:33:13.274+0000] {processor.py:186} INFO - Started process (PID=467) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:33:13.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:33:13.278+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:13.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:31:42.437+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:31:42.462+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:31:42.461+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:31:42.495+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:31:42.494+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:31:42.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.413 seconds
[2025-12-13T10:33:28.701+0000] {processor.py:186} INFO - Started process (PID=486) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:33:28.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:33:28.705+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:28.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:33:29.931+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:33:29.954+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:29.953+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:33:29.975+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:29.975+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:33:29.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.295 seconds
[2025-12-13T10:32:45.134+0000] {processor.py:186} INFO - Started process (PID=505) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:32:45.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:32:45.138+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:32:45.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:32:46.322+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:32:46.344+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:32:46.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:32:46.365+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:32:46.364+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:32:46.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.254 seconds
[2025-12-13T10:34:33.378+0000] {processor.py:186} INFO - Started process (PID=524) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:34:33.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:34:33.382+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:34:33.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:33:02.443+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:33:02.464+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:02.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:33:02.483+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:02.482+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:33:02.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.306 seconds
[2025-12-13T10:33:32.680+0000] {processor.py:186} INFO - Started process (PID=543) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:33:32.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:33:32.684+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:32.683+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:33:33.731+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:33:33.752+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:33.752+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:33:33.771+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:33.771+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:33:33.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.113 seconds
[2025-12-13T10:34:03.944+0000] {processor.py:186} INFO - Started process (PID=562) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:34:03.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:34:03.948+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:34:03.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:34:04.960+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:34:04.983+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:34:04.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:34:05.013+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:34:05.012+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:34:05.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.096 seconds
[2025-12-13T10:34:35.192+0000] {processor.py:186} INFO - Started process (PID=581) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:34:35.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:34:35.195+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:34:35.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:34:36.244+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:34:36.266+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:34:36.266+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:34:36.284+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:34:36.284+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:36:08.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.120 seconds
[2025-12-13T10:36:15.131+0000] {processor.py:186} INFO - Started process (PID=612) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:36:15.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:36:15.134+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:36:15.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:36:16.264+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:37:48.629+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:37:48.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:37:48.651+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:37:48.651+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:37:48.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.382 seconds
[2025-12-13T10:36:46.823+0000] {processor.py:186} INFO - Started process (PID=637) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:36:46.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:36:46.825+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:36:46.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:36:47.973+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:36:47.996+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:36:47.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:36:48.016+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:36:48.016+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:36:48.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.222 seconds
[2025-12-13T10:37:16.592+0000] {processor.py:186} INFO - Started process (PID=656) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:37:16.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:37:16.594+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:37:16.594+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:37:17.701+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:37:17.723+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:37:17.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:37:17.742+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:37:17.741+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:37:17.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.172 seconds
[2025-12-13T10:39:13.731+0000] {processor.py:186} INFO - Started process (PID=669) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:39:13.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:39:13.733+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:39:13.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:37:42.767+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:37:42.792+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:37:42.792+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:37:42.816+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:37:42.815+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:37:42.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.280 seconds
[2025-12-13T10:46:44.923+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:46:44.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:46:44.928+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:46:44.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:46:48.086+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:46:48.127+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:46:48.127+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:46:48.150+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:46:48.149+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:46:48.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.257 seconds
[2025-12-13T10:48:39.511+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:48:39.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:48:39.516+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:39.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:08.600+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:08.620+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:08.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:47:08.637+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:08.637+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:47:08.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.343 seconds
[2025-12-13T10:47:12.404+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:47:12.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:47:12.409+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:12.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:14.197+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:14.223+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:14.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:47:14.253+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:14.253+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:47:14.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.883 seconds
[2025-12-13T10:48:49.532+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:48:49.534+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:48:49.538+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:49.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:19.069+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:19.107+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:19.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:47:19.135+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:19.135+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:47:19.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.812 seconds
[2025-12-13T10:49:09.530+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:49:09.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:49:09.533+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:09.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:38.660+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:38.685+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:38.685+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:47:38.714+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:38.713+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:47:38.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.379 seconds
[2025-12-13T10:47:42.413+0000] {processor.py:186} INFO - Started process (PID=149) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:47:42.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:47:42.417+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:42.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:43.604+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:43.626+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:43.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:47:43.645+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:43.645+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:47:43.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.256 seconds
[2025-12-13T10:49:24.555+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:49:24.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:49:24.559+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:24.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:53.762+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:53.788+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:53.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:47:53.809+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:53.809+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:47:53.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.453 seconds
[2025-12-13T10:48:10.753+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:48:10.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:48:10.758+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:10.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:12.025+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:12.048+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:12.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:48:12.067+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:12.066+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:48:12.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.338 seconds
[2025-12-13T10:48:42.393+0000] {processor.py:186} INFO - Started process (PID=200) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:48:42.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:48:42.398+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:42.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:43.661+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:43.683+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:43.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:48:43.700+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:43.700+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:48:43.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.326 seconds
[2025-12-13T10:50:19.651+0000] {processor.py:186} INFO - Started process (PID=213) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:50:19.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:50:19.654+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:19.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:48.666+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:48.689+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:48.688+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:48:48.708+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:48.708+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:48:48.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.251 seconds
[2025-12-13T10:48:52.565+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:48:52.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:48:52.569+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:52.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:53.812+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:53.836+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:53.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:48:53.859+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:53.859+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:48:53.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.331 seconds
[2025-12-13T10:49:24.149+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:49:24.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:49:24.154+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:24.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:49:25.399+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:49:25.420+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:25.420+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:49:25.442+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:25.442+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:49:25.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.324 seconds
[2025-12-13T10:50:59.708+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:50:59.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:50:59.711+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:59.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:49:28.731+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:49:28.756+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:28.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:49:28.781+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:28.780+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:49:28.799+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.268 seconds
[2025-12-13T10:49:32.591+0000] {processor.py:186} INFO - Started process (PID=277) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:49:32.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:49:32.597+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:32.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:49:34.031+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:49:34.056+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:34.056+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:49:34.077+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:34.077+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:49:34.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.520 seconds
[2025-12-13T10:50:04.403+0000] {processor.py:186} INFO - Started process (PID=296) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:50:04.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:50:04.407+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:04.407+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:50:05.780+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:50:05.806+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:05.806+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:50:05.829+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:05.829+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:50:05.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.453 seconds
[2025-12-13T10:50:36.058+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:50:36.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:50:36.064+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:36.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:50:37.282+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:50:37.303+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:37.303+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:50:37.323+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:37.323+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:50:37.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.289 seconds
[2025-12-13T10:51:07.547+0000] {processor.py:186} INFO - Started process (PID=334) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:51:07.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:51:07.553+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:07.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:08.819+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:08.845+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:08.845+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:51:08.869+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:08.869+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:51:08.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.344 seconds
[2025-12-13T10:52:59.864+0000] {processor.py:186} INFO - Started process (PID=353) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:52:59.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:52:59.868+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:52:59.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:28.899+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:28.923+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:28.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:51:28.944+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:28.944+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:51:28.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.282 seconds
[2025-12-13T10:51:32.756+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:51:32.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:51:32.763+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:32.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:33.859+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:33.881+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:33.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:51:33.899+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:33.899+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:51:33.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.170 seconds
[2025-12-13T10:51:37.797+0000] {processor.py:186} INFO - Started process (PID=379) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:51:37.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:51:37.801+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:37.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:38.873+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:38.893+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:38.893+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:51:38.911+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:38.911+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:51:38.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.138 seconds
[2025-12-13T10:52:09.064+0000] {processor.py:186} INFO - Started process (PID=398) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:52:09.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:52:09.068+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:52:09.067+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:52:10.113+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:52:10.134+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:52:10.134+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:52:10.152+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:52:10.152+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:52:10.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.120 seconds
[2025-12-13T10:52:41.236+0000] {processor.py:186} INFO - Started process (PID=417) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:52:41.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:52:41.240+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:52:41.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:52:42.423+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:52:42.444+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:52:42.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:52:42.468+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:52:42.467+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:52:42.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.255 seconds
[2025-12-13T10:53:12.740+0000] {processor.py:186} INFO - Started process (PID=436) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:53:12.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:53:12.743+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:53:12.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:53:13.911+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:53:13.936+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:53:13.936+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:53:13.956+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:53:13.956+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:53:13.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.240 seconds
[2025-12-13T10:53:44.475+0000] {processor.py:186} INFO - Started process (PID=455) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:53:44.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:53:44.479+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:53:44.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:53:45.666+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:53:45.687+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:53:45.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:53:45.705+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:53:45.704+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:53:45.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.251 seconds
[2025-12-13T10:55:35.097+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:55:35.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:55:35.101+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:35.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:04.203+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:04.227+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:04.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:54:04.249+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:04.249+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:54:04.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.352 seconds
[2025-12-13T10:55:40.181+0000] {processor.py:186} INFO - Started process (PID=487) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:55:40.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:54:08.016+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:40.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:09.190+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:09.212+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:09.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:54:09.232+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:09.232+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:54:09.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.254 seconds
[2025-12-13T10:54:13.037+0000] {processor.py:186} INFO - Started process (PID=500) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:54:13.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:54:13.041+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:13.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:14.138+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:14.163+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:14.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:54:14.185+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:14.185+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:54:14.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.171 seconds
[2025-12-13T10:54:44.490+0000] {processor.py:186} INFO - Started process (PID=519) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:54:44.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:54:44.494+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:44.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:45.555+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:45.579+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:45.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:54:45.600+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:45.599+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:54:45.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.134 seconds
[2025-12-13T10:55:15.713+0000] {processor.py:186} INFO - Started process (PID=544) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:55:15.714+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:55:15.717+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:15.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:55:16.859+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:55:16.883+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:16.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:55:16.904+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:16.904+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:55:16.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.220 seconds
[2025-12-13T10:55:23.110+0000] {processor.py:186} INFO - Started process (PID=557) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:55:23.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:55:23.114+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:23.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:55:24.197+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:55:24.222+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:24.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:55:24.241+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:24.241+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:55:24.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.155 seconds
[2025-12-13T10:55:54.524+0000] {processor.py:186} INFO - Started process (PID=576) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:55:54.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:55:54.528+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:54.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:55:55.611+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:55:55.634+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:55.633+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:55:55.653+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:55.653+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:55:55.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.158 seconds
[2025-12-13T10:56:25.853+0000] {processor.py:186} INFO - Started process (PID=595) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:56:25.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:56:25.858+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:56:25.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:56:27.029+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:56:27.052+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:56:27.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:56:27.072+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:56:27.072+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:56:27.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.247 seconds
[2025-12-13T10:56:28.188+0000] {processor.py:186} INFO - Started process (PID=608) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:56:28.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:56:28.193+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:56:28.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:56:29.334+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:56:29.360+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:56:29.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:56:29.381+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:56:29.380+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:56:29.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.216 seconds
[2025-12-13T10:56:59.750+0000] {processor.py:186} INFO - Started process (PID=627) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:56:59.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:56:59.756+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:56:59.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:01.064+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:01.093+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:01.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:01.121+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:01.120+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:01.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.408 seconds
[2025-12-13T10:58:40.446+0000] {processor.py:186} INFO - Started process (PID=640) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:40.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:40.451+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:40.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:09.908+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:09.930+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:09.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:09.947+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:09.947+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:09.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.688 seconds
[2025-12-13T10:58:55.463+0000] {processor.py:186} INFO - Started process (PID=659) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:55.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:55.467+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:55.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:24.910+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:24.949+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:24.948+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:24.980+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:24.980+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:25.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.728 seconds
[2025-12-13T10:57:28.333+0000] {processor.py:186} INFO - Started process (PID=672) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:57:28.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:57:28.337+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:28.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:29.418+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:29.440+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:29.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:29.459+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:29.459+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:29.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.155 seconds
[2025-12-13T10:57:53.946+0000] {processor.py:186} INFO - Started process (PID=691) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:57:53.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:57:53.950+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:53.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:55.202+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:55.223+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:55.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:55.245+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:55.244+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:55.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.331 seconds
[2025-12-13T10:57:55.319+0000] {processor.py:186} INFO - Started process (PID=704) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:57:55.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:57:55.323+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:55.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:56.451+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:56.471+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:56.471+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:56.490+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:56.489+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:56.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.193 seconds
[2025-12-13T10:57:56.558+0000] {processor.py:186} INFO - Started process (PID=717) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:57:56.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:57:56.561+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:56.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:57.628+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:57.651+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:57.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:57.671+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:57.671+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:57.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.138 seconds
[2025-12-13T10:57:57.741+0000] {processor.py:186} INFO - Started process (PID=730) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:57:57.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:57:57.745+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:57.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:58.888+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:58.910+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:58.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:58.933+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:58.932+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:58.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.225 seconds
[2025-12-13T10:57:59.020+0000] {processor.py:186} INFO - Started process (PID=743) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:57:59.021+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:57:59.024+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:59.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:00.070+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:00.092+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:00.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:58:00.112+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:00.112+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:58:00.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.120 seconds
[2025-12-13T10:58:00.185+0000] {processor.py:186} INFO - Started process (PID=756) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:00.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:00.189+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:00.189+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:01.329+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:01.363+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:01.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:58:01.387+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:01.386+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:58:01.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.234 seconds
[2025-12-13T10:58:01.469+0000] {processor.py:186} INFO - Started process (PID=769) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:01.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:01.473+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:01.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:02.599+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:02.622+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:02.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:58:02.642+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:02.641+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:58:02.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.202 seconds
[2025-12-13T10:58:02.718+0000] {processor.py:186} INFO - Started process (PID=782) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:02.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:02.722+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:02.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:03.829+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:03.854+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:03.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:58:03.876+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:03.876+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:58:03.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.181 seconds
[2025-12-13T10:58:03.955+0000] {processor.py:186} INFO - Started process (PID=795) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:03.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:03.959+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:03.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:33.828+0000] {processor.py:186} INFO - Started process (PID=814) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:33.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:33.832+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:33.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:34.954+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:35.146+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:35.146+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:58:35.163+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:35.163+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:58:35.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.371 seconds
[2025-12-13T10:58:35.235+0000] {processor.py:186} INFO - Started process (PID=827) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:35.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:35.237+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:35.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:36.300+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:36.310+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:36.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:58:36.330+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:36.330+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:58:36.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.119 seconds
[2025-12-13T10:58:36.403+0000] {processor.py:186} INFO - Started process (PID=840) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:36.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:36.406+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:36.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:43.052+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:43.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:43.056+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:43.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:46.150+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:46.186+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:46.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:46.207+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:46.207+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:46.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.185 seconds
[2025-12-13T10:59:46.296+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:46.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:46.301+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:46.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:47.991+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:48.025+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:48.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:48.056+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:48.056+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:48.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.795 seconds
[2025-12-13T10:59:48.152+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:48.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:48.156+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:48.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:49.555+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:49.579+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:49.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:49.601+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:49.601+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:49.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.473 seconds
[2025-12-13T10:59:49.679+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:49.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:49.683+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:49.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:50.886+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:50.907+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:50.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:50.926+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:50.926+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:50.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.278 seconds
[2025-12-13T10:59:51.004+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:51.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:51.008+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:51.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:52.248+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:52.270+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:52.269+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:52.293+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:52.293+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:52.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.314 seconds
[2025-12-13T10:59:52.373+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:52.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:52.377+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:52.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:01:25.724+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:01:25.747+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:01:25.747+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:01:25.769+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:01:25.769+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:53.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.253 seconds
[2025-12-13T10:59:53.674+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:53.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:53.679+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:53.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:55.139+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:55.172+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:55.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:55.197+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:55.197+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:55.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.549 seconds
[2025-12-13T10:59:55.269+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:55.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:55.273+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:55.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:56.439+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:56.462+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:56.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:56.485+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:56.485+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:56.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.239 seconds
[2025-12-13T10:59:56.553+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:56.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:56.557+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:56.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:57.715+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:57.738+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:57.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:57.758+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:57.757+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:57.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.227 seconds
[2025-12-13T10:59:57.823+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:57.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:57.827+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:57.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:02:00.976+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:02:00.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:02:00.980+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:00.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:02:02.206+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:02:02.230+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:02.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:02:02.251+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:02.251+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:02:02.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.299 seconds
[2025-12-13T11:02:32.408+0000] {processor.py:186} INFO - Started process (PID=249) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:02:32.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:02:32.414+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:32.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:02:33.550+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:02:33.574+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:33.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:02:33.594+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:33.594+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:02:33.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.220 seconds
[2025-12-13T11:04:26.043+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:04:26.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:04:26.047+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:04:26.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:02:55.229+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:02:55.256+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:55.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:02:55.285+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:55.284+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:02:55.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.467 seconds
[2025-12-13T11:03:25.630+0000] {processor.py:186} INFO - Started process (PID=287) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:03:25.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:03:25.634+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:03:25.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:03:26.985+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:03:27.014+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:03:27.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:03:27.040+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:03:27.040+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:03:27.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.444 seconds
[2025-12-13T11:03:34.207+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:03:34.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:03:34.211+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:03:34.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:03:35.661+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:03:35.683+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:03:35.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:03:35.703+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:03:35.703+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:03:35.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.525 seconds
[2025-12-13T11:05:31.094+0000] {processor.py:186} INFO - Started process (PID=319) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:31.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:31.103+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:31.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:04:01.286+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:04:01.311+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:04:01.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:04:01.341+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:04:01.341+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:04:01.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.458 seconds
[2025-12-13T11:04:19.114+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:04:19.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:04:19.118+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:04:19.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:04:20.449+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:04:20.501+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:04:20.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:04:20.552+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:04:20.552+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:04:20.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.508 seconds
[2025-12-13T11:04:31.305+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:04:31.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:04:31.309+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:04:31.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:43.563+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:43.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:43.567+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:43.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:46.525+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:46.564+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:46.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:46.586+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:46.586+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:46.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.066 seconds
[2025-12-13T11:05:46.681+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:46.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:46.685+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:46.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:48.139+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:48.160+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:48.160+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:48.178+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:48.178+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:48.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.527 seconds
[2025-12-13T11:05:48.257+0000] {processor.py:186} INFO - Started process (PID=94) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:48.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:48.261+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:48.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:49.746+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:49.774+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:49.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:49.796+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:49.796+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:49.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.552 seconds
[2025-12-13T11:05:49.875+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:49.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:49.880+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:49.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:51.114+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:51.136+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:51.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:51.155+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:51.154+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:51.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.302 seconds
[2025-12-13T11:05:51.224+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:51.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:51.229+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:51.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:52.433+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:52.453+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:52.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:52.476+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:52.476+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:52.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.275 seconds
[2025-12-13T11:05:52.552+0000] {processor.py:186} INFO - Started process (PID=133) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:52.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:52.555+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:52.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:53.843+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:53.871+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:53.870+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:53.902+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:53.901+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:53.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.384 seconds
[2025-12-13T11:07:26.178+0000] {processor.py:186} INFO - Started process (PID=146) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:07:26.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:07:26.182+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:26.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:55.301+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:55.323+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:55.323+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:55.343+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:55.343+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:55.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.367 seconds
[2025-12-13T11:05:55.413+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:55.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:55.417+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:55.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:56.645+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:56.668+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:56.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:56.689+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:56.688+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:56.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.299 seconds
[2025-12-13T11:05:56.762+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:56.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:56.765+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:56.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:57.918+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:57.939+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:57.939+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:57.957+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:57.957+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:57.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.216 seconds
[2025-12-13T11:05:58.021+0000] {processor.py:186} INFO - Started process (PID=185) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:58.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:58.025+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:58.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:08:11.286+0000] {processor.py:186} INFO - Started process (PID=213) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:08:11.287+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:08:11.290+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:08:11.289+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:06:40.662+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:06:40.686+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:06:40.686+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:06:40.711+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:06:40.710+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:06:40.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.632 seconds
[2025-12-13T11:07:11.034+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:07:11.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:07:11.038+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:11.038+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:07:12.213+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:07:12.236+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:12.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:07:12.256+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:12.256+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:07:12.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.244 seconds
[2025-12-13T11:09:01.378+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:09:01.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:09:01.382+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:09:01.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:07:30.654+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:07:30.679+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:30.679+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:07:30.703+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:30.702+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:07:30.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.535 seconds
[2025-12-13T11:09:21.386+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:09:21.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:09:21.390+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:09:21.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:07:50.677+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:07:50.701+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:50.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:07:50.724+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:50.724+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:07:50.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.551 seconds
[2025-12-13T11:08:20.933+0000] {processor.py:186} INFO - Started process (PID=289) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:08:20.934+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:08:20.936+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:08:20.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:08:22.198+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:08:22.223+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:08:22.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:08:22.245+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:08:22.244+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:08:22.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.336 seconds
[2025-12-13T11:08:52.533+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:08:52.534+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:08:52.538+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:08:52.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:08:53.847+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:08:53.870+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:08:53.870+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:08:53.891+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:08:53.891+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:08:53.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.383 seconds
[2025-12-13T11:09:24.118+0000] {processor.py:186} INFO - Started process (PID=327) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:09:24.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:09:24.121+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:09:24.121+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:09:25.475+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:09:25.505+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:09:25.505+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:09:25.543+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:09:25.543+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:09:25.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.455 seconds
[2025-12-13T11:11:02.854+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:11:02.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:11:02.857+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:02.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:09:32.045+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:09:32.069+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:09:32.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:09:32.092+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:09:32.091+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:09:32.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.448 seconds
[2025-12-13T11:10:02.338+0000] {processor.py:186} INFO - Started process (PID=359) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:10:02.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:10:02.342+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:02.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:03.816+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:03.843+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:03.842+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:10:03.865+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:03.864+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:10:03.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.551 seconds
[2025-12-13T11:11:41.584+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:11:41.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:11:41.590+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:41.589+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:11.133+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:11.162+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:11.162+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:10:11.195+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:11.194+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:10:11.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.825 seconds
[2025-12-13T11:12:06.589+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:12:06.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:12:06.592+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:06.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:35.697+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:35.719+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:35.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:10:35.740+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:35.740+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:10:35.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.358 seconds
[2025-12-13T11:10:39.467+0000] {processor.py:186} INFO - Started process (PID=404) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:10:39.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:10:39.471+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:39.470+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:40.802+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:40.826+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:40.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:10:40.854+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:40.853+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:10:40.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.417 seconds
[2025-12-13T11:11:11.096+0000] {processor.py:186} INFO - Started process (PID=423) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:11:11.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:11:11.100+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:11.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:12.158+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:12.180+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:12.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:11:12.199+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:12.198+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:11:12.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.124 seconds
[2025-12-13T11:11:42.281+0000] {processor.py:186} INFO - Started process (PID=443) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:11:42.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:11:42.285+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:42.284+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:43.377+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:43.399+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:43.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:11:43.417+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:43.417+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:11:43.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.166 seconds
[2025-12-13T11:13:21.719+0000] {processor.py:186} INFO - Started process (PID=462) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:13:21.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:13:21.723+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:13:21.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:50.887+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:50.917+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:50.917+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:11:50.941+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:50.941+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:11:50.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.436 seconds
[2025-12-13T11:11:54.612+0000] {processor.py:186} INFO - Started process (PID=475) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:11:54.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:11:54.620+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:54.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:55.775+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:55.804+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:55.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:11:55.826+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:55.826+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:11:55.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.249 seconds
[2025-12-13T11:12:26.169+0000] {processor.py:186} INFO - Started process (PID=494) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:12:26.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:12:26.173+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:26.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:12:27.231+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:12:27.252+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:27.252+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:12:27.271+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:27.270+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:12:27.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.130 seconds
[2025-12-13T11:12:57.458+0000] {processor.py:186} INFO - Started process (PID=513) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:12:57.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:12:57.462+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:57.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:12:58.568+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:12:58.591+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:58.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:12:58.612+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:58.612+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:12:58.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.184 seconds
[2025-12-13T11:12:59.683+0000] {processor.py:186} INFO - Started process (PID=526) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:12:59.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:12:59.687+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:59.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:15:00.085+0000] {processor.py:186} INFO - Started process (PID=564) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:15:00.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:15:00.088+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:15:00.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:15:01.295+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:15:01.519+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:15:01.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:15:01.538+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:15:01.538+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:15:01.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.484 seconds
[2025-12-13T11:15:31.859+0000] {processor.py:186} INFO - Started process (PID=583) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:15:31.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:15:31.862+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:15:31.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:15:33.068+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:15:33.090+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:15:33.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:15:33.111+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:15:33.110+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:15:33.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.277 seconds
[2025-12-13T11:16:03.436+0000] {processor.py:186} INFO - Started process (PID=602) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:16:03.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:16:03.438+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:03.438+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:04.462+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:04.486+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:04.486+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:16:04.506+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:04.506+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:16:04.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.091 seconds
[2025-12-13T11:16:34.604+0000] {processor.py:186} INFO - Started process (PID=621) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:16:34.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:16:34.607+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:34.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:35.754+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:35.776+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:35.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:16:35.793+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:35.793+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:16:35.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.216 seconds
[2025-12-13T11:18:17.109+0000] {processor.py:186} INFO - Started process (PID=634) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:18:17.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:18:17.112+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:18:17.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:46.089+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:46.159+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:46.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:16:46.231+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:46.230+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:16:46.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.386 seconds
[2025-12-13T11:16:50.011+0000] {processor.py:186} INFO - Started process (PID=653) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:16:50.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:16:50.014+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:50.014+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:51.211+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:51.240+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:51.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:16:51.264+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:51.263+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:16:51.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.290 seconds
[2025-12-13T11:17:00.102+0000] {processor.py:186} INFO - Started process (PID=666) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:17:00.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:17:00.106+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:17:00.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:17:01.355+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:17:01.415+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:17:01.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:17:01.475+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:17:01.474+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:17:01.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.435 seconds
[2025-12-13T11:17:01.644+0000] {processor.py:186} INFO - Started process (PID=679) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:17:01.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:17:01.648+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:17:01.647+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:18:13.013+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:18:13.015+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:18:13.017+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:18:13.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:20:18.135+0000] {processor.py:186} INFO - Started process (PID=114) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:20:18.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:20:18.139+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:18.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:20:19.933+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:20:19.973+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:19.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:20:19.994+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:19.994+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:20:20.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.885 seconds
[2025-12-13T11:20:25.257+0000] {processor.py:186} INFO - Started process (PID=127) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:20:25.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:20:25.261+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:25.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:20:26.448+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:20:26.470+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:26.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:20:26.490+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:26.489+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:20:26.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.256 seconds
[2025-12-13T11:20:29.294+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:20:29.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:20:29.299+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:29.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:20:30.574+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:20:30.600+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:30.600+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:20:30.626+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:30.626+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:20:30.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.357 seconds
[2025-12-13T11:21:00.932+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:21:00.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:21:00.936+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:00.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:02.151+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:02.175+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:02.175+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:21:02.196+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:02.195+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:21:02.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.289 seconds
[2025-12-13T11:22:37.471+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:22:37.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:22:37.475+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:22:37.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:06.475+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:06.500+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:06.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:21:06.522+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:06.522+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:21:06.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.264 seconds
[2025-12-13T11:21:10.360+0000] {processor.py:186} INFO - Started process (PID=185) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:21:10.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:21:10.365+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:10.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:11.565+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:11.589+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:11.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:21:11.610+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:11.610+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:21:11.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.274 seconds
[2025-12-13T11:21:42.302+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:21:42.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:21:42.306+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:42.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:43.667+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:43.689+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:43.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:21:43.710+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:43.710+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:21:43.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.430 seconds
[2025-12-13T11:22:14.262+0000] {processor.py:186} INFO - Started process (PID=223) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:22:14.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:22:14.266+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:22:14.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:22:15.496+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:22:15.519+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:22:15.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:22:15.541+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:22:15.541+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:22:15.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.304 seconds
[2025-12-13T11:22:45.483+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:22:45.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:22:45.488+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:22:45.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:22:46.854+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:22:46.902+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:22:46.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:22:46.953+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:22:46.948+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:22:46.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.508 seconds
[2025-12-13T11:23:17.226+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:23:17.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:23:17.230+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:23:17.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:23:18.456+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:23:18.477+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:23:18.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:23:18.496+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:23:18.496+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:23:18.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.292 seconds
[2025-12-13T11:23:49.224+0000] {processor.py:186} INFO - Started process (PID=287) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:23:49.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:23:49.228+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:23:49.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:23:50.401+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:23:50.424+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:23:50.424+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:23:50.445+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:23:50.444+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:23:50.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.249 seconds
[2025-12-13T11:24:21.056+0000] {processor.py:186} INFO - Started process (PID=306) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:24:21.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:24:21.059+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:24:21.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:24:22.121+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:24:22.142+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:24:22.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:24:22.159+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:24:22.159+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:24:22.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.124 seconds
[2025-12-13T11:24:52.456+0000] {processor.py:186} INFO - Started process (PID=325) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:24:52.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:24:52.459+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:24:52.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:24:53.623+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:24:53.644+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:24:53.644+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:24:53.662+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:24:53.661+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:24:53.679+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.230 seconds
[2025-12-13T11:26:42.853+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:26:42.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:26:42.856+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:42.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:25:11.865+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:25:11.890+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:11.890+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:25:11.911+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:11.911+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:25:11.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.277 seconds
[2025-12-13T11:25:42.155+0000] {processor.py:186} INFO - Started process (PID=357) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:25:42.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:25:42.158+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:42.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:25:43.256+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:25:43.278+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:43.278+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:25:43.298+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:43.298+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:25:43.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.170 seconds
[2025-12-13T11:25:57.409+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:25:57.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:25:57.412+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:57.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:25:58.622+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:25:58.642+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:58.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:25:58.660+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:58.660+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:25:58.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.274 seconds
[2025-12-13T11:27:32.937+0000] {processor.py:186} INFO - Started process (PID=389) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:27:32.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:27:32.940+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:32.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:26:01.834+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:26:01.855+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:01.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:26:01.872+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:01.872+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:26:01.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.151 seconds
[2025-12-13T11:26:05.786+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:26:05.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:26:05.790+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:05.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:26:06.961+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:26:06.986+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:06.985+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:26:07.008+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:07.008+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:26:07.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.245 seconds
[2025-12-13T11:26:37.312+0000] {processor.py:186} INFO - Started process (PID=421) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:26:37.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:26:37.315+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:37.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:26:38.754+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:26:38.786+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:38.786+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:26:38.808+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:38.808+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:26:38.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.522 seconds
[2025-12-13T11:27:09.208+0000] {processor.py:186} INFO - Started process (PID=440) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:27:09.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:27:09.212+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:09.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:10.334+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:10.356+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:10.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:27:10.376+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:10.375+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:27:10.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.196 seconds
[2025-12-13T11:28:53.023+0000] {processor.py:186} INFO - Started process (PID=459) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:28:53.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:28:53.027+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:53.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:22.163+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:22.186+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:22.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:27:22.207+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:22.207+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:27:22.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.404 seconds
[2025-12-13T11:27:26.055+0000] {processor.py:186} INFO - Started process (PID=472) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:27:26.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:27:26.058+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:26.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:27.195+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:27.218+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:27.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:27:27.240+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:27.240+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:27:27.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.215 seconds
[2025-12-13T11:29:18.095+0000] {processor.py:186} INFO - Started process (PID=491) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:29:18.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:29:18.099+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:18.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:47.058+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:47.084+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:47.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:27:47.105+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:47.104+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:27:47.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.234 seconds
[2025-12-13T11:29:33.079+0000] {processor.py:186} INFO - Started process (PID=504) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:29:33.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:29:33.083+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:33.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:28:02.073+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:28:02.097+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:02.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:28:02.118+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:02.118+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:28:02.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.260 seconds
[2025-12-13T11:28:05.936+0000] {processor.py:186} INFO - Started process (PID=517) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:28:05.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:28:05.940+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:05.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:28:06.975+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:28:06.998+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:06.997+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:28:07.018+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:07.017+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:28:07.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.106 seconds
[2025-12-13T11:28:37.219+0000] {processor.py:186} INFO - Started process (PID=536) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:28:37.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:28:37.222+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:37.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:28:38.406+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:28:38.428+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:38.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:28:38.449+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:38.449+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:28:38.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.253 seconds
[2025-12-13T11:29:08.686+0000] {processor.py:186} INFO - Started process (PID=555) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:29:08.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:29:08.690+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:08.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:29:10.265+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:29:10.288+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:10.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:29:10.310+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:10.310+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:29:10.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.651 seconds
[2025-12-13T11:30:55.156+0000] {processor.py:186} INFO - Started process (PID=573) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:30:55.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:30:55.160+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:55.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:29:24.047+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:29:24.068+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:24.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:29:24.086+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:24.085+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:29:24.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.143 seconds
[2025-12-13T11:31:03.236+0000] {processor.py:186} INFO - Started process (PID=586) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:31:03.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:31:03.240+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:03.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:29:32.286+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:29:32.308+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:32.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:29:32.327+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:32.327+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:29:32.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.318 seconds
[2025-12-13T11:30:02.482+0000] {processor.py:186} INFO - Started process (PID=605) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:30:02.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:30:02.486+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:02.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:30:03.707+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:30:03.729+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:03.729+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:30:03.750+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:03.749+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:30:03.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.300 seconds
[2025-12-13T11:31:55.153+0000] {processor.py:186} INFO - Started process (PID=624) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:31:55.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:31:55.157+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:55.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:30:24.087+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:30:24.111+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:24.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:30:24.132+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:24.132+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:30:24.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.194 seconds
[2025-12-13T11:32:18.323+0000] {processor.py:186} INFO - Started process (PID=643) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:32:18.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:32:18.327+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:32:18.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:30:47.167+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:30:47.190+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:47.190+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:30:47.223+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:47.223+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:30:47.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.122 seconds
[2025-12-13T11:31:17.368+0000] {processor.py:186} INFO - Started process (PID=663) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:31:17.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:31:17.372+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:17.372+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:18.620+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:18.642+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:18.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:31:18.664+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:18.664+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:31:18.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.326 seconds
[2025-12-13T11:31:48.950+0000] {processor.py:186} INFO - Started process (PID=683) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:31:48.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:31:48.954+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:48.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:50.096+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:50.122+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:50.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:31:50.141+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:50.141+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:31:50.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.215 seconds
[2025-12-13T11:33:23.431+0000] {processor.py:186} INFO - Started process (PID=696) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:33:23.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:33:23.434+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:33:23.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:52.311+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:52.337+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:52.337+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:31:52.365+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:52.364+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:31:52.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.172 seconds
[2025-12-13T11:31:56.280+0000] {processor.py:186} INFO - Started process (PID=709) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:31:56.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:31:56.284+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:56.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:57.355+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:57.379+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:57.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:31:57.399+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:57.399+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:31:57.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.144 seconds
[2025-12-13T11:32:27.561+0000] {processor.py:186} INFO - Started process (PID=728) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:32:27.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:32:27.567+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:32:27.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:32:28.782+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:32:28.804+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:32:28.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:32:28.826+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:32:28.825+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:32:28.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.287 seconds
[2025-12-13T11:32:58.899+0000] {processor.py:186} INFO - Started process (PID=747) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:32:58.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:32:58.903+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:32:58.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:32:59.978+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:33:00.015+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:33:00.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:33:00.037+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:33:00.037+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:33:00.054+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.162 seconds
[2025-12-13T11:33:30.274+0000] {processor.py:186} INFO - Started process (PID=766) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:33:30.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:33:30.278+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:33:30.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:03.526+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:03.550+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:03.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:33:31.376+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:33:31.375+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:33:31.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.122 seconds
[2025-12-13T11:35:08.549+0000] {processor.py:186} INFO - Started process (PID=779) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:35:08.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:35:08.554+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:08.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:33:37.402+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:33:37.430+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:33:37.430+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:33:37.452+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:33:37.452+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:33:37.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.119 seconds
[2025-12-13T11:34:07.732+0000] {processor.py:186} INFO - Started process (PID=798) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:34:07.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:34:07.736+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:07.736+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:34:09.078+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:34:09.106+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:09.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:34:09.129+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:09.128+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:34:09.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.420 seconds
[2025-12-13T11:35:55.120+0000] {processor.py:186} INFO - Started process (PID=817) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:35:55.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:35:55.124+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:55.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:34:23.993+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:34:24.015+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:24.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:34:24.036+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:24.036+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:34:24.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.138 seconds
[2025-12-13T11:34:54.599+0000] {processor.py:186} INFO - Started process (PID=836) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:34:54.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:34:54.602+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:54.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:34:55.743+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:34:55.767+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:55.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:34:55.792+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:55.792+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:34:55.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.215 seconds
[2025-12-13T11:35:26.193+0000] {processor.py:186} INFO - Started process (PID=855) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:35:26.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:35:26.198+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:26.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:27.288+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:27.311+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:27.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:35:27.330+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:27.330+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:35:27.348+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.139 seconds
[2025-12-13T11:37:08.694+0000] {processor.py:186} INFO - Started process (PID=868) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:37:08.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:37:08.697+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:08.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:37.601+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:37.623+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:37.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:35:37.640+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:37.640+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:35:37.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.168 seconds
[2025-12-13T11:35:41.576+0000] {processor.py:186} INFO - Started process (PID=887) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:35:41.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:35:41.579+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:41.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:42.630+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:42.651+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:42.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:35:42.669+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:42.669+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:35:42.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.115 seconds
[2025-12-13T11:36:12.865+0000] {processor.py:186} INFO - Started process (PID=906) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:36:12.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:36:12.868+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:12.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:36:13.920+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:36:13.942+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:13.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:36:13.961+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:13.960+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:36:13.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.125 seconds
[2025-12-13T11:36:44.255+0000] {processor.py:186} INFO - Started process (PID=925) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:36:44.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:36:44.258+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:44.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:36:45.297+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:36:45.321+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:45.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:36:45.343+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:45.343+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:36:45.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.111 seconds
[2025-12-13T11:38:23.549+0000] {processor.py:186} INFO - Started process (PID=938) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:38:23.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:38:23.553+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:23.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:36:52.390+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:36:52.412+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:52.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:36:52.432+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:52.432+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:36:52.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.113 seconds
[2025-12-13T11:38:38.815+0000] {processor.py:186} INFO - Started process (PID=951) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:38:38.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:38:38.819+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:38.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:07.860+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:07.883+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:07.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:37:07.903+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:07.903+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:37:07.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.318 seconds
[2025-12-13T11:37:11.670+0000] {processor.py:186} INFO - Started process (PID=970) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:37:11.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:37:11.675+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:11.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:12.744+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:12.768+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:12.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:37:12.789+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:12.788+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:37:12.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.144 seconds
[2025-12-13T11:37:21.734+0000] {processor.py:186} INFO - Started process (PID=983) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:37:21.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:37:21.738+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:21.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:22.876+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:22.902+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:22.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:37:22.922+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:22.922+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:37:22.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.211 seconds
[2025-12-13T11:37:53.241+0000] {processor.py:186} INFO - Started process (PID=1002) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:37:53.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:37:53.245+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:53.245+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:54.318+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:54.342+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:54.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:37:54.365+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:54.364+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:37:54.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.149 seconds
[2025-12-13T11:38:24.477+0000] {processor.py:186} INFO - Started process (PID=1021) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:38:24.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:38:24.481+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:24.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:38:25.549+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:38:25.571+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:25.571+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:38:25.591+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:25.590+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:38:25.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.136 seconds
[2025-12-13T11:40:08.913+0000] {processor.py:186} INFO - Started process (PID=1034) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:40:08.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:40:08.917+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:40:08.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:38:37.791+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:38:37.815+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:37.814+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:38:37.836+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:37.836+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:38:37.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.142 seconds
[2025-12-13T11:38:41.765+0000] {processor.py:186} INFO - Started process (PID=1053) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:38:41.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:38:41.769+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:41.768+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:38:42.893+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:38:42.914+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:42.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:38:42.932+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:42.932+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:38:42.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.191 seconds
[2025-12-13T11:39:13.162+0000] {processor.py:186} INFO - Started process (PID=1072) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:39:13.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:39:13.166+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:13.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:14.298+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:14.322+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:14.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:39:14.343+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:14.342+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:39:14.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.205 seconds
[2025-12-13T11:39:44.505+0000] {processor.py:186} INFO - Started process (PID=1091) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:39:44.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:39:44.508+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:44.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:45.624+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:45.647+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:45.647+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:39:45.670+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:45.669+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:39:45.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.195 seconds
[2025-12-13T11:41:24.026+0000] {processor.py:186} INFO - Started process (PID=1104) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:41:24.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:41:24.031+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:41:24.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:53.015+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:53.036+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:53.036+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:39:53.055+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:53.054+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:39:53.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.253 seconds
[2025-12-13T11:39:56.863+0000] {processor.py:186} INFO - Started process (PID=1117) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:39:56.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:39:56.867+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:56.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:58.015+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:58.039+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:58.039+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:39:58.060+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:58.060+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:39:58.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.221 seconds
[2025-12-13T11:41:53.372+0000] {processor.py:186} INFO - Started process (PID=1136) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:41:53.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:41:53.376+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:41:53.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:40:22.233+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:40:22.256+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:40:22.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:40:22.277+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:40:22.276+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:40:22.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.186 seconds
[2025-12-13T11:40:52.405+0000] {processor.py:186} INFO - Started process (PID=1155) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:40:52.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:40:52.409+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:40:52.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:40:53.436+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:40:53.458+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:40:53.458+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:40:53.478+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:40:53.478+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:40:53.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.094 seconds
[2025-12-13T11:41:23.727+0000] {processor.py:186} INFO - Started process (PID=1174) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:41:23.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:41:23.731+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:41:23.730+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:41:24.889+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:41:24.913+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:41:24.913+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:41:24.934+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:41:24.934+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:41:24.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.231 seconds
[2025-12-13T11:41:55.845+0000] {processor.py:186} INFO - Started process (PID=1194) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:41:55.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:41:55.848+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:41:55.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:41:56.873+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:41:56.894+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:41:56.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:43:29.107+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:29.106+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:43:20.817+0000] {processor.py:186} INFO - Started process (PID=1225) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:20.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:20.822+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:20.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:22.650+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:22.676+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:22.675+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:43:22.699+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:22.699+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:43:22.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.901 seconds
[2025-12-13T11:43:38.902+0000] {processor.py:186} INFO - Started process (PID=1238) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:38.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:38.908+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:38.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:40.276+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:40.266+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:40.277+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:40.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.403 seconds
[2025-12-13T11:43:40.358+0000] {processor.py:186} INFO - Started process (PID=1251) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:40.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:40.362+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:40.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:41.659+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:41.653+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:41.660+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:41.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.327 seconds
[2025-12-13T11:43:41.734+0000] {processor.py:186} INFO - Started process (PID=1270) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:41.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:41.738+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:41.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:42.790+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:42.784+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:42.791+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:42.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.077 seconds
[2025-12-13T11:43:42.867+0000] {processor.py:186} INFO - Started process (PID=1283) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:42.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:42.871+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:42.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:44.157+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:44.150+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:44.159+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:44.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.321 seconds
[2025-12-13T11:43:44.262+0000] {processor.py:186} INFO - Started process (PID=1296) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:44.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:44.267+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:44.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:45.421+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:45.415+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:45.422+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:45.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.182 seconds
[2025-12-13T11:43:45.487+0000] {processor.py:186} INFO - Started process (PID=1309) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:45.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:45.490+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:45.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:46.760+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:46.750+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:46.762+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:46.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.308 seconds
[2025-12-13T11:43:46.901+0000] {processor.py:186} INFO - Started process (PID=1322) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:46.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:46.909+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:46.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:48.477+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:48.471+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:48.478+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:48.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.612 seconds
[2025-12-13T11:43:48.581+0000] {processor.py:186} INFO - Started process (PID=1335) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:48.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:48.586+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:48.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:49.760+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:49.753+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:49.761+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:49.776+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.204 seconds
[2025-12-13T11:43:49.829+0000] {processor.py:186} INFO - Started process (PID=1348) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:49.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:49.833+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:49.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:50.999+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:50.987+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:51.000+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:51.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.205 seconds
[2025-12-13T11:43:51.079+0000] {processor.py:186} INFO - Started process (PID=1361) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:51.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:51.082+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:51.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:52.209+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:52.204+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:52.210+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:52.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.159 seconds
[2025-12-13T11:43:52.289+0000] {processor.py:186} INFO - Started process (PID=1374) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:52.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:52.293+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:52.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:53.398+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:53.392+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:53.399+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:53.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.132 seconds
[2025-12-13T11:43:53.464+0000] {processor.py:186} INFO - Started process (PID=1387) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:53.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:53.468+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:53.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:54.538+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:54.532+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:54.539+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:54.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.101 seconds
[2025-12-13T11:43:54.619+0000] {processor.py:186} INFO - Started process (PID=1400) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:54.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:54.624+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:54.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:55.671+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:55.666+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:55.672+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:55.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.074 seconds
[2025-12-13T11:43:55.738+0000] {processor.py:186} INFO - Started process (PID=1413) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:55.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:55.742+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:55.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:56.875+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:56.869+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:56.876+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:56.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.164 seconds
[2025-12-13T11:43:56.958+0000] {processor.py:186} INFO - Started process (PID=1426) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:56.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:56.962+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:56.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:58.149+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:58.140+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:58.150+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:58.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.204 seconds
[2025-12-13T11:43:58.219+0000] {processor.py:186} INFO - Started process (PID=1439) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:58.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:58.223+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:58.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:59.388+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:59.382+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:59.389+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:59.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.192 seconds
[2025-12-13T11:43:59.476+0000] {processor.py:186} INFO - Started process (PID=1452) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:59.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:59.480+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:59.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:00.594+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:00.586+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:00.595+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:00.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.143 seconds
[2025-12-13T11:44:00.667+0000] {processor.py:186} INFO - Started process (PID=1465) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:00.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:00.671+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:00.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:01.764+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:01.758+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:01.765+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:01.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.119 seconds
[2025-12-13T11:44:01.831+0000] {processor.py:186} INFO - Started process (PID=1478) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:01.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:01.836+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:01.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:02.849+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:02.843+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:02.850+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:02.864+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.043 seconds
[2025-12-13T11:44:02.918+0000] {processor.py:186} INFO - Started process (PID=1491) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:02.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:02.922+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:02.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:03.980+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:03.974+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:03.981+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:03.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.085 seconds
[2025-12-13T11:44:04.063+0000] {processor.py:186} INFO - Started process (PID=1504) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:04.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:04.066+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:04.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:05.223+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:05.216+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:05.223+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:05.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.181 seconds
[2025-12-13T11:44:05.288+0000] {processor.py:186} INFO - Started process (PID=1517) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:05.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:05.292+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:05.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:06.320+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:06.314+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:06.321+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:06.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.053 seconds
[2025-12-13T11:44:06.395+0000] {processor.py:186} INFO - Started process (PID=1530) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:06.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:06.400+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:06.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:07.514+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:07.508+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:07.515+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:07.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.150 seconds
[2025-12-13T11:44:07.581+0000] {processor.py:186} INFO - Started process (PID=1543) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:07.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:07.585+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:07.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:08.701+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:08.696+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:08.702+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:08.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.144 seconds
[2025-12-13T11:44:08.803+0000] {processor.py:186} INFO - Started process (PID=1556) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:08.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:08.811+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:08.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:09.950+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:09.946+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:09.951+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:09.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.173 seconds
[2025-12-13T11:44:10.019+0000] {processor.py:186} INFO - Started process (PID=1569) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:10.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:10.022+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:10.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:11.199+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:11.193+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:11.200+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:11.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.201 seconds
[2025-12-13T11:44:11.267+0000] {processor.py:186} INFO - Started process (PID=1582) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:11.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:11.271+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:11.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:12.370+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:12.363+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:12.371+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:12.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.122 seconds
[2025-12-13T11:44:12.439+0000] {processor.py:186} INFO - Started process (PID=1601) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:12.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:12.443+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:12.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:13.552+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:13.546+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:13.553+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:13.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.137 seconds
[2025-12-13T11:44:13.623+0000] {processor.py:186} INFO - Started process (PID=1614) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:13.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:13.627+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:13.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:14.744+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:14.738+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:14.745+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:14.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.142 seconds
[2025-12-13T11:44:14.811+0000] {processor.py:186} INFO - Started process (PID=1627) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:14.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:14.815+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:14.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:15.950+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:15.943+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:15.951+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:15.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.165 seconds
[2025-12-13T11:44:16.045+0000] {processor.py:186} INFO - Started process (PID=1640) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:16.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:16.050+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:16.049+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:17.229+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:17.223+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:17.230+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:17.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.209 seconds
[2025-12-13T11:44:17.314+0000] {processor.py:186} INFO - Started process (PID=1653) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:17.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:17.319+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:17.318+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:18.536+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:18.528+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:18.538+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:18.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.256 seconds
[2025-12-13T11:44:18.678+0000] {processor.py:186} INFO - Started process (PID=1666) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:18.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:18.686+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:18.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:19.730+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:19.725+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:19.731+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:19.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.079 seconds
[2025-12-13T11:44:19.796+0000] {processor.py:186} INFO - Started process (PID=1679) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:19.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:19.800+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:19.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:20.910+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:20.904+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:20.911+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:20.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.137 seconds
[2025-12-13T11:44:20.981+0000] {processor.py:186} INFO - Started process (PID=1692) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:20.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:20.985+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:20.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:22.001+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:21.996+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:22.002+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:22.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.042 seconds
[2025-12-13T11:44:22.068+0000] {processor.py:186} INFO - Started process (PID=1705) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:22.069+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:22.071+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:22.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:23.107+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:23.100+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:23.107+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:23.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.064 seconds
[2025-12-13T11:44:23.185+0000] {processor.py:186} INFO - Started process (PID=1718) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:23.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:23.189+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:23.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:24.298+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:24.293+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:24.299+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:24.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.141 seconds
[2025-12-13T11:44:24.383+0000] {processor.py:186} INFO - Started process (PID=1731) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:24.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:24.387+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:24.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:25.551+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:25.546+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:25.552+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:25.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.198 seconds
[2025-12-13T11:44:25.629+0000] {processor.py:186} INFO - Started process (PID=1744) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:25.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:25.633+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:25.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:26.716+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:26.709+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:26.717+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:26.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.116 seconds
[2025-12-13T11:44:26.788+0000] {processor.py:186} INFO - Started process (PID=1757) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:26.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:26.792+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:26.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:27.838+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:27.830+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:27.838+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:27.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.073 seconds
[2025-12-13T11:44:27.905+0000] {processor.py:186} INFO - Started process (PID=1770) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:27.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:27.909+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:27.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:29.092+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:29.086+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:29.093+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:29.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.215 seconds
[2025-12-13T11:44:29.166+0000] {processor.py:186} INFO - Started process (PID=1783) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:29.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:29.170+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:29.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:30.218+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:30.208+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:30.219+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:30.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.074 seconds
[2025-12-13T11:44:30.294+0000] {processor.py:186} INFO - Started process (PID=1796) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:30.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:30.299+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:30.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:31.418+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:31.413+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:31.419+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:31.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.154 seconds
[2025-12-13T11:44:31.494+0000] {processor.py:186} INFO - Started process (PID=1809) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:31.495+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:31.497+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:31.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:32.560+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:32.555+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:32.561+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:32.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.097 seconds
[2025-12-13T11:44:32.630+0000] {processor.py:186} INFO - Started process (PID=1822) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:32.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:32.634+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:32.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:33.748+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:33.741+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:33.749+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:33.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.141 seconds
[2025-12-13T11:44:33.828+0000] {processor.py:186} INFO - Started process (PID=1835) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:33.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:33.832+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:33.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:34.956+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:34.950+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:34.957+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:34.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.152 seconds
[2025-12-13T11:44:35.030+0000] {processor.py:186} INFO - Started process (PID=1848) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:35.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:35.035+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:35.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:36.144+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:36.137+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:36.145+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:36.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.142 seconds
[2025-12-13T11:44:36.218+0000] {processor.py:186} INFO - Started process (PID=1861) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:36.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:36.221+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:36.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:38.035+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:38.029+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:38.036+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:38.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.836 seconds
[2025-12-13T11:44:38.115+0000] {processor.py:186} INFO - Started process (PID=1874) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:38.116+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:38.119+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:38.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:39.398+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:39.391+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:39.399+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:39.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.313 seconds
[2025-12-13T11:44:39.484+0000] {processor.py:186} INFO - Started process (PID=1887) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:39.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:39.488+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:39.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:40.590+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:40.583+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:40.591+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:40.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.139 seconds
[2025-12-13T11:44:40.670+0000] {processor.py:186} INFO - Started process (PID=1900) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:40.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:40.674+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:40.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:41.737+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:41.731+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:41.738+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:41.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.094 seconds
[2025-12-13T11:44:41.817+0000] {processor.py:186} INFO - Started process (PID=1919) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:41.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:41.822+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:41.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:42.893+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:42.888+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:42.894+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:42.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.100 seconds
[2025-12-13T11:44:42.965+0000] {processor.py:186} INFO - Started process (PID=1932) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:42.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:42.969+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:42.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:44.055+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:44.049+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:44.056+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:44.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.119 seconds
[2025-12-13T11:44:44.134+0000] {processor.py:186} INFO - Started process (PID=1945) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:44.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:44.137+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:44.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:45.276+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:45.269+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:45.277+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:45.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.165 seconds
[2025-12-13T11:44:45.350+0000] {processor.py:186} INFO - Started process (PID=1958) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:45.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:45.354+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:45.354+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:46.621+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:46.614+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:46.622+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:46.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.296 seconds
[2025-12-13T11:44:46.697+0000] {processor.py:186} INFO - Started process (PID=1971) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:46.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:46.701+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:46.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:48.028+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:48.017+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:48.029+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:48.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.361 seconds
[2025-12-13T11:44:48.144+0000] {processor.py:186} INFO - Started process (PID=1984) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:48.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:48.151+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:48.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:50.131+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:50.124+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:50.132+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:50.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.058 seconds
[2025-12-13T11:44:50.443+0000] {processor.py:186} INFO - Started process (PID=1997) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:50.444+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:50.449+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:50.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:52.015+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:52.008+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:52.016+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:52.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.584 seconds
[2025-12-13T11:44:52.103+0000] {processor.py:186} INFO - Started process (PID=2010) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:52.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:52.107+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:52.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:53.618+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:53.613+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:53.619+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:53.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.553 seconds
[2025-12-13T11:44:53.687+0000] {processor.py:186} INFO - Started process (PID=2023) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:53.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:53.690+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:53.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:55.011+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:55.003+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:55.012+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:55.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.345 seconds
[2025-12-13T11:44:55.083+0000] {processor.py:186} INFO - Started process (PID=2036) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:55.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:55.086+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:55.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:56.211+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:56.205+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:56.211+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:56.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.149 seconds
[2025-12-13T11:44:56.375+0000] {processor.py:186} INFO - Started process (PID=2049) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:56.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:56.382+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:56.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:57.735+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:57.729+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:57.736+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:57.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.402 seconds
[2025-12-13T11:44:57.812+0000] {processor.py:186} INFO - Started process (PID=2062) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:57.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:57.815+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:57.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:59.416+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:59.406+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:59.417+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:59.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.813 seconds
[2025-12-13T11:44:59.766+0000] {processor.py:186} INFO - Started process (PID=2075) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:59.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:59.770+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:59.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:01.415+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:01.308+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:45:01.416+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:01.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.677 seconds
[2025-12-13T11:45:01.489+0000] {processor.py:186} INFO - Started process (PID=2088) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:01.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:01.493+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:01.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:03.045+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:03.035+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:45:03.047+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:03.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.586 seconds
[2025-12-13T11:45:03.218+0000] {processor.py:186} INFO - Started process (PID=2101) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:03.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:03.227+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:03.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:04.687+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:04.681+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:45:04.688+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:04.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.498 seconds
[2025-12-13T11:45:04.777+0000] {processor.py:186} INFO - Started process (PID=2114) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:04.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:04.781+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:04.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:05.957+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:05.949+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:45:05.959+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:05.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.212 seconds
[2025-12-13T11:45:06.039+0000] {processor.py:186} INFO - Started process (PID=2127) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:06.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:06.043+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:06.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:07.157+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:07.151+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:45:07.158+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:39.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.145 seconds
[2025-12-13T11:45:09.090+0000] {processor.py:186} INFO - Started process (PID=2140) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:09.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:09.095+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:09.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:10.407+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:11.217+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:11.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:11.276+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:11.276+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:11.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.293 seconds
[2025-12-13T11:45:11.567+0000] {processor.py:186} INFO - Started process (PID=2153) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:11.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:11.575+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:11.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:12.975+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:12.986+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:12.986+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:13.006+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:13.006+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:13.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.474 seconds
[2025-12-13T11:45:13.075+0000] {processor.py:186} INFO - Started process (PID=2172) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:13.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:13.078+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:13.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:14.192+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:14.202+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:14.202+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:14.221+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:14.221+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:14.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.168 seconds
[2025-12-13T11:45:14.290+0000] {processor.py:186} INFO - Started process (PID=2185) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:14.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:14.293+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:14.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:15.415+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:15.425+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:15.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:15.446+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:15.446+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:15.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.179 seconds
[2025-12-13T11:45:15.524+0000] {processor.py:186} INFO - Started process (PID=2198) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:15.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:15.527+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:15.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:16.713+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:16.722+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:16.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:16.743+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:16.743+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:16.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.242 seconds
[2025-12-13T11:45:16.815+0000] {processor.py:186} INFO - Started process (PID=2211) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:16.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:16.818+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:16.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:17.769+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:17.782+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:17.782+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:17.976+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:17.976+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:17.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.345 seconds
[2025-12-13T11:45:18.062+0000] {processor.py:186} INFO - Started process (PID=2224) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:18.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:18.065+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:18.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:19.388+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:19.399+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:19.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:19.419+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:19.419+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:19.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.380 seconds
[2025-12-13T11:45:19.489+0000] {processor.py:186} INFO - Started process (PID=2237) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:19.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:19.491+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:19.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:20.661+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:20.672+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:20.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:20.694+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:20.694+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:20.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.228 seconds
[2025-12-13T11:45:20.786+0000] {processor.py:186} INFO - Started process (PID=2250) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:20.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:20.789+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:20.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:21.923+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:21.932+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:21.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:21.949+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:21.949+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:21.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.185 seconds
[2025-12-13T11:45:22.018+0000] {processor.py:186} INFO - Started process (PID=2263) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:22.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:22.021+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:22.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:23.243+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:23.255+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:23.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:23.276+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:23.276+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:23.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.288 seconds
[2025-12-13T11:45:23.348+0000] {processor.py:186} INFO - Started process (PID=2276) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:23.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:23.351+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:23.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:24.591+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:24.604+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:24.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:24.634+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:24.633+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:24.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.319 seconds
[2025-12-13T11:45:24.737+0000] {processor.py:186} INFO - Started process (PID=2289) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:24.738+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:24.740+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:24.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:25.893+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:25.903+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:25.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:25.924+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:25.923+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:25.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.212 seconds
[2025-12-13T11:45:26.000+0000] {processor.py:186} INFO - Started process (PID=2302) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:26.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:26.002+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:26.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:27.307+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:27.317+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:27.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:27.340+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:27.340+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:27.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.362 seconds
[2025-12-13T11:45:27.423+0000] {processor.py:186} INFO - Started process (PID=2315) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:27.424+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:27.425+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:27.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:28.759+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:28.768+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:28.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:28.795+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:28.794+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:28.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.402 seconds
[2025-12-13T11:45:28.889+0000] {processor.py:186} INFO - Started process (PID=2328) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:28.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:28.892+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:28.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:30.556+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:30.572+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:30.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:30.612+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:30.612+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:30.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.766 seconds
[2025-12-13T11:45:30.719+0000] {processor.py:186} INFO - Started process (PID=2341) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:30.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:30.724+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:30.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:32.446+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:32.462+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:32.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:32.495+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:32.495+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:32.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.801 seconds
[2025-12-13T11:45:32.577+0000] {processor.py:186} INFO - Started process (PID=2354) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:32.578+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:32.579+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:32.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:33.832+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:33.847+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:33.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:33.874+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:33.873+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:33.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.333 seconds
[2025-12-13T11:45:33.972+0000] {processor.py:186} INFO - Started process (PID=2367) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:33.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:33.975+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:33.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:35.514+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:35.525+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:35.525+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:35.546+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:35.546+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:35.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.597 seconds
[2025-12-13T11:45:35.622+0000] {processor.py:186} INFO - Started process (PID=2380) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:35.623+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:35.625+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:35.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:37.322+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:37.332+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:37.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:37.355+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:37.355+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:37.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.760 seconds
[2025-12-13T11:45:37.426+0000] {processor.py:186} INFO - Started process (PID=2393) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:37.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:37.429+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:37.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:39.711+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:39.721+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:39.721+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:39.741+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:39.741+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:39.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.340 seconds
[2025-12-13T11:45:39.822+0000] {processor.py:186} INFO - Started process (PID=2406) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:39.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:39.825+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:39.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:40.965+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:40.988+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:40.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:41.006+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:41.006+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:41.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.205 seconds
[2025-12-13T11:45:41.078+0000] {processor.py:186} INFO - Started process (PID=2419) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:41.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:41.081+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:41.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:42.352+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:42.376+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:42.375+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:42.394+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:42.394+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:42.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.339 seconds
[2025-12-13T11:45:42.465+0000] {processor.py:186} INFO - Started process (PID=2438) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:42.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:42.467+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:42.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:43.668+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:43.692+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:43.692+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:43.716+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:43.715+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:43.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.280 seconds
[2025-12-13T11:45:43.794+0000] {processor.py:186} INFO - Started process (PID=2451) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:43.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:43.796+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:43.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:44.992+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:45.016+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:45.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:45.035+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:45.035+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:45.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.269 seconds
[2025-12-13T11:45:45.110+0000] {processor.py:186} INFO - Started process (PID=2464) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:45.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:45.112+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:45.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:46.302+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:46.323+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:46.323+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:46.342+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:46.342+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:46.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.255 seconds
[2025-12-13T11:45:46.414+0000] {processor.py:186} INFO - Started process (PID=2477) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:46.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:46.417+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:46.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:47.638+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:47.667+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:47.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:47.688+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:47.688+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:47.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.316 seconds
[2025-12-13T11:45:47.785+0000] {processor.py:186} INFO - Started process (PID=2490) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:47.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:47.787+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:47.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:50.126+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:50.155+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:50.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:50.177+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:50.176+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:50.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.414 seconds
[2025-12-13T11:45:50.247+0000] {processor.py:186} INFO - Started process (PID=2503) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:50.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:50.250+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:50.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:51.598+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:51.622+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:51.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:51.641+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:51.641+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:51.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.420 seconds
[2025-12-13T11:45:51.730+0000] {processor.py:186} INFO - Started process (PID=2516) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:51.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:51.732+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:51.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:40.743+0000] {processor.py:186} INFO - Started process (PID=2534) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:40.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:40.746+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:40.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:42.003+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:42.097+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:42.096+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:42.118+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:42.117+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:42.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.415 seconds
[2025-12-13T11:46:42.217+0000] {processor.py:186} INFO - Started process (PID=2553) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:42.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:42.219+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:42.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:43.313+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:43.322+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:43.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:43.340+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:43.340+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:43.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.153 seconds
[2025-12-13T11:46:43.413+0000] {processor.py:186} INFO - Started process (PID=2566) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:43.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:43.415+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:43.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:44.902+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:44.921+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:44.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:44.964+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:44.964+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:45.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.605 seconds
[2025-12-13T11:46:45.134+0000] {processor.py:186} INFO - Started process (PID=2579) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:45.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:45.146+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:45.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:46.700+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:46.710+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:46.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:46.729+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:46.729+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:46.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.623 seconds
[2025-12-13T11:46:46.890+0000] {processor.py:186} INFO - Started process (PID=2592) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:46.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:46.893+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:46.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:48.018+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:48.027+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:48.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:48.046+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:48.046+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:48.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.177 seconds
[2025-12-13T11:46:48.113+0000] {processor.py:186} INFO - Started process (PID=2605) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:48.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:48.116+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:48.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:49.243+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:49.253+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:49.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:49.274+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:49.273+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:49.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.182 seconds
[2025-12-13T11:46:49.341+0000] {processor.py:186} INFO - Started process (PID=2618) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:49.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:49.344+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:49.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:50.391+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:50.400+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:50.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:50.419+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:50.418+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:50.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.106 seconds
[2025-12-13T11:46:50.501+0000] {processor.py:186} INFO - Started process (PID=2631) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:50.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:50.503+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:50.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:51.622+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:51.632+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:51.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:51.651+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:51.651+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:51.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.188 seconds
[2025-12-13T11:46:51.727+0000] {processor.py:186} INFO - Started process (PID=2644) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:51.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:51.729+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:51.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:52.785+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:52.794+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:52.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:52.814+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:52.813+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:52.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.107 seconds
[2025-12-13T11:46:52.892+0000] {processor.py:186} INFO - Started process (PID=2657) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:52.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:52.895+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:52.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:53.973+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:53.982+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:53.982+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:54.001+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:54.000+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:54.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.132 seconds
[2025-12-13T11:46:54.072+0000] {processor.py:186} INFO - Started process (PID=2670) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:54.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:54.074+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:54.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:55.119+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:55.127+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:55.127+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:55.145+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:55.145+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:55.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.095 seconds
[2025-12-13T11:46:55.213+0000] {processor.py:186} INFO - Started process (PID=2683) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:55.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:55.216+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:55.215+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:56.220+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:56.228+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:56.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:56.246+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:56.246+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:56.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.055 seconds
[2025-12-13T11:46:56.317+0000] {processor.py:186} INFO - Started process (PID=2696) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:56.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:56.319+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:56.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:29.543+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:29.566+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:29.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:29.584+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:29.584+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:57.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.085 seconds
[2025-12-13T11:46:57.450+0000] {processor.py:186} INFO - Started process (PID=2709) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:57.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:57.452+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:57.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:58.488+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:58.497+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:58.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:58.516+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:58.516+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:58.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.096 seconds
[2025-12-13T11:46:58.594+0000] {processor.py:186} INFO - Started process (PID=2722) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:58.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:58.597+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:58.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:59.783+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:59.795+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:59.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:59.815+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:59.815+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:59.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.244 seconds
[2025-12-13T11:46:59.884+0000] {processor.py:186} INFO - Started process (PID=2735) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:59.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:59.886+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:59.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:01.485+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:01.503+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:01.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:01.532+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:01.531+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:01.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.681 seconds
[2025-12-13T11:47:01.630+0000] {processor.py:186} INFO - Started process (PID=2748) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:01.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:01.633+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:01.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:03.591+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:03.602+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:03.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:03.627+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:03.626+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:03.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.024 seconds
[2025-12-13T11:47:03.702+0000] {processor.py:186} INFO - Started process (PID=2761) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:03.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:03.705+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:03.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:04.879+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:04.890+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:04.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:04.911+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:04.911+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:04.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.232 seconds
[2025-12-13T11:47:04.981+0000] {processor.py:186} INFO - Started process (PID=2774) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:04.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:04.984+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:04.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:06.136+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:06.145+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:06.145+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:06.164+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:06.164+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:06.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.206 seconds
[2025-12-13T11:47:06.234+0000] {processor.py:186} INFO - Started process (PID=2787) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:06.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:06.237+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:06.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:39.552+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:39.575+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:39.575+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:39.592+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:39.592+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:39.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.179 seconds
[2025-12-13T11:47:51.304+0000] {processor.py:186} INFO - Started process (PID=2812) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:51.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:51.308+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:51.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:52.545+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:52.568+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:52.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:52.588+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:52.587+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:52.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.323 seconds
[2025-12-13T11:47:52.662+0000] {processor.py:186} INFO - Started process (PID=2825) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:52.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:52.664+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:52.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:53.758+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:53.855+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:53.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:53.872+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:53.872+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:53.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.234 seconds
[2025-12-13T11:47:53.942+0000] {processor.py:186} INFO - Started process (PID=2838) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:53.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:53.944+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:53.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:55.071+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:55.081+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:55.081+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:55.102+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:55.102+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:55.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.192 seconds
[2025-12-13T11:47:55.183+0000] {processor.py:186} INFO - Started process (PID=2851) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:55.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:55.185+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:55.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:56.215+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:56.224+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:56.224+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:56.244+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:56.243+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:56.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.084 seconds
[2025-12-13T11:47:56.318+0000] {processor.py:186} INFO - Started process (PID=2864) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:56.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:56.320+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:56.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:57.355+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:57.364+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:57.364+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:57.382+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:57.382+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:57.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.086 seconds
[2025-12-13T11:49:29.651+0000] {processor.py:186} INFO - Started process (PID=2877) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:49:29.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:49:29.654+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:49:29.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:58.559+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:58.568+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:58.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:58.587+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:58.587+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:58.610+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.179 seconds
[2025-12-13T11:47:58.664+0000] {processor.py:186} INFO - Started process (PID=2890) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:58.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:58.666+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:58.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:59.756+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:59.768+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:59.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:59.798+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:59.798+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:59.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.160 seconds
[2025-12-13T11:47:59.876+0000] {processor.py:186} INFO - Started process (PID=2903) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:59.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:59.879+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:59.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:01.787+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:01.799+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:01.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:01.821+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:01.821+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:01.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.973 seconds
[2025-12-13T11:48:01.922+0000] {processor.py:186} INFO - Started process (PID=2916) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:01.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:01.926+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:01.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:03.688+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:03.699+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:03.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:03.723+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:03.723+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:03.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.825 seconds
[2025-12-13T11:48:03.817+0000] {processor.py:186} INFO - Started process (PID=2929) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:03.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:03.820+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:03.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:05.341+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:05.355+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:05.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:05.386+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:05.386+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:05.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.615 seconds
[2025-12-13T11:48:05.517+0000] {processor.py:186} INFO - Started process (PID=2942) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:05.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:05.520+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:05.519+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:07.303+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:07.313+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:07.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:07.335+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:07.334+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:07.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.846 seconds
[2025-12-13T11:48:07.418+0000] {processor.py:186} INFO - Started process (PID=2955) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:07.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:07.423+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:07.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:10.078+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:10.094+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:10.094+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:10.125+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:10.124+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:10.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.747 seconds
[2025-12-13T11:48:10.219+0000] {processor.py:186} INFO - Started process (PID=2968) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:10.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:10.222+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:10.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:11.356+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:11.365+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:11.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:11.386+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:11.386+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:11.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.191 seconds
[2025-12-13T11:48:11.461+0000] {processor.py:186} INFO - Started process (PID=2981) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:11.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:11.464+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:11.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:49:44.764+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:12.591+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:12.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:12.610+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:12.610+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:12.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.161 seconds
[2025-12-13T11:48:12.678+0000] {processor.py:186} INFO - Started process (PID=3000) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:12.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:12.680+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:12.680+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:13.714+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:13.723+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:13.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:13.741+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:13.741+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:13.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.086 seconds
[2025-12-13T11:48:13.811+0000] {processor.py:186} INFO - Started process (PID=3013) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:13.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:13.813+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:13.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:14.850+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:14.859+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:14.859+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:14.877+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:14.877+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:14.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.090 seconds
[2025-12-13T11:48:14.947+0000] {processor.py:186} INFO - Started process (PID=3026) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:14.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:14.949+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:14.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:16.029+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:16.039+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:16.039+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:16.058+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:16.058+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:16.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.137 seconds
[2025-12-13T11:48:16.134+0000] {processor.py:186} INFO - Started process (PID=3039) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:16.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:16.137+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:16.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:17.159+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:17.168+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:17.168+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:17.187+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:17.187+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:17.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.080 seconds
[2025-12-13T11:48:17.263+0000] {processor.py:186} INFO - Started process (PID=3052) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:17.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:17.266+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:17.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:18.350+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:18.360+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:18.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:18.383+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:18.383+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:18.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.166 seconds
[2025-12-13T11:48:18.480+0000] {processor.py:186} INFO - Started process (PID=3065) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:18.482+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:18.483+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:18.483+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:20.450+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:20.460+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:20.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:20.481+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:20.481+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:20.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.030 seconds
[2025-12-13T11:48:20.557+0000] {processor.py:186} INFO - Started process (PID=3078) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:20.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:20.560+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:20.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:21.693+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:21.703+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:21.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:21.727+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:21.727+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:21.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.188 seconds
[2025-12-13T11:48:21.805+0000] {processor.py:186} INFO - Started process (PID=3091) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:21.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:21.808+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:21.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:22.945+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:22.955+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:22.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:22.979+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:22.979+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:22.999+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.202 seconds
[2025-12-13T11:48:23.067+0000] {processor.py:186} INFO - Started process (PID=3104) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:23.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:23.070+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:23.069+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:24.160+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:24.180+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:24.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:24.201+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:24.201+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:24.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.166 seconds
[2025-12-13T11:48:24.278+0000] {processor.py:186} INFO - Started process (PID=3117) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:24.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:24.280+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:24.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:25.421+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:25.443+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:25.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:25.462+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:25.461+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:25.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.206 seconds
[2025-12-13T11:48:25.531+0000] {processor.py:186} INFO - Started process (PID=3130) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:25.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:25.533+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:25.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:26.688+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:26.710+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:26.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:26.730+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:26.730+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:26.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.221 seconds
[2025-12-13T11:48:26.803+0000] {processor.py:186} INFO - Started process (PID=3143) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:26.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:26.805+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:26.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:46.765+0000] {processor.py:186} INFO - Started process (PID=3162) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:46.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:46.768+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:46.768+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:47.832+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:47.854+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:47.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:47.877+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:47.877+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:47.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.165 seconds
[2025-12-13T11:48:47.962+0000] {processor.py:186} INFO - Started process (PID=3175) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:47.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:47.966+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:47.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:49.210+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:49.233+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:49.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:49.257+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:49.257+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:49.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.320 seconds
[2025-12-13T11:48:49.332+0000] {processor.py:186} INFO - Started process (PID=3188) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:49.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:49.335+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:49.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:50.417+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:50.438+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:50.438+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:50.459+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:50.459+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:50.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.156 seconds
[2025-12-13T11:48:50.535+0000] {processor.py:186} INFO - Started process (PID=3201) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:50.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:50.538+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:50.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:51.647+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:51.672+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:51.672+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:51.698+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:51.697+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:51.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.188 seconds
[2025-12-13T11:48:51.782+0000] {processor.py:186} INFO - Started process (PID=3214) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:51.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:51.789+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:51.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:50:54.919+0000] {processor.py:186} INFO - Started process (PID=3251) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:50:54.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:50:54.921+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:50:54.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:50:56.356+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:50:56.381+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:50:56.381+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:50:56.406+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:50:56.406+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:50:56.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.522 seconds
[2025-12-13T11:51:26.760+0000] {processor.py:186} INFO - Started process (PID=3270) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:51:26.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:51:26.763+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:51:26.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:00:46.752+0000] {processor.py:186} INFO - Started process (PID=536) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:00:46.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:00:46.758+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:00:46.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:00:47.510+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:00:47.531+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:00:47.531+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:00:47.543+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:00:47.543+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:00:47.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.806 seconds
[2025-12-13T15:01:17.907+0000] {processor.py:186} INFO - Started process (PID=547) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:01:17.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:01:17.914+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:01:17.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:01:18.885+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:01:18.912+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:01:18.911+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:01:18.927+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:01:18.927+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:01:18.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.039 seconds
[2025-12-13T15:03:47.118+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:03:47.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:03:47.127+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:03:47.127+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:03:50.148+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:03:50.191+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:03:50.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:03:50.210+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:03:50.210+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:03:50.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.127 seconds
[2025-12-13T15:04:20.516+0000] {processor.py:186} INFO - Started process (PID=42) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:04:20.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:04:20.537+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:04:20.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:04:25.585+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:04:25.754+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:04:25.754+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:04:25.774+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:04:25.773+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:04:25.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 5.349 seconds
[2025-12-13T15:04:58.558+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:04:58.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:04:58.754+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:04:58.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:05:10.818+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:05:10.917+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:05:10.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:05:10.944+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:05:10.944+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:05:10.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 12.635 seconds
[2025-12-13T15:05:41.839+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:05:41.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:05:42.009+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:05:41.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:06:01.799+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:06:01.863+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:06:01.863+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:06:01.897+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:06:01.897+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:06:01.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 20.365 seconds
[2025-12-13T15:06:32.877+0000] {processor.py:186} INFO - Started process (PID=87) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:06:32.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:06:32.957+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:06:32.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:06:37.124+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:06:37.142+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:06:37.141+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:06:37.155+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:06:37.155+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:06:37.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 4.419 seconds
[2025-12-13T15:07:07.389+0000] {processor.py:186} INFO - Started process (PID=99) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:07:07.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:07:07.394+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:07:07.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:07:08.404+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:07:08.423+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:07:08.423+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:07:08.439+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:07:08.439+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:07:08.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.072 seconds
[2025-12-13T15:07:38.586+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:07:38.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:07:38.592+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:07:38.591+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:07:40.212+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:07:40.239+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:07:40.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:07:40.256+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:07:40.256+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:07:40.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.740 seconds
[2025-12-13T15:08:07.435+0000] {processor.py:186} INFO - Started process (PID=121) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:08:07.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:08:07.592+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:08:07.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:08:23.599+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:08:24.498+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:08:24.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:08:24.558+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:08:24.558+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:08:24.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 17.365 seconds
[2025-12-13T15:08:56.358+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:08:56.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:08:56.520+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:08:56.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:09:13.892+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:09:13.925+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:09:13.925+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:09:13.950+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:09:13.950+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:09:13.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 17.884 seconds
[2025-12-13T15:09:44.543+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:09:44.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:09:44.607+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:09:44.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:09:48.634+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:09:48.741+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:09:48.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:09:48.885+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:09:48.882+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:09:48.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 4.497 seconds
[2025-12-13T15:10:19.384+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:10:19.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:10:19.388+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:10:19.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:10:20.150+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:10:20.165+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:10:20.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:10:20.176+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:10:20.176+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:10:20.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.807 seconds
[2025-12-13T15:10:50.797+0000] {processor.py:186} INFO - Started process (PID=182) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:10:50.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:10:50.815+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:10:50.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:10:53.243+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:10:53.281+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:10:53.281+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:10:53.305+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:10:53.304+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:10:53.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.545 seconds
[2025-12-13T15:11:23.724+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:11:23.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:11:23.730+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:11:23.730+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:11:24.441+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:11:24.454+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:11:24.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:11:24.464+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:11:24.464+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:11:24.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.760 seconds
[2025-12-13T15:11:54.847+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:11:54.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:11:54.851+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:11:54.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:11:55.387+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:11:55.399+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:11:55.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:11:55.408+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:11:55.408+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:11:55.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.574 seconds
[2025-12-13T15:12:25.740+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:12:25.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:12:25.744+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:12:25.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:12:26.362+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:12:26.375+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:12:26.375+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:12:26.384+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:12:26.383+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:12:26.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.658 seconds
[2025-12-13T15:12:54.674+0000] {processor.py:186} INFO - Started process (PID=226) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:12:54.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:12:54.676+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:12:54.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:12:55.221+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:12:55.233+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:12:55.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:12:55.243+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:12:55.243+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:12:55.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.585 seconds
[2025-12-13T15:12:59.017+0000] {processor.py:186} INFO - Started process (PID=231) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:12:59.018+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:12:59.020+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:12:59.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:12:59.542+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:12:59.553+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:12:59.553+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:12:59.561+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:12:59.561+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:12:59.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.559 seconds
[2025-12-13T15:13:29.897+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:13:29.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:13:29.900+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:13:29.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:13:30.540+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:13:30.551+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:13:30.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:13:30.561+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:13:30.561+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:13:30.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.677 seconds
[2025-12-13T15:14:00.909+0000] {processor.py:186} INFO - Started process (PID=263) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:14:00.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:14:00.914+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:14:00.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:14:01.628+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:14:01.641+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:14:01.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:14:01.651+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:14:01.651+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:14:01.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.758 seconds
[2025-12-13T15:14:32.051+0000] {processor.py:186} INFO - Started process (PID=274) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:14:32.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:14:32.055+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:14:32.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:14:32.697+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:14:32.710+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:14:32.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:14:32.720+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:14:32.720+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:14:32.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.686 seconds
[2025-12-13T15:14:38.224+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:14:38.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:14:38.228+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:14:38.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:14:38.786+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:14:38.781+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 27, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:14:38.786+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:14:38.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.580 seconds
[2025-12-13T15:14:43.894+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:14:43.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:14:43.897+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:14:43.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:14:44.423+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:14:44.422+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 27, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:14:44.424+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:14:44.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.545 seconds
[2025-12-13T15:15:14.810+0000] {processor.py:186} INFO - Started process (PID=301) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:15:14.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:15:14.818+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:15:14.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:15:15.549+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:15:15.548+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 27, in <module>
    import sys
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:15:15.550+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:15:15.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.759 seconds
[2025-12-13T15:15:16.281+0000] {processor.py:186} INFO - Started process (PID=306) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:15:16.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:15:16.285+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:15:16.285+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:15:16.929+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:15:16.927+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:15:16.929+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:15:16.938+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.665 seconds
[2025-12-13T15:15:47.329+0000] {processor.py:186} INFO - Started process (PID=317) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:15:47.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:15:47.333+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:15:47.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:15:48.066+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:15:48.065+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:15:48.067+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:15:48.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.755 seconds
[2025-12-13T15:16:08.498+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:16:08.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:16:08.500+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:16:08.500+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:16:09.240+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:16:09.239+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:16:09.241+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:16:09.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.757 seconds
[2025-12-13T15:16:33.749+0000] {processor.py:186} INFO - Started process (PID=42) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:16:33.750+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:16:33.753+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:16:33.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:16:34.664+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:16:34.722+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:16:34.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:16:34.731+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:16:34.731+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:16:34.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.999 seconds
[2025-12-13T15:17:05.045+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:17:05.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:17:05.050+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:17:05.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:17:06.379+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:17:06.428+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:17:06.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:17:06.448+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:17:06.447+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:17:06.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.418 seconds
[2025-12-13T15:17:36.793+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:17:36.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:17:36.798+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:17:36.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:17:37.896+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:17:37.910+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:17:37.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:17:37.921+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:17:37.920+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:17:37.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.144 seconds
[2025-12-13T15:18:08.141+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:18:08.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:18:08.150+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:18:08.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:18:09.117+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:18:09.132+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:18:09.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:18:09.144+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:18:09.144+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:18:09.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.016 seconds
[2025-12-13T15:18:39.657+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:18:39.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:18:39.663+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:18:39.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:18:40.501+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:18:40.514+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:18:40.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:18:40.528+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:18:40.528+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:18:40.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.888 seconds
[2025-12-13T15:19:11.000+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:19:11.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:19:11.014+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:19:11.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:19:11.962+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:19:11.980+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:19:11.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:19:11.994+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:19:11.994+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:19:12.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.016 seconds
[2025-12-13T15:19:27.246+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:19:27.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:19:27.252+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:19:27.251+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:19:28.163+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:19:28.161+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:19:28.164+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:19:28.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.944 seconds
[2025-12-13T15:19:58.541+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:19:58.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:19:58.546+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:19:58.545+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:19:59.553+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:19:59.552+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:19:59.554+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:19:59.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.032 seconds
[2025-12-13T15:20:29.931+0000] {processor.py:186} INFO - Started process (PID=134) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:20:29.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:20:29.938+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:20:29.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:20:30.760+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:20:30.758+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:20:30.760+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:20:30.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.848 seconds
[2025-12-13T15:21:01.326+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:21:01.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:21:01.331+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:21:01.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:21:02.095+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:21:02.094+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:21:02.096+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:21:02.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.791 seconds
[2025-12-13T15:21:19.326+0000] {processor.py:186} INFO - Started process (PID=155) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:21:19.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:21:19.328+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:21:19.327+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:21:20.411+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:21:20.408+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:21:20.411+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:21:20.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.106 seconds
[2025-12-13T15:21:40.640+0000] {processor.py:186} INFO - Started process (PID=166) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:21:40.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:21:40.644+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:21:40.643+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:21:41.731+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:21:41.729+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:21:41.732+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:21:41.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.172 seconds
[2025-12-13T15:21:46.782+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:21:46.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:21:46.785+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:21:46.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:21:47.830+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:21:47.955+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:21:47.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T15:21:47.967+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:21:47.967+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T15:21:47.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.217 seconds
[2025-12-13T15:21:58.732+0000] {processor.py:186} INFO - Started process (PID=186) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:21:58.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:21:58.749+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:21:58.747+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:22:02.800+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:22:02.797+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:22:02.801+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:22:02.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 4.109 seconds
[2025-12-13T15:22:03.844+0000] {processor.py:186} INFO - Started process (PID=197) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:22:03.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:22:03.857+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:22:03.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:22:06.478+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:22:06.476+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:22:06.479+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:22:06.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.676 seconds
[2025-12-13T15:22:21.037+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:22:21.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:22:21.047+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:22:21.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:22:21.945+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:22:21.943+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:22:21.946+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:22:21.956+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.928 seconds
[2025-12-13T15:22:52.291+0000] {processor.py:186} INFO - Started process (PID=213) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:22:52.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:22:52.296+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:22:52.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:22:53.134+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:22:53.133+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:22:53.135+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:22:53.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.862 seconds
[2025-12-13T15:23:23.378+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:23:23.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:23:23.382+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:23:23.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:23:24.319+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:23:24.317+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:23:24.319+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:23:24.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.961 seconds
[2025-12-13T15:23:54.819+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:23:54.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:23:54.822+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:23:54.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:23:55.654+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:23:55.653+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:23:55.655+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:23:55.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.860 seconds
[2025-12-13T15:24:26.100+0000] {processor.py:186} INFO - Started process (PID=246) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:24:26.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:24:26.107+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:24:26.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:24:26.932+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:24:26.930+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:24:26.932+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:24:26.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.850 seconds
[2025-12-13T15:24:57.432+0000] {processor.py:186} INFO - Started process (PID=257) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:24:57.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:24:57.436+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:24:57.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:24:58.305+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:24:58.304+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:24:58.306+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:24:58.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.898 seconds
[2025-12-13T15:25:28.741+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:25:28.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:25:28.745+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:25:28.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:25:29.589+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:25:29.587+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:25:29.589+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:25:29.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.869 seconds
[2025-12-13T15:26:00.043+0000] {processor.py:186} INFO - Started process (PID=279) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:26:00.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:26:00.047+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:26:00.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:26:00.895+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:26:00.893+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:26:00.895+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:26:00.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.872 seconds
[2025-12-13T15:26:31.306+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:26:31.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:26:31.309+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:26:31.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:26:31.972+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:26:31.970+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:26:31.972+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:26:31.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.685 seconds
[2025-12-13T15:27:02.420+0000] {processor.py:186} INFO - Started process (PID=301) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:27:02.425+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:27:02.429+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:27:02.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:27:03.321+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:27:03.320+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:27:03.322+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:27:03.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.919 seconds
[2025-12-13T15:27:33.776+0000] {processor.py:186} INFO - Started process (PID=318) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:27:33.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:27:33.779+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:27:33.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:27:34.539+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:27:34.537+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:27:34.539+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:27:34.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.783 seconds
[2025-12-13T15:28:05.015+0000] {processor.py:186} INFO - Started process (PID=329) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:28:05.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:28:05.019+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:28:05.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:28:05.774+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:28:05.772+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:28:05.774+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:28:05.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.784 seconds
[2025-12-13T15:28:36.187+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:28:36.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:28:36.192+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:28:36.191+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:28:36.942+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:28:36.941+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:28:36.943+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:28:36.956+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.776 seconds
[2025-12-13T15:29:07.334+0000] {processor.py:186} INFO - Started process (PID=357) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:29:07.337+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:29:07.339+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:29:07.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:29:08.198+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:29:08.196+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:29:08.198+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:29:08.210+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.890 seconds
[2025-12-13T15:29:38.544+0000] {processor.py:186} INFO - Started process (PID=380) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:29:38.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:29:38.549+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:29:38.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:29:39.330+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:29:39.327+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:29:39.332+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:29:39.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.816 seconds
[2025-12-13T15:30:09.547+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:30:09.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:30:09.552+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:30:09.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:30:10.596+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:30:10.594+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:30:10.597+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:30:10.610+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.073 seconds
[2025-12-13T15:30:40.907+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/airflow.py
[2025-12-13T15:30:40.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T15:30:40.912+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:30:40.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T15:30:41.685+0000] {logging_mixin.py:190} INFO - [2025-12-13T15:30:41.684+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 22, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2025-12-13T15:30:41.686+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T15:30:41.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.807 seconds
[2025-12-13T16:12:07.075+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:12:07.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:12:07.169+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:12:07.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:12:28.327+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:12:29.571+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:12:29.543+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:stock_portfolio_pipeline_datafrogs
[2025-12-13T16:12:29.644+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:12:29.637+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:stock_portfolio_pipeline_datafrogs
[2025-12-13T16:12:29.676+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:12:29.675+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:stock_portfolio_pipeline_datafrogs
[2025-12-13T16:12:29.688+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:12:29.685+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:stock_portfolio_pipeline_datafrogs
[2025-12-13T16:12:29.696+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:12:29.693+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:stock_portfolio_pipeline_datafrogs
[2025-12-13T16:12:29.701+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:12:29.700+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:stock_portfolio_pipeline_datafrogs
[2025-12-13T16:12:29.724+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:12:29.724+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:stock_portfolio_pipeline_datafrogs
[2025-12-13T16:12:29.725+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:12:29.725+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:12:29.801+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:12:29.797+0000] {dag.py:3262} INFO - Creating ORM DAG for stock_portfolio_pipeline_datafrogs
[2025-12-13T16:12:29.918+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:12:29.917+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-12 00:00:00+00:00, run_after=2025-12-13 00:00:00+00:00
[2025-12-13T16:12:30.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 23.245 seconds
[2025-12-13T16:13:01.634+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:13:01.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:13:01.906+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:13:01.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:13:09.840+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:13:10.055+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:13:10.055+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:13:10.155+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:13:10.155+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-12 00:00:00+00:00, run_after=2025-12-13 00:00:00+00:00
[2025-12-13T16:13:10.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 8.948 seconds
[2025-12-13T16:13:41.201+0000] {processor.py:186} INFO - Started process (PID=65) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:13:41.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:13:41.294+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:13:41.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:13:48.155+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:13:48.295+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:13:48.294+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:13:48.417+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:13:48.417+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-12 00:00:00+00:00, run_after=2025-12-13 00:00:00+00:00
[2025-12-13T16:13:48.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 7.387 seconds
[2025-12-13T16:14:18.968+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:14:18.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:14:19.041+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:14:19.037+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:14:31.933+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:14:32.110+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:14:32.109+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:14:32.143+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:14:32.143+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-12 00:00:00+00:00, run_after=2025-12-13 00:00:00+00:00
[2025-12-13T16:14:32.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 13.334 seconds
[2025-12-13T16:15:04.532+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:15:04.594+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:15:05.039+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:15:04.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:15:24.227+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:15:24.308+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:15:24.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:15:24.357+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:15:24.357+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:15:24.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 20.175 seconds
[2025-12-13T16:15:56.159+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:15:56.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:15:56.641+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:15:56.605+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:16:08.425+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:16:08.479+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:16:08.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:16:08.500+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:16:08.500+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:16:08.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 12.682 seconds
[2025-12-13T16:16:39.200+0000] {processor.py:186} INFO - Started process (PID=121) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:16:39.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:16:39.292+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:16:39.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:16:42.706+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:16:42.727+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:16:42.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:16:42.739+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:16:42.739+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:16:42.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.667 seconds
[2025-12-13T16:17:13.697+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:17:13.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:17:13.787+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:17:13.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:17:19.473+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:17:19.521+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:17:19.521+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:17:19.544+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:17:19.543+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:17:19.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 6.076 seconds
[2025-12-13T16:17:53.057+0000] {processor.py:186} INFO - Started process (PID=149) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:17:53.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:17:53.127+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:17:53.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:18:05.447+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:18:05.492+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:18:05.492+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:18:05.522+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:18:05.522+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:18:05.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 13.147 seconds
[2025-12-13T16:18:35.951+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:18:35.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:18:35.970+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:18:35.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:18:37.785+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:18:37.810+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:18:37.810+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:18:37.825+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:18:37.825+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:18:37.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.914 seconds
[2025-12-13T16:19:08.059+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:19:08.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:19:08.063+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:19:08.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:19:11.589+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:19:11.698+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:19:11.697+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:19:11.710+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:19:11.710+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:19:11.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.660 seconds
[2025-12-13T16:19:42.277+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:19:42.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:19:42.288+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:19:42.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:19:44.517+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:19:44.552+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:19:44.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:19:44.568+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:19:44.568+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:19:44.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.328 seconds
[2025-12-13T16:20:15.258+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:20:15.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:20:15.299+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:20:15.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:20:31.387+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:20:31.504+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:20:31.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:20:31.680+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:20:31.679+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:20:31.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 16.695 seconds
[2025-12-13T16:21:03.927+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:21:03.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:21:04.153+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:21:04.138+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:21:31.285+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:21:31.515+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:21:31.511+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:21:31.594+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:21:31.593+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:21:31.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 27.929 seconds
[2025-12-13T16:22:03.144+0000] {processor.py:186} INFO - Started process (PID=237) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:22:03.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:22:03.275+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:22:03.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:22:10.641+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:22:10.672+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:22:10.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:22:10.694+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:22:10.694+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:22:10.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 7.739 seconds
[2025-12-13T16:22:41.842+0000] {processor.py:186} INFO - Started process (PID=248) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:22:41.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:22:41.951+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:22:41.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:22:57.067+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:22:57.100+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:22:57.099+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:22:57.179+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:22:57.179+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:22:57.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 15.652 seconds
[2025-12-13T16:23:29.629+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:23:29.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:23:30.350+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:23:30.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:24:01.238+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:24:01.338+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:24:01.337+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:24:01.391+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:24:01.390+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:24:01.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 32.608 seconds
[2025-12-13T16:24:32.444+0000] {processor.py:186} INFO - Started process (PID=287) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:24:32.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:24:32.518+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:24:32.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:24:41.518+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:24:41.555+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:24:41.554+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:24:41.608+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:24:41.607+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:24:41.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 9.256 seconds
[2025-12-13T16:25:12.672+0000] {processor.py:186} INFO - Started process (PID=297) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:25:12.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:25:12.749+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:25:12.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:25:18.768+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:25:18.795+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:25:18.795+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:25:18.821+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:25:18.820+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:25:18.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 6.251 seconds
[2025-12-13T16:25:50.114+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:25:50.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:25:50.253+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:25:50.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:25:57.879+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:25:57.907+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:25:57.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:25:57.921+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:25:57.921+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:25:57.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 8.053 seconds
[2025-12-13T16:26:29.213+0000] {processor.py:186} INFO - Started process (PID=325) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:26:29.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:26:29.266+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:26:29.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:26:32.382+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:26:32.404+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:26:32.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:26:32.418+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:26:32.418+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:26:32.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.305 seconds
[2025-12-13T16:27:02.911+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:27:02.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:27:02.924+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:27:02.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:27:05.603+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:27:05.626+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:27:05.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:27:05.646+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:27:05.646+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:27:05.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.835 seconds
[2025-12-13T16:27:35.869+0000] {processor.py:186} INFO - Started process (PID=347) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:27:35.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:27:35.873+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:27:35.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:27:37.731+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:27:37.769+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:27:37.769+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:27:37.794+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:27:37.794+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:27:37.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.988 seconds
[2025-12-13T16:28:08.195+0000] {processor.py:186} INFO - Started process (PID=358) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:28:08.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:28:08.208+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:28:08.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:28:12.247+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:28:12.338+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:28:12.337+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:28:12.384+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:28:12.383+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:28:12.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 4.235 seconds
[2025-12-13T16:28:43.351+0000] {processor.py:186} INFO - Started process (PID=368) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:28:43.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:28:43.378+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:28:43.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:28:47.233+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:28:47.265+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:28:47.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:28:47.282+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:28:47.282+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:28:47.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.993 seconds
[2025-12-13T16:29:19.008+0000] {processor.py:186} INFO - Started process (PID=379) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:29:19.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:29:19.163+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:29:19.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:29:25.223+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:29:25.272+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:29:25.266+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:29:25.308+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:29:25.308+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:29:25.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 6.503 seconds
[2025-12-13T16:29:55.945+0000] {processor.py:186} INFO - Started process (PID=390) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:29:55.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:29:55.993+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:29:55.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:30:02.039+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:30:02.124+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:30:02.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:30:02.159+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:30:02.158+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:30:02.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 6.311 seconds
[2025-12-13T16:30:32.776+0000] {processor.py:186} INFO - Started process (PID=407) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:30:32.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:30:32.785+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:30:32.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:30:34.609+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:30:34.626+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:30:34.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:30:34.638+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:30:34.637+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:30:34.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.881 seconds
[2025-12-13T16:31:05.147+0000] {processor.py:186} INFO - Started process (PID=420) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:31:05.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:31:05.174+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:31:05.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:31:09.268+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:31:09.295+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:31:09.295+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:31:09.313+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:31:09.312+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:31:09.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 4.205 seconds
[2025-12-13T16:31:39.750+0000] {processor.py:186} INFO - Started process (PID=431) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:31:39.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:31:39.756+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:31:39.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:31:40.925+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:31:40.946+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:31:40.946+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:31:40.963+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:31:40.962+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:31:40.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.232 seconds
[2025-12-13T16:32:11.199+0000] {processor.py:186} INFO - Started process (PID=442) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:32:11.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:32:11.201+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:32:11.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:32:11.887+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:32:11.900+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:32:11.900+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:32:11.910+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:32:11.910+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:32:11.916+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.720 seconds
[2025-12-13T16:32:42.240+0000] {processor.py:186} INFO - Started process (PID=453) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:32:42.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:32:42.243+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:32:42.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:32:43.691+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:32:43.721+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:32:43.721+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:32:43.732+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:32:43.731+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:32:43.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.581 seconds
[2025-12-13T16:33:13.901+0000] {processor.py:186} INFO - Started process (PID=464) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:33:13.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:33:13.906+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:33:13.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:33:15.942+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:33:16.025+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:33:16.025+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:33:16.044+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:33:16.043+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:33:16.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.174 seconds
[2025-12-13T16:33:46.255+0000] {processor.py:186} INFO - Started process (PID=481) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:33:46.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:33:46.262+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:33:46.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:33:48.946+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:33:48.985+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:33:48.985+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:33:49.017+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:33:49.012+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:33:49.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.845 seconds
[2025-12-13T16:34:20.253+0000] {processor.py:186} INFO - Started process (PID=496) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:34:20.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:34:20.297+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:34:20.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:34:33.301+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:34:33.384+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:34:33.381+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:34:33.429+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:34:33.429+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:34:33.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 13.263 seconds
[2025-12-13T16:35:07.386+0000] {processor.py:186} INFO - Started process (PID=513) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:35:07.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:35:07.457+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:35:07.453+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:35:24.486+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:35:25.709+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:35:25.698+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:35:25.891+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:35:25.890+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:35:26.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 18.999 seconds
[2025-12-13T16:35:59.038+0000] {processor.py:186} INFO - Started process (PID=524) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:35:59.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:35:59.920+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:35:59.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:36:30.108+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:36:30.107+0000] {timeout.py:68} ERROR - Process timed out, PID: 524
[2025-12-13T16:36:30.251+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:36:30.121+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 2, in <module>
    from sklearn import preprocessing
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/__init__.py", line 70, in <module>
    from sklearn.base import clone  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/base.py", line 19, in <module>
    from sklearn.utils._metadata_requests import _MetadataRequester, _routing_enabled
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/__init__.py", line 9, in <module>
    from sklearn.utils._chunking import gen_batches, gen_even_slices
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_chunking.py", line 11, in <module>
    from sklearn.utils._param_validation import Interval, validate_params
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py", line 17, in <module>
    from sklearn.utils.validation import _is_arraylike_not_scalar
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/validation.py", line 14, in <module>
    import joblib
  File "/home/airflow/.local/lib/python3.12/site-packages/joblib/__init__.py", line 114, in <module>
    from ._cloudpickle_wrapper import wrap_non_picklable_objects
  File "/home/airflow/.local/lib/python3.12/site-packages/joblib/_cloudpickle_wrapper.py", line 14, in <module>
    from .externals.loky import wrap_non_picklable_objects
  File "/home/airflow/.local/lib/python3.12/site-packages/joblib/externals/loky/__init__.py", line 19, in <module>
    from .backend.context import cpu_count
  File "/home/airflow/.local/lib/python3.12/site-packages/joblib/externals/loky/backend/__init__.py", line 4, in <module>
    from .context import get_context
  File "/home/airflow/.local/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py", line 24, in <module>
    from .process import LokyProcess, LokyInitMainProcess
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1087, in get_code
  File "<frozen importlib._bootstrap_external>", line 1187, in get_data
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/airflow.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#reducing-dag-complexity, PID: 524
[2025-12-13T16:36:30.256+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:36:30.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 31.635 seconds
[2025-12-13T16:37:03.627+0000] {processor.py:186} INFO - Started process (PID=538) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:37:03.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:37:04.103+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:37:04.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:37:21.349+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:37:22.065+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:37:22.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:37:22.092+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:37:22.091+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:37:22.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 19.911 seconds
[2025-12-13T16:37:52.919+0000] {processor.py:186} INFO - Started process (PID=554) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:37:52.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:37:52.944+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:37:52.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:37:57.368+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:37:57.431+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:37:57.431+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:37:57.469+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:37:57.467+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:37:57.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 4.684 seconds
[2025-12-13T16:38:28.436+0000] {processor.py:186} INFO - Started process (PID=565) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:38:28.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:38:28.464+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:38:28.460+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:38:41.095+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:38:41.220+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:38:41.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:38:41.291+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:38:41.291+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:38:41.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 13.007 seconds
[2025-12-13T16:39:12.203+0000] {processor.py:186} INFO - Started process (PID=576) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:39:12.207+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:39:12.229+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:39:12.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:39:17.465+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:39:17.519+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:39:17.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:39:17.548+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:39:17.547+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:39:17.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 5.446 seconds
[2025-12-13T16:39:48.533+0000] {processor.py:186} INFO - Started process (PID=593) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:39:48.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:39:48.567+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:39:48.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:39:59.396+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:39:59.475+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:39:59.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:39:59.510+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:39:59.510+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:39:59.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 11.187 seconds
[2025-12-13T16:40:30.433+0000] {processor.py:186} INFO - Started process (PID=604) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:40:30.449+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:40:30.479+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:40:30.461+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:40:41.184+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:40:41.240+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:40:41.240+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:40:41.261+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:40:41.261+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:40:41.274+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 10.953 seconds
[2025-12-13T16:41:11.626+0000] {processor.py:186} INFO - Started process (PID=615) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:41:11.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:41:11.631+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:41:11.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:41:14.020+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:41:14.073+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:41:14.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:41:14.091+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:41:14.091+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:41:14.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.522 seconds
[2025-12-13T16:41:44.339+0000] {processor.py:186} INFO - Started process (PID=626) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:41:44.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:41:44.346+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:41:44.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:41:46.497+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:41:46.529+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:41:46.529+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:41:46.545+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:41:46.544+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:41:46.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.227 seconds
[2025-12-13T16:42:16.673+0000] {processor.py:186} INFO - Started process (PID=643) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:42:16.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:42:16.676+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:42:16.675+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:42:18.166+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:42:18.184+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:42:18.184+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:42:18.194+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:42:18.194+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:42:18.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.537 seconds
[2025-12-13T16:42:48.834+0000] {processor.py:186} INFO - Started process (PID=654) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:42:48.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:42:48.838+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:42:48.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:42:50.775+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:42:50.809+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:42:50.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:42:50.834+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:42:50.834+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:42:50.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.029 seconds
[2025-12-13T16:43:21.181+0000] {processor.py:186} INFO - Started process (PID=665) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:43:21.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:43:21.184+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:43:21.183+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:43:21.907+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:43:21.919+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:43:21.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:43:21.928+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:43:21.928+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:43:21.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.760 seconds
[2025-12-13T16:43:52.192+0000] {processor.py:186} INFO - Started process (PID=677) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:43:52.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:43:52.194+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:43:52.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:43:53.105+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:43:53.118+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:43:53.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:43:53.128+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:43:53.128+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:43:53.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.948 seconds
[2025-12-13T16:44:23.380+0000] {processor.py:186} INFO - Started process (PID=688) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:44:23.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:44:23.382+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:44:23.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:44:24.180+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:44:24.194+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:44:24.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:44:24.204+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:44:24.203+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:44:24.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.835 seconds
[2025-12-13T16:45:34.255+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:45:34.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:45:34.288+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:45:34.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:46:08.361+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:46:08.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:46:08.365+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:46:08.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:46:13.103+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:46:13.130+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:46:13.130+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:46:13.144+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:46:13.144+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:46:13.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 4.754 seconds
[2025-12-13T16:46:44.158+0000] {processor.py:186} INFO - Started process (PID=57) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:46:44.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:46:44.202+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:46:44.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:47:05.334+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:47:05.379+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:47:05.379+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:47:05.414+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:47:05.414+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:47:05.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 21.408 seconds
[2025-12-13T16:47:36.420+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:47:36.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:47:36.587+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:47:36.584+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:47:49.857+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:47:49.896+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:47:49.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:47:49.928+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:47:49.927+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:47:49.952+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 13.711 seconds
[2025-12-13T16:48:20.917+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:48:20.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:48:20.996+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:48:20.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:48:28.902+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:48:28.949+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:48:28.949+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:48:29.010+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:48:29.009+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:48:29.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 8.276 seconds
[2025-12-13T16:49:00.073+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:49:00.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:49:00.237+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:00.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:49:08.946+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:49:08.970+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:08.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:49:08.994+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:08.994+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:49:09.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 9.238 seconds
[2025-12-13T16:49:39.880+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:49:39.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:49:39.969+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:39.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:49:47.333+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:49:47.456+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:47.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:49:47.533+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:47.533+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:49:47.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 7.801 seconds
[2025-12-13T16:49:54.456+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:49:54.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:49:54.475+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:54.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:49:56.769+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:49:56.847+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:56.846+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'stock_portfolio_pipeline_datafrogs', 'Task Id': 'consume_and_process_stream', 'Run Id': 'manual__2025-12-13T16:33:40.698025+00:00', 'Hostname': '4ed43adab64d', 'External Executor Id': '0791405b-c791-4226-a30a-9fbb6075c31a'}
[2025-12-13T16:49:56.896+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:56.895+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=stock_portfolio_pipeline_datafrogs, task_id=consume_and_process_stream, run_id=manual__2025-12-13T16:33:40.698025+00:00, execution_date=20251213T163340, start_date=20251213T164424, end_date=20251213T164956
[2025-12-13T16:49:56.928+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:56.927+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: stock_portfolio_pipeline_datafrogs.consume_and_process_stream manual__2025-12-13T16:33:40.698025+00:00 [up_for_retry]> in state up_for_retry
[2025-12-13T16:49:56.931+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:56.931+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'stock_portfolio_pipeline_datafrogs', 'Task Id': 'consume_and_process_stream', 'Run Id': 'manual__2025-12-13T16:33:40.698025+00:00', 'Hostname': '4ed43adab64d', 'External Executor Id': '0791405b-c791-4226-a30a-9fbb6075c31a'}
[2025-12-13T16:49:56.935+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:56.935+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=stock_portfolio_pipeline_datafrogs, task_id=consume_and_process_stream, run_id=manual__2025-12-13T16:33:40.698025+00:00, execution_date=20251213T163340, start_date=20251213T164424, end_date=20251213T164956
[2025-12-13T16:49:56.938+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:56.938+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: stock_portfolio_pipeline_datafrogs.consume_and_process_stream manual__2025-12-13T16:33:40.698025+00:00 [up_for_retry]> in state up_for_retry
[2025-12-13T16:49:56.966+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:56.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:49:57.002+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:49:57.002+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:49:57.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.632 seconds
[2025-12-13T16:50:27.697+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:50:27.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:50:27.744+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:50:27.740+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:50:34.200+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:50:34.249+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:50:34.249+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:50:34.270+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:50:34.270+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:50:34.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 6.671 seconds
[2025-12-13T16:51:04.750+0000] {processor.py:186} INFO - Started process (PID=141) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:51:04.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:51:04.834+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:51:04.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:51:12.131+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:51:12.162+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:51:12.161+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:51:12.184+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:51:12.184+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:51:12.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 7.608 seconds
[2025-12-13T16:51:43.028+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:51:43.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:51:43.058+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:51:43.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:51:50.640+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:51:50.678+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:51:50.678+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:51:50.708+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:51:50.707+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:51:50.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 7.734 seconds
[2025-12-13T16:52:21.752+0000] {processor.py:186} INFO - Started process (PID=169) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:52:21.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:52:21.952+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:52:21.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:52:31.252+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:52:31.282+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:52:31.282+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:52:31.307+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:52:31.307+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:52:31.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 9.679 seconds
[2025-12-13T16:53:02.183+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:53:02.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:53:02.242+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:53:02.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:53:09.631+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:53:09.649+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:53:09.649+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:53:09.662+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:53:09.662+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:53:09.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 7.574 seconds
[2025-12-13T16:53:39.887+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:53:39.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:53:39.892+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:53:39.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:53:41.540+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:53:41.580+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:53:41.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:53:41.598+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:53:41.598+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:53:41.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.731 seconds
[2025-12-13T16:54:11.822+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/airflow.py
[2025-12-13T16:54:11.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T16:54:11.892+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:54:11.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T16:54:18.438+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T16:54:19.094+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:54:19.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T16:54:19.124+0000] {logging_mixin.py:190} INFO - [2025-12-13T16:54:19.124+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T16:54:19.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 7.285 seconds
[2025-12-13T17:25:11.983+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:25:11.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:25:12.040+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:25:12.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:25:28.030+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:25:28.073+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:25:28.072+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:25:28.093+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:25:28.093+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:25:28.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 16.194 seconds
[2025-12-13T17:25:58.932+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:25:58.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:25:58.959+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:25:58.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:26:06.288+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:26:06.342+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:26:06.342+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:26:06.366+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:26:06.365+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:26:06.380+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 7.556 seconds
[2025-12-13T17:26:37.068+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:26:37.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:26:37.114+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:26:37.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:26:50.400+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:26:50.503+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:26:50.501+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:26:50.606+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:26:50.605+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:26:50.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 13.685 seconds
[2025-12-13T17:27:25.523+0000] {processor.py:186} INFO - Started process (PID=80) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:27:25.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:27:25.882+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:27:25.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:27:39.529+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:27:39.677+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:27:39.673+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:27:39.766+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:27:39.765+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:27:39.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 15.325 seconds
[2025-12-13T17:28:11.234+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:28:11.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:28:11.467+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:28:11.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:29:51.927+0000] {processor.py:186} INFO - Started process (PID=36) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:29:51.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:29:51.950+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:29:51.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:30:13.000+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:30:13.403+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:30:13.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:30:13.629+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:30:13.626+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:30:13.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 22.027 seconds
[2025-12-13T17:30:44.847+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:30:44.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:30:44.896+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:30:44.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:30:57.186+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:30:57.405+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:30:57.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:30:57.586+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:30:57.585+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:30:57.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 12.907 seconds
[2025-12-13T17:31:28.869+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:31:28.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:31:29.087+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:31:29.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:31:59.416+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:31:59.365+0000] {timeout.py:68} ERROR - Process timed out, PID: 88
[2025-12-13T17:31:59.630+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:31:59.445+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 2, in <module>
    from sklearn import preprocessing
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/__init__.py", line 70, in <module>
    from sklearn.base import clone  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/base.py", line 19, in <module>
    from sklearn.utils._metadata_requests import _MetadataRequester, _routing_enabled
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/__init__.py", line 9, in <module>
    from sklearn.utils._chunking import gen_batches, gen_even_slices
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_chunking.py", line 11, in <module>
    from sklearn.utils._param_validation import Interval, validate_params
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py", line 17, in <module>
    from sklearn.utils.validation import _is_arraylike_not_scalar
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/validation.py", line 24, in <module>
    from sklearn.utils._array_api import (
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_array_api.py", line 20, in <module>
    from sklearn.utils.fixes import parse_version
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/fixes.py", line 19, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/__init__.py", line 23, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.12/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
  File "<frozen importlib._bootstrap>", line 645, in parent
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/airflow.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#reducing-dag-complexity, PID: 88
[2025-12-13T17:31:59.721+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:32:00.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 31.548 seconds
[2025-12-13T17:32:31.750+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:32:31.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:32:31.823+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:32:31.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:32:52.249+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:32:52.311+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:32:52.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:32:52.330+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:32:52.330+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:32:52.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 20.724 seconds
[2025-12-13T17:33:23.273+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:33:23.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:33:23.368+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:33:23.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:33:33.861+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:33:34.356+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:33:34.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:33:34.558+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:33:34.557+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:33:34.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 11.434 seconds
[2025-12-13T17:34:05.667+0000] {processor.py:186} INFO - Started process (PID=133) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:34:05.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:34:05.750+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:34:05.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:34:13.981+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:34:14.018+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:34:14.018+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:34:14.043+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:34:14.042+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:34:14.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 8.483 seconds
[2025-12-13T17:34:44.829+0000] {processor.py:186} INFO - Started process (PID=150) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:34:44.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:34:44.878+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:34:44.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:34:50.064+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:34:50.087+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:34:50.087+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:34:50.099+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:34:50.099+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:34:50.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 5.330 seconds
[2025-12-13T17:35:20.792+0000] {processor.py:186} INFO - Started process (PID=161) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:35:20.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:35:20.800+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:35:20.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:35:36.110+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:35:36.935+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:35:36.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:35:37.296+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:35:37.293+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:35:37.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 16.837 seconds
[2025-12-13T17:35:40.679+0000] {processor.py:186} INFO - Started process (PID=166) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:35:40.683+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:35:40.703+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:35:40.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:37:21.209+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:37:21.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:37:21.216+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:37:21.215+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:37:27.210+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:37:27.263+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:37:27.262+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:37:27.302+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:37:27.301+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:37:27.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 6.184 seconds
[2025-12-13T17:37:58.331+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:37:58.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:37:58.350+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:37:58.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:38:02.466+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:38:02.495+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:38:02.495+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:38:02.515+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:38:02.515+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:38:02.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 4.331 seconds
[2025-12-13T17:38:33.440+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:38:33.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:38:33.448+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:38:33.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:38:39.076+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:38:39.116+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:38:39.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:38:39.137+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:38:39.137+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:38:39.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 5.754 seconds
[2025-12-13T17:39:10.412+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:39:10.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:39:10.777+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:39:10.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:39:23.185+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:39:23.234+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:39:23.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:39:23.259+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:39:23.259+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:39:23.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 13.063 seconds
[2025-12-13T17:39:54.423+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:39:54.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:39:54.474+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:39:54.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:40:14.507+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:40:14.574+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:40:14.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:40:14.679+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:40:14.678+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:40:14.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 20.435 seconds
[2025-12-13T17:41:00.114+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:41:00.116+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:41:00.125+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:00.122+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:41:06.944+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:41:07.020+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:07.018+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:41:07.065+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:07.065+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:41:07.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 7.022 seconds
[2025-12-13T17:41:16.462+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:41:16.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:41:16.505+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:16.500+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:41:26.876+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:41:26.956+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:26.952+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'stock_portfolio_pipeline_datafrogs', 'Task Id': 'start_kafka_producer', 'Run Id': 'manual__2025-12-13T17:26:03.598095+00:00', 'Hostname': '686b42cad89b', 'External Executor Id': '27a347f3-41ea-4b6a-bc03-13b649fe2b31'}
[2025-12-13T17:41:27.017+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:27.017+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=stock_portfolio_pipeline_datafrogs, task_id=start_kafka_producer, run_id=manual__2025-12-13T17:26:03.598095+00:00, execution_date=20251213T172603, start_date=20251213T173249, end_date=20251213T174127
[2025-12-13T17:41:27.099+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:27.098+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: stock_portfolio_pipeline_datafrogs.start_kafka_producer manual__2025-12-13T17:26:03.598095+00:00 [up_for_retry]> in state up_for_retry
[2025-12-13T17:41:27.109+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:27.109+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'stock_portfolio_pipeline_datafrogs', 'Task Id': 'start_kafka_producer', 'Run Id': 'manual__2025-12-13T17:26:03.598095+00:00', 'Hostname': '686b42cad89b', 'External Executor Id': '27a347f3-41ea-4b6a-bc03-13b649fe2b31'}
[2025-12-13T17:41:27.118+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:27.118+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=stock_portfolio_pipeline_datafrogs, task_id=start_kafka_producer, run_id=manual__2025-12-13T17:26:03.598095+00:00, execution_date=20251213T172603, start_date=20251213T173249, end_date=20251213T174127
[2025-12-13T17:41:27.129+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:27.128+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: stock_portfolio_pipeline_datafrogs.start_kafka_producer manual__2025-12-13T17:26:03.598095+00:00 [up_for_retry]> in state up_for_retry
[2025-12-13T17:41:27.130+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:27.130+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'stock_portfolio_pipeline_datafrogs', 'Task Id': 'start_kafka_producer', 'Run Id': 'manual__2025-12-13T17:26:03.598095+00:00', 'Hostname': '686b42cad89b', 'External Executor Id': '27a347f3-41ea-4b6a-bc03-13b649fe2b31'}
[2025-12-13T17:41:27.134+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:27.134+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=stock_portfolio_pipeline_datafrogs, task_id=start_kafka_producer, run_id=manual__2025-12-13T17:26:03.598095+00:00, execution_date=20251213T172603, start_date=20251213T173249, end_date=20251213T174127
[2025-12-13T17:41:27.146+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:27.146+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: stock_portfolio_pipeline_datafrogs.start_kafka_producer manual__2025-12-13T17:26:03.598095+00:00 [up_for_retry]> in state up_for_retry
[2025-12-13T17:41:27.360+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:27.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:41:27.576+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:27.576+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:41:27.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 11.607 seconds
[2025-12-13T17:41:58.922+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:41:58.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:41:59.008+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:41:58.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:42:22.836+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:42:22.866+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:42:22.866+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'stock_portfolio_pipeline_datafrogs', 'Task Id': 'start_kafka_producer', 'Run Id': 'manual__2025-12-13T17:26:03.598095+00:00', 'Hostname': '686b42cad89b', 'External Executor Id': '27a347f3-41ea-4b6a-bc03-13b649fe2b31'}
[2025-12-13T17:42:22.907+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:42:22.906+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=stock_portfolio_pipeline_datafrogs, task_id=start_kafka_producer, run_id=manual__2025-12-13T17:26:03.598095+00:00, execution_date=20251213T172603, start_date=20251213T173249, end_date=20251213T174222
[2025-12-13T17:42:22.962+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:42:22.962+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: stock_portfolio_pipeline_datafrogs.start_kafka_producer manual__2025-12-13T17:26:03.598095+00:00 [up_for_retry]> in state up_for_retry
[2025-12-13T17:42:23.019+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:42:23.019+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:42:23.060+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:42:23.060+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:42:23.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 24.262 seconds
[2025-12-13T17:42:38.418+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:42:38.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:42:38.466+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:42:38.463+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:42:51.457+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:42:51.535+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:42:51.535+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:42:51.572+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:42:51.571+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:42:51.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 13.307 seconds
[2025-12-13T17:42:57.900+0000] {processor.py:186} INFO - Started process (PID=150) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:42:57.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:42:57.940+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:42:57.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:43:08.962+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:43:08.995+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:43:08.995+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:43:09.016+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:43:09.016+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:43:09.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 11.195 seconds
[2025-12-13T17:43:40.849+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:43:40.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:43:41.145+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:43:41.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:43:57.223+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:43:57.252+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:43:57.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:43:57.268+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:43:57.268+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:43:57.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 16.915 seconds
[2025-12-13T17:44:29.597+0000] {processor.py:186} INFO - Started process (PID=179) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:44:29.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:44:29.920+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:44:29.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:44:36.840+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:44:36.875+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:44:36.875+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:44:36.899+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:44:36.898+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:44:36.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 7.483 seconds
[2025-12-13T17:45:09.674+0000] {processor.py:186} INFO - Started process (PID=190) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:45:09.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:45:10.111+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:45:10.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:45:32.608+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:45:32.645+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:45:32.644+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:45:32.663+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:45:32.663+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:45:32.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 23.380 seconds
[2025-12-13T17:46:03.029+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:46:03.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:46:03.037+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:46:03.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:46:05.647+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:46:05.679+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:46:05.679+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:46:05.693+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:46:05.693+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:46:05.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.691 seconds
[2025-12-13T17:46:36.027+0000] {processor.py:186} INFO - Started process (PID=218) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:46:36.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:46:36.032+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:46:36.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:46:37.401+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:46:37.422+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:46:37.422+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:46:37.436+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:46:37.436+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:46:37.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.433 seconds
[2025-12-13T17:47:08.350+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:47:08.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:47:08.376+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:47:08.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:47:11.315+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:47:11.374+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:47:11.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:47:11.397+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:47:11.396+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:47:11.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.121 seconds
[2025-12-13T17:47:41.664+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:47:41.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:47:41.669+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:47:41.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:47:42.813+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:47:42.837+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:47:42.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:47:42.851+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:47:42.851+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:47:42.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.205 seconds
[2025-12-13T17:48:12.998+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:48:12.999+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:48:13.004+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:48:13.003+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:48:13.876+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:48:13.890+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:48:13.890+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:48:13.900+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:48:13.900+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:48:13.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.933 seconds
[2025-12-13T17:48:44.254+0000] {processor.py:186} INFO - Started process (PID=263) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:48:44.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:48:44.257+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:48:44.257+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:48:44.845+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:48:44.858+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:48:44.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:48:44.866+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:48:44.866+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:48:44.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.626 seconds
[2025-12-13T17:49:15.230+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:49:15.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:49:15.237+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:49:15.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:49:16.112+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:49:16.132+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:49:16.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:49:16.146+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:49:16.146+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:49:16.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.932 seconds
[2025-12-13T17:49:46.493+0000] {processor.py:186} INFO - Started process (PID=291) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:49:46.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:49:46.498+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:49:46.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:49:47.215+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:49:47.229+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:49:47.229+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:49:47.239+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:49:47.239+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:49:47.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.762 seconds
[2025-12-13T17:50:17.500+0000] {processor.py:186} INFO - Started process (PID=302) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:50:17.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:50:17.503+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:50:17.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:50:18.332+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:50:18.348+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:50:18.348+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:50:18.358+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:50:18.358+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:50:18.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.881 seconds
[2025-12-13T17:50:48.519+0000] {processor.py:186} INFO - Started process (PID=313) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:50:48.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:50:48.523+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:50:48.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:50:49.431+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:50:49.453+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:50:49.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:50:49.466+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:50:49.466+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:50:49.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.963 seconds
[2025-12-13T17:51:20.406+0000] {processor.py:186} INFO - Started process (PID=331) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:51:20.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:51:20.411+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:51:20.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:51:21.607+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:51:21.630+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:51:21.630+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:51:21.644+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:51:21.644+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:51:21.653+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.255 seconds
[2025-12-13T17:51:52.212+0000] {processor.py:186} INFO - Started process (PID=342) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:51:52.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:51:52.221+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:51:52.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:51:53.728+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:51:53.761+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:51:53.760+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:51:53.789+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:51:53.789+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:51:53.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.603 seconds
[2025-12-13T17:52:24.157+0000] {processor.py:186} INFO - Started process (PID=352) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:52:24.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:52:24.168+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:52:24.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:52:25.737+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:52:25.765+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:52:25.764+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:52:25.779+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:52:25.779+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:52:25.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.649 seconds
[2025-12-13T17:52:56.239+0000] {processor.py:186} INFO - Started process (PID=363) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:52:56.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:52:56.245+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:52:56.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:52:57.403+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:52:57.427+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:52:57.427+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:52:57.440+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:52:57.440+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:52:57.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.235 seconds
[2025-12-13T17:53:27.750+0000] {processor.py:186} INFO - Started process (PID=374) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:53:27.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:53:27.755+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:53:27.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:53:28.614+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:53:28.628+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:53:28.628+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:53:28.638+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:53:28.638+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:53:28.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.908 seconds
[2025-12-13T17:53:59.132+0000] {processor.py:186} INFO - Started process (PID=385) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:53:59.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:53:59.138+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:53:59.138+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:54:00.544+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:54:00.627+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:54:00.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:54:00.649+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:54:00.649+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:54:00.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.543 seconds
[2025-12-13T17:54:10.926+0000] {processor.py:186} INFO - Started process (PID=390) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:54:10.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:54:10.939+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:54:10.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:54:12.118+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:54:12.142+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:54:12.141+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:54:12.173+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:54:12.173+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:54:12.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.299 seconds
[2025-12-13T17:54:13.264+0000] {processor.py:186} INFO - Started process (PID=395) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:54:13.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:54:13.275+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:54:13.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:54:15.815+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:54:15.865+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:54:15.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:54:15.883+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:54:15.883+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:54:15.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.647 seconds
[2025-12-13T17:54:53.815+0000] {processor.py:186} INFO - Started process (PID=411) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:54:53.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:54:53.874+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:54:53.860+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:55:04.870+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:55:04.986+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:55:04.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:55:05.034+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:55:05.033+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:55:05.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 11.334 seconds
[2025-12-13T17:56:04.986+0000] {processor.py:186} INFO - Started process (PID=422) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:56:04.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:56:05.018+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:56:05.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:56:12.127+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:56:12.148+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:56:12.148+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'stock_portfolio_pipeline_datafrogs', 'Task Id': 'start_kafka_producer', 'Run Id': 'manual__2025-12-13T17:54:17.484782+00:00', 'Hostname': '686b42cad89b', 'External Executor Id': '9a76ff86-9fab-4c57-b3a1-91562415fde8'}
[2025-12-13T17:56:12.167+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:56:12.167+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=stock_portfolio_pipeline_datafrogs, task_id=start_kafka_producer, run_id=manual__2025-12-13T17:54:17.484782+00:00, execution_date=20251213T175417, start_date=20251213T175421, end_date=20251213T175612
[2025-12-13T17:56:12.191+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:56:12.191+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: stock_portfolio_pipeline_datafrogs.start_kafka_producer manual__2025-12-13T17:54:17.484782+00:00 [up_for_retry]> in state up_for_retry
[2025-12-13T17:56:12.249+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:56:12.249+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:56:12.286+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:56:12.285+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:56:12.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 20.363 seconds
[2025-12-13T17:56:42.813+0000] {processor.py:186} INFO - Started process (PID=439) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:56:42.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:56:42.822+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:56:42.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:56:44.628+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:56:44.640+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:56:44.639+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'stock_portfolio_pipeline_datafrogs', 'Task Id': 'start_kafka_producer', 'Run Id': 'manual__2025-12-13T17:54:17.484782+00:00', 'Hostname': '686b42cad89b', 'External Executor Id': '9a76ff86-9fab-4c57-b3a1-91562415fde8'}
[2025-12-13T17:56:44.650+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:56:44.649+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=stock_portfolio_pipeline_datafrogs, task_id=start_kafka_producer, run_id=manual__2025-12-13T17:54:17.484782+00:00, execution_date=20251213T175417, start_date=20251213T175421, end_date=20251213T175644
[2025-12-13T17:56:44.656+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:56:44.656+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: stock_portfolio_pipeline_datafrogs.start_kafka_producer manual__2025-12-13T17:54:17.484782+00:00 [up_for_retry]> in state up_for_retry
[2025-12-13T17:56:44.669+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:56:44.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:56:44.684+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:56:44.684+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:56:44.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.897 seconds
[2025-12-13T17:57:15.211+0000] {processor.py:186} INFO - Started process (PID=450) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:57:15.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:57:15.226+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:57:15.225+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:57:16.932+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:57:16.966+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:57:16.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:57:16.984+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:57:16.984+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:57:16.995+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.798 seconds
[2025-12-13T17:57:47.526+0000] {processor.py:186} INFO - Started process (PID=461) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:57:47.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:57:47.538+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:57:47.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:57:48.758+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:57:48.806+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:57:48.805+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:57:48.836+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:57:48.836+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:57:48.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.358 seconds
[2025-12-13T17:58:19.204+0000] {processor.py:186} INFO - Started process (PID=472) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:58:19.207+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:58:19.211+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:58:19.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:58:20.220+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:58:20.236+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:58:20.236+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:58:20.248+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:58:20.248+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:58:20.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.060 seconds
[2025-12-13T17:58:39.497+0000] {processor.py:186} INFO - Started process (PID=483) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:58:39.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:58:39.502+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:58:39.502+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:58:40.466+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:58:40.481+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:58:40.481+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:58:40.494+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:58:40.494+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:58:40.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.018 seconds
[2025-12-13T17:58:45.655+0000] {processor.py:186} INFO - Started process (PID=488) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:58:45.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:58:45.662+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:58:45.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:58:46.628+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:58:46.652+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:58:46.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:58:46.664+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:58:46.664+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:58:46.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.036 seconds
[2025-12-13T17:59:17.119+0000] {processor.py:186} INFO - Started process (PID=500) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:59:17.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:59:17.124+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:59:17.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:59:17.978+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:59:17.994+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:59:17.993+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:59:18.005+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:59:18.005+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:59:18.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.899 seconds
[2025-12-13T17:59:48.513+0000] {processor.py:186} INFO - Started process (PID=511) to work on /opt/airflow/dags/airflow.py
[2025-12-13T17:59:48.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T17:59:48.523+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:59:48.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T17:59:49.992+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T17:59:50.377+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:59:50.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T17:59:50.479+0000] {logging_mixin.py:190} INFO - [2025-12-13T17:59:50.476+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T17:59:50.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.058 seconds
[2025-12-13T18:00:34.709+0000] {processor.py:186} INFO - Started process (PID=522) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:00:34.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:00:34.789+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:00:34.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:00:37.922+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:00:37.963+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:00:37.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:00:37.981+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:00:37.981+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:00:37.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.414 seconds
[2025-12-13T18:01:08.250+0000] {processor.py:186} INFO - Started process (PID=539) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:01:08.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:01:08.254+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:01:08.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:01:09.107+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:01:09.122+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:01:09.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:01:09.134+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:01:09.134+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:01:09.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.904 seconds
[2025-12-13T18:01:39.651+0000] {processor.py:186} INFO - Started process (PID=549) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:01:39.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:01:39.665+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:01:39.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:01:41.166+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:01:41.202+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:01:41.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:01:41.225+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:01:41.224+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:01:41.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.626 seconds
[2025-12-13T18:02:11.765+0000] {processor.py:186} INFO - Started process (PID=560) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:02:11.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:02:11.774+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:02:11.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:02:15.180+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:02:15.214+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:02:15.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:02:15.228+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:02:15.228+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:02:15.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.495 seconds
[2025-12-13T18:02:45.730+0000] {processor.py:186} INFO - Started process (PID=571) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:02:45.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:02:45.776+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:02:45.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:02:47.852+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:02:47.888+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:02:47.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:02:47.915+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:02:47.915+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:02:47.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.244 seconds
[2025-12-13T18:03:18.082+0000] {processor.py:186} INFO - Started process (PID=581) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:03:18.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:03:18.090+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:03:18.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:03:19.316+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:03:19.334+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:03:19.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:03:19.354+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:03:19.354+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:03:19.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.297 seconds
[2025-12-13T18:03:20.125+0000] {processor.py:186} INFO - Started process (PID=586) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:03:20.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:03:20.128+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:03:20.128+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:03:23.389+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:03:23.406+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:03:23.406+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:03:23.422+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:03:23.422+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:03:23.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.314 seconds
[2025-12-13T18:03:54.490+0000] {processor.py:186} INFO - Started process (PID=603) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:03:55.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:03:57.454+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:03:57.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:04:42.055+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:04:42.036+0000] {timeout.py:68} ERROR - Process timed out, PID: 603
[2025-12-13T18:04:42.118+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:04:42.067+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 2, in <module>
    from sklearn import preprocessing
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/__init__.py", line 70, in <module>
    from sklearn.base import clone  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/base.py", line 19, in <module>
    from sklearn.utils._metadata_requests import _MetadataRequester, _routing_enabled
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/__init__.py", line 9, in <module>
    from sklearn.utils._chunking import gen_batches, gen_even_slices
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_chunking.py", line 11, in <module>
    from sklearn.utils._param_validation import Interval, validate_params
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py", line 17, in <module>
    from sklearn.utils.validation import _is_arraylike_not_scalar
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/validation.py", line 24, in <module>
    from sklearn.utils._array_api import (
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_array_api.py", line 20, in <module>
    from sklearn.utils.fixes import parse_version
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/fixes.py", line 19, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/__init__.py", line 46, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/api.py", line 28, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/arrays/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/arrays/arrow/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow.array import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/arrays/arrow/array.py", line 52, in <module>
    from pandas.core.arrays._arrow_string_mixins import ArrowStringArrayMixin
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/arrays/_arrow_string_mixins.py", line 11, in <module>
    import pyarrow.compute as pc
  File "/home/airflow/.local/lib/python3.12/site-packages/pyarrow/compute.py", line 18, in <module>
    from pyarrow._compute import (  # noqa
  File "pyarrow/_compute.pyx", line 1513, in init pyarrow._compute
  File "pyarrow/_compute.pyx", line 837, in pyarrow._compute._min_count_doc
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/airflow.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#reducing-dag-complexity, PID: 603
[2025-12-13T18:04:42.139+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:04:42.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 48.757 seconds
[2025-12-13T18:05:13.207+0000] {processor.py:186} INFO - Started process (PID=618) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:05:13.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:05:13.221+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:05:13.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:05:14.511+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:05:14.537+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:05:14.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:05:14.552+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:05:14.552+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:05:14.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.376 seconds
[2025-12-13T18:05:44.862+0000] {processor.py:186} INFO - Started process (PID=629) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:05:44.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:05:44.867+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:05:44.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:05:46.110+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:05:46.127+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:05:46.127+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:05:46.138+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:05:46.138+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:05:46.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.293 seconds
[2025-12-13T18:06:06.061+0000] {processor.py:186} INFO - Started process (PID=634) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:06:06.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:06:06.068+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:06:06.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:06:08.728+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:06:08.764+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:06:08.764+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:06:08.783+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:06:08.783+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:06:08.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.756 seconds
[2025-12-13T18:06:46.365+0000] {processor.py:186} INFO - Started process (PID=654) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:06:46.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:06:46.438+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:06:46.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:07:17.842+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:07:16.637+0000] {timeout.py:68} ERROR - Process timed out, PID: 654
[2025-12-13T18:07:21.520+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:07:20.149+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 2, in <module>
    from sklearn import preprocessing
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/__init__.py", line 70, in <module>
    from sklearn.base import clone  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/base.py", line 19, in <module>
    from sklearn.utils._metadata_requests import _MetadataRequester, _routing_enabled
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/__init__.py", line 9, in <module>
    from sklearn.utils._chunking import gen_batches, gen_even_slices
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_chunking.py", line 11, in <module>
    from sklearn.utils._param_validation import Interval, validate_params
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py", line 17, in <module>
    from sklearn.utils.validation import _is_arraylike_not_scalar
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/validation.py", line 24, in <module>
    from sklearn.utils._array_api import (
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_array_api.py", line 20, in <module>
    from sklearn.utils.fixes import parse_version
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/fixes.py", line 19, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/__init__.py", line 46, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/api.py", line 28, in <module>
    from pandas.core.arrays import Categorical
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/arrays/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/arrays/arrow/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow.array import ArrowExtensionArray
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/arrays/arrow/array.py", line 52, in <module>
    from pandas.core.arrays._arrow_string_mixins import ArrowStringArrayMixin
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/arrays/_arrow_string_mixins.py", line 11, in <module>
    import pyarrow.compute as pc
  File "/home/airflow/.local/lib/python3.12/site-packages/pyarrow/compute.py", line 336, in <module>
    _make_global_functions()
  File "/home/airflow/.local/lib/python3.12/site-packages/pyarrow/compute.py", line 333, in _make_global_functions
    g[cpp_name] = g[name] = _wrap_function(name, func)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyarrow/compute.py", line 293, in _wrap_function
    arg_names = _get_arg_names(func)
                ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyarrow/compute.py", line 107, in _get_arg_names
    def _get_arg_names(func):
    
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/airflow.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#reducing-dag-complexity, PID: 654
[2025-12-13T18:07:21.563+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:07:22.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 36.670 seconds
[2025-12-13T18:07:53.533+0000] {processor.py:186} INFO - Started process (PID=671) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:07:53.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:07:53.558+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:07:53.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:07:57.825+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:07:57.903+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:07:57.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:07:57.928+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:07:57.928+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:07:57.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 4.435 seconds
[2025-12-13T18:07:59.893+0000] {processor.py:186} INFO - Started process (PID=676) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:07:59.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:07:59.899+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:07:59.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:08:02.693+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:08:02.712+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:08:02.712+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'stock_portfolio_pipeline_datafrogs', 'Task Id': 'initialize_spark_session', 'Run Id': 'manual__2025-12-13T17:59:51.022425+00:00', 'Hostname': '686b42cad89b', 'External Executor Id': '0e748187-91d2-4f94-a75a-e592ff378c88'}
[2025-12-13T18:08:02.725+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:08:02.724+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=stock_portfolio_pipeline_datafrogs, task_id=initialize_spark_session, run_id=manual__2025-12-13T17:59:51.022425+00:00, execution_date=20251213T175951, start_date=20251213T180729, end_date=20251213T180802
[2025-12-13T18:08:02.731+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:08:02.731+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: stock_portfolio_pipeline_datafrogs.initialize_spark_session manual__2025-12-13T17:59:51.022425+00:00 [failed]> in state failed
[2025-12-13T18:08:02.746+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:08:02.745+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:08:02.762+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:08:02.761+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:08:02.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.889 seconds
[2025-12-13T18:08:33.157+0000] {processor.py:186} INFO - Started process (PID=687) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:08:33.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:08:33.163+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:08:33.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:08:34.367+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:08:34.384+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:08:34.384+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:08:34.402+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:08:34.402+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:08:34.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.262 seconds
[2025-12-13T18:09:04.623+0000] {processor.py:186} INFO - Started process (PID=698) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:09:04.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:09:04.637+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:09:04.636+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:09:06.215+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:09:06.241+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:09:06.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:09:06.259+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:09:06.259+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:09:06.267+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.662 seconds
[2025-12-13T18:09:36.769+0000] {processor.py:186} INFO - Started process (PID=709) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:09:36.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:09:36.776+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:09:36.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:09:38.242+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:09:38.301+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:09:38.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:09:38.331+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:09:38.330+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:09:38.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.586 seconds
[2025-12-13T18:09:56.146+0000] {processor.py:186} INFO - Started process (PID=720) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:09:56.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:09:56.158+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:09:56.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:09:57.566+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:09:57.582+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:09:57.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:09:57.604+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:09:57.604+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:09:57.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.492 seconds
[2025-12-13T18:10:28.122+0000] {processor.py:186} INFO - Started process (PID=731) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:10:28.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:10:28.136+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:10:28.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:10:29.071+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:10:29.090+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:10:29.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:10:29.102+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:10:29.102+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:10:29.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.000 seconds
[2025-12-13T18:10:59.381+0000] {processor.py:186} INFO - Started process (PID=742) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:10:59.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:10:59.395+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:10:59.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:11:01.906+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:11:01.931+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:11:01.931+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:11:01.947+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:11:01.947+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:11:01.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.594 seconds
[2025-12-13T18:11:32.304+0000] {processor.py:186} INFO - Started process (PID=753) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:11:32.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:11:32.310+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:11:32.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:11:33.409+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:11:33.429+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:11:33.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:11:33.443+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:11:33.442+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:11:33.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.156 seconds
[2025-12-13T18:12:03.676+0000] {processor.py:186} INFO - Started process (PID=764) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:12:03.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:12:03.684+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:12:03.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:12:04.529+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:12:04.547+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:12:04.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:12:04.558+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:12:04.558+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:12:04.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.902 seconds
[2025-12-13T18:12:35.090+0000] {processor.py:186} INFO - Started process (PID=779) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:12:35.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:12:35.095+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:12:35.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:12:36.197+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:12:36.219+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:12:36.219+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:12:36.232+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:12:36.232+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:12:36.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.165 seconds
[2025-12-13T18:12:52.278+0000] {processor.py:186} INFO - Started process (PID=784) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:12:52.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:12:52.282+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:12:52.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:12:53.281+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:12:53.298+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:12:53.298+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:12:53.316+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:12:53.315+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:12:53.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.064 seconds
[2025-12-13T18:13:23.931+0000] {processor.py:186} INFO - Started process (PID=795) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:13:23.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:13:23.941+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:13:23.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:13:26.817+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:13:26.879+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:13:26.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:13:26.903+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:13:26.903+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:13:26.920+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.036 seconds
[2025-12-13T18:13:57.444+0000] {processor.py:186} INFO - Started process (PID=811) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:13:57.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:13:57.450+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:13:57.450+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:13:58.415+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:13:58.443+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:13:58.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:13:58.455+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:13:58.455+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:13:58.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.028 seconds
[2025-12-13T18:14:29.340+0000] {processor.py:186} INFO - Started process (PID=822) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:14:29.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:14:29.351+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:14:29.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:14:32.034+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:14:32.237+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:14:32.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:14:32.286+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:14:32.285+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:14:32.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.980 seconds
[2025-12-13T18:15:03.443+0000] {processor.py:186} INFO - Started process (PID=833) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:15:03.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:15:03.452+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:15:03.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:15:05.158+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:15:05.187+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:15:05.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:15:05.203+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:15:05.203+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:15:05.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.784 seconds
[2025-12-13T18:15:35.788+0000] {processor.py:186} INFO - Started process (PID=844) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:15:35.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:15:35.795+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:15:35.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:15:36.820+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:15:36.837+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:15:36.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:15:36.851+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:15:36.851+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:15:36.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.078 seconds
[2025-12-13T18:16:07.301+0000] {processor.py:186} INFO - Started process (PID=855) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:16:07.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:16:07.307+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:16:07.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:16:08.164+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:16:08.180+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:16:08.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:16:08.195+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:16:08.195+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:16:08.205+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.914 seconds
[2025-12-13T18:16:38.736+0000] {processor.py:186} INFO - Started process (PID=866) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:16:38.737+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:16:38.744+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:16:38.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:16:39.797+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:16:39.814+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:16:39.814+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:16:39.831+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:16:39.831+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:16:39.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.113 seconds
[2025-12-13T18:17:10.096+0000] {processor.py:186} INFO - Started process (PID=877) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:17:10.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:17:10.102+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:17:10.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:17:11.328+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:17:11.363+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:17:11.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:17:11.384+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:17:11.383+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:17:11.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.308 seconds
[2025-12-13T18:17:41.577+0000] {processor.py:186} INFO - Started process (PID=888) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:17:41.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:17:41.584+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:17:41.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:17:42.552+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:17:42.573+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:17:42.573+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:17:42.595+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:17:42.595+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:17:42.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.046 seconds
[2025-12-13T18:18:12.987+0000] {processor.py:186} INFO - Started process (PID=899) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:18:12.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:18:12.991+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:18:12.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:18:13.862+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:18:13.880+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:18:13.880+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:18:13.891+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:18:13.891+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:18:13.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.921 seconds
[2025-12-13T18:18:44.363+0000] {processor.py:186} INFO - Started process (PID=911) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:18:44.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:18:44.373+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:18:44.370+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:18:45.296+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:18:45.316+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:18:45.315+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:18:45.326+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:18:45.326+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:18:45.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.982 seconds
[2025-12-13T18:19:15.816+0000] {processor.py:186} INFO - Started process (PID=923) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:19:15.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:19:15.821+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:19:15.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:19:16.950+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:19:16.975+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:19:16.975+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:19:16.992+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:19:16.992+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:19:17.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.192 seconds
[2025-12-13T18:19:47.258+0000] {processor.py:186} INFO - Started process (PID=933) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:19:47.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:19:47.264+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:19:47.264+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:19:48.165+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:19:48.187+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:19:48.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:19:48.201+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:19:48.201+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:19:48.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.966 seconds
[2025-12-13T18:20:18.717+0000] {processor.py:186} INFO - Started process (PID=944) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:20:18.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:20:18.727+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:20:18.725+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:20:19.714+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:20:19.739+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:20:19.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:20:19.750+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:20:19.749+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:20:19.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.057 seconds
[2025-12-13T18:20:50.067+0000] {processor.py:186} INFO - Started process (PID=955) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:20:50.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:20:50.078+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:20:50.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:20:50.892+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:20:50.908+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:20:50.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:20:50.918+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:20:50.918+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:20:50.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.867 seconds
[2025-12-13T18:21:21.401+0000] {processor.py:186} INFO - Started process (PID=966) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:21:21.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:21:21.407+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:21:21.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:21:22.296+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:21:22.312+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:21:22.312+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:21:22.330+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:21:22.330+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:21:22.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.956 seconds
[2025-12-13T18:21:52.749+0000] {processor.py:186} INFO - Started process (PID=977) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:21:52.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:21:52.757+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:21:52.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:21:53.667+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:21:53.690+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:21:53.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:21:53.704+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:21:53.704+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:21:53.714+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.973 seconds
[2025-12-13T18:22:24.234+0000] {processor.py:186} INFO - Started process (PID=988) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:22:24.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:22:24.240+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:22:24.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:22:25.105+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:22:25.120+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:22:25.120+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:22:25.131+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:22:25.131+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:22:25.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.993 seconds
[2025-12-13T18:22:55.679+0000] {processor.py:186} INFO - Started process (PID=999) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:22:55.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:22:55.684+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:22:55.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:22:56.551+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:22:56.586+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:22:56.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:22:56.609+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:22:56.609+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:22:56.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.956 seconds
[2025-12-13T18:23:27.126+0000] {processor.py:186} INFO - Started process (PID=1010) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:23:27.128+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:23:27.132+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:23:27.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:23:28.091+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:23:28.181+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:23:28.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:23:28.192+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:23:28.192+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:23:28.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.080 seconds
[2025-12-13T18:23:58.596+0000] {processor.py:186} INFO - Started process (PID=1027) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:23:58.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:23:58.612+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:23:58.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:23:59.603+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:23:59.623+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:23:59.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:23:59.632+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:23:59.632+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:23:59.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.066 seconds
[2025-12-13T18:24:30.023+0000] {processor.py:186} INFO - Started process (PID=1038) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:24:30.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:24:30.030+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:24:30.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:24:31.044+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:24:31.070+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:24:31.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:24:31.092+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:24:31.091+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:24:31.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.098 seconds
[2025-12-13T18:25:01.389+0000] {processor.py:186} INFO - Started process (PID=1049) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:25:01.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:25:01.400+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:25:01.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:25:02.523+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:25:02.553+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:25:02.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:25:02.653+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:25:02.653+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:25:02.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.287 seconds
[2025-12-13T18:25:33.005+0000] {processor.py:186} INFO - Started process (PID=1060) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:25:33.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:25:33.011+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:25:33.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:25:34.147+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:25:34.169+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:25:34.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:25:34.189+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:25:34.189+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:25:34.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.199 seconds
[2025-12-13T18:26:04.398+0000] {processor.py:186} INFO - Started process (PID=1071) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:26:04.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:26:04.405+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:26:04.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:26:05.420+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:26:05.445+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:26:05.445+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:26:05.456+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:26:05.456+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:26:05.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.079 seconds
[2025-12-13T18:26:35.817+0000] {processor.py:186} INFO - Started process (PID=1082) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:26:35.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:26:35.824+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:26:35.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:26:38.383+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:26:38.407+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:26:38.407+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:26:38.419+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:26:38.419+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:26:38.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.619 seconds
[2025-12-13T18:27:08.834+0000] {processor.py:186} INFO - Started process (PID=1093) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:27:08.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:27:08.839+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:27:08.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:27:09.815+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:27:09.841+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:27:09.840+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:27:09.854+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:27:09.854+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:27:09.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.040 seconds
[2025-12-13T18:27:40.283+0000] {processor.py:186} INFO - Started process (PID=1104) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:27:40.285+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:27:40.297+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:27:40.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:27:41.254+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:27:41.276+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:27:41.276+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:27:41.287+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:27:41.286+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:27:41.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.022 seconds
[2025-12-13T18:28:11.752+0000] {processor.py:186} INFO - Started process (PID=1115) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:28:11.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:28:11.762+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:28:11.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:28:12.793+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:28:12.817+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:28:12.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:28:12.827+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:28:12.827+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:28:12.834+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.095 seconds
[2025-12-13T18:28:43.104+0000] {processor.py:186} INFO - Started process (PID=1126) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:28:43.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:28:43.111+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:28:43.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:28:44.097+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:28:44.138+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:28:44.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:28:44.158+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:28:44.158+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:28:44.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.087 seconds
[2025-12-13T18:29:14.515+0000] {processor.py:186} INFO - Started process (PID=1137) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:29:14.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:29:14.521+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:29:14.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:29:15.615+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:29:15.634+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:29:15.634+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:29:15.645+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:29:15.645+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:29:15.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.146 seconds
[2025-12-13T18:29:45.890+0000] {processor.py:186} INFO - Started process (PID=1148) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:29:45.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:29:45.894+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:29:45.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:29:46.888+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:29:46.913+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:29:46.913+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:29:46.924+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:29:46.924+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:29:46.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.049 seconds
[2025-12-13T18:30:17.425+0000] {processor.py:186} INFO - Started process (PID=1159) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:30:17.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:30:17.432+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:30:17.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:30:18.515+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:30:18.537+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:30:18.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:30:18.550+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:30:18.550+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:30:18.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.150 seconds
[2025-12-13T18:30:48.793+0000] {processor.py:186} INFO - Started process (PID=1171) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:30:48.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:30:48.800+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:30:48.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:30:49.841+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:30:49.892+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:30:49.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:30:49.907+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:30:49.907+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:30:49.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.144 seconds
[2025-12-13T18:31:20.275+0000] {processor.py:186} INFO - Started process (PID=1182) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:31:20.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:31:20.280+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:31:20.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:31:21.253+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:31:21.269+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:31:21.269+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:31:21.279+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:31:21.279+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:31:21.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.026 seconds
[2025-12-13T18:31:51.581+0000] {processor.py:186} INFO - Started process (PID=1193) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:31:51.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:31:51.585+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:31:51.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:31:52.634+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:31:52.659+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:31:52.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:31:52.672+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:31:52.672+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:31:52.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.107 seconds
[2025-12-13T18:32:22.922+0000] {processor.py:186} INFO - Started process (PID=1204) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:32:22.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:32:22.929+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:32:22.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:32:23.906+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:32:23.929+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:32:23.929+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:32:23.945+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:32:23.944+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:32:23.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.052 seconds
[2025-12-13T18:32:54.306+0000] {processor.py:186} INFO - Started process (PID=1215) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:32:54.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:32:54.313+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:32:54.312+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:32:55.323+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:32:55.344+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:32:55.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:32:55.356+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:32:55.356+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:32:55.365+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.070 seconds
[2025-12-13T18:33:25.854+0000] {processor.py:186} INFO - Started process (PID=1226) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:33:25.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:33:25.861+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:33:25.860+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:33:26.961+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:33:26.993+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:33:26.993+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:33:27.007+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:33:27.007+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:33:27.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.176 seconds
[2025-12-13T18:33:57.430+0000] {processor.py:186} INFO - Started process (PID=1236) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:33:57.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:33:57.437+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:33:57.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:33:58.512+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:33:58.532+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:33:58.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:33:58.542+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:33:58.542+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:33:58.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.131 seconds
[2025-12-13T18:34:29.616+0000] {processor.py:186} INFO - Started process (PID=1247) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:34:29.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:34:29.624+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:34:29.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:34:30.690+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:34:30.713+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:34:30.712+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:34:30.731+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:34:30.731+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:34:30.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.137 seconds
[2025-12-13T18:35:01.223+0000] {processor.py:186} INFO - Started process (PID=1264) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:35:01.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:35:01.230+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:35:01.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:35:02.582+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:35:02.631+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:35:02.630+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:35:02.643+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:35:02.643+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:35:02.651+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.451 seconds
[2025-12-13T18:35:33.078+0000] {processor.py:186} INFO - Started process (PID=1275) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:35:33.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:35:33.088+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:35:33.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:35:34.183+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:35:34.203+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:35:34.203+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:35:34.212+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:35:34.212+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:35:34.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.162 seconds
[2025-12-13T18:36:04.607+0000] {processor.py:186} INFO - Started process (PID=1286) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:36:04.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:36:04.613+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:36:04.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:36:05.598+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:36:05.621+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:36:05.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:36:05.632+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:36:05.631+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:36:05.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.043 seconds
[2025-12-13T18:36:36.071+0000] {processor.py:186} INFO - Started process (PID=1296) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:36:36.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:36:36.078+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:36:36.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:36:37.010+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:36:37.036+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:36:37.036+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:36:37.062+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:36:37.061+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:36:37.083+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.019 seconds
[2025-12-13T18:37:07.591+0000] {processor.py:186} INFO - Started process (PID=1308) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:37:07.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:37:07.598+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:37:07.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:37:08.609+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:37:08.629+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:37:08.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:37:08.644+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:37:08.644+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:37:08.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.078 seconds
[2025-12-13T18:37:39.088+0000] {processor.py:186} INFO - Started process (PID=1319) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:37:39.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:37:39.096+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:37:39.096+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:37:39.974+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:37:40.005+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:37:40.005+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:37:40.017+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:37:40.016+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:37:40.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.954 seconds
[2025-12-13T18:38:10.495+0000] {processor.py:186} INFO - Started process (PID=1330) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:38:10.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:38:10.502+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:38:10.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:38:11.597+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:38:11.612+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:38:11.612+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:38:11.621+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:38:11.621+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:38:11.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.145 seconds
[2025-12-13T18:38:41.988+0000] {processor.py:186} INFO - Started process (PID=1341) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:38:41.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:38:41.994+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:38:41.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:38:42.918+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:38:42.942+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:38:42.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:38:42.953+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:38:42.953+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:38:42.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.981 seconds
[2025-12-13T18:39:13.445+0000] {processor.py:186} INFO - Started process (PID=1352) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:39:13.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:39:13.454+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:39:13.453+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:39:14.391+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:39:14.411+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:39:14.411+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:39:14.422+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:39:14.422+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:39:14.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.992 seconds
[2025-12-13T18:39:44.939+0000] {processor.py:186} INFO - Started process (PID=1363) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:39:44.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:39:44.972+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:39:44.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:39:46.035+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:39:46.074+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:39:46.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:39:46.093+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:39:46.093+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:39:46.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.179 seconds
[2025-12-13T18:40:16.303+0000] {processor.py:186} INFO - Started process (PID=1374) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:40:16.304+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:40:16.307+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:40:16.307+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:40:17.218+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:40:17.238+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:40:17.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:40:17.260+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:40:17.260+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:40:17.274+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.979 seconds
[2025-12-13T18:40:47.761+0000] {processor.py:186} INFO - Started process (PID=1385) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:40:47.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:40:47.767+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:40:47.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:40:48.762+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:40:48.783+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:40:48.783+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:40:48.797+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:40:48.797+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:40:48.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.073 seconds
[2025-12-13T18:41:19.249+0000] {processor.py:186} INFO - Started process (PID=1396) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:41:19.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:41:19.257+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:41:19.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:41:20.132+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:41:20.155+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:41:20.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:41:20.167+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:41:20.167+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:41:20.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.937 seconds
[2025-12-13T18:41:50.875+0000] {processor.py:186} INFO - Started process (PID=1407) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:41:50.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:41:50.883+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:41:50.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:41:52.148+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:41:52.199+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:41:52.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:41:52.221+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:41:52.221+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:41:52.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.375 seconds
[2025-12-13T18:42:22.667+0000] {processor.py:186} INFO - Started process (PID=1418) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:42:22.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:42:22.677+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:42:22.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:42:23.711+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:42:23.728+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:42:23.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:42:23.739+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:42:23.739+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:42:23.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.093 seconds
[2025-12-13T18:42:53.984+0000] {processor.py:186} INFO - Started process (PID=1429) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:42:53.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:42:53.990+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:42:53.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:42:55.068+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:42:55.089+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:42:55.089+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:42:55.101+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:42:55.101+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:42:55.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.139 seconds
[2025-12-13T18:43:25.458+0000] {processor.py:186} INFO - Started process (PID=1441) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:43:25.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:43:25.466+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:43:25.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:43:26.448+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:43:26.470+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:43:26.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:43:26.483+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:43:26.483+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:43:26.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.044 seconds
[2025-12-13T18:43:56.827+0000] {processor.py:186} INFO - Started process (PID=1452) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:43:56.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:43:56.834+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:43:56.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:43:57.778+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:43:57.804+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:43:57.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:43:57.816+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:43:57.816+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:43:57.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.012 seconds
[2025-12-13T18:44:24.230+0000] {processor.py:186} INFO - Started process (PID=1463) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:44:24.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:44:24.241+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:44:24.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:44:25.155+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:44:25.175+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:44:25.175+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:44:25.187+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:44:25.187+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:44:25.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.981 seconds
[2025-12-13T18:44:55.404+0000] {processor.py:186} INFO - Started process (PID=1483) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:44:55.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:44:55.421+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:44:55.420+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:45:08.370+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:45:08.503+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:45:08.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:45:08.537+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:45:08.537+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:45:08.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 13.215 seconds
[2025-12-13T18:45:38.660+0000] {processor.py:186} INFO - Started process (PID=1499) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:45:38.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:45:38.669+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:45:38.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:45:40.385+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:45:40.406+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:45:40.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:45:40.420+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:45:40.420+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:45:40.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.779 seconds
[2025-12-13T18:46:10.835+0000] {processor.py:186} INFO - Started process (PID=1510) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:46:10.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:46:10.845+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:46:10.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:46:12.291+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:46:12.325+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:46:12.325+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:46:12.342+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:46:12.341+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:46:12.350+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.535 seconds
[2025-12-13T18:46:42.698+0000] {processor.py:186} INFO - Started process (PID=1521) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:46:42.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:46:42.705+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:46:42.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:46:43.939+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:46:43.960+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:46:43.960+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:46:43.971+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:46:43.971+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:46:43.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.291 seconds
[2025-12-13T18:47:14.211+0000] {processor.py:186} INFO - Started process (PID=1532) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:47:14.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:47:14.216+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:47:14.215+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:47:15.123+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:47:15.139+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:47:15.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:47:15.150+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:47:15.150+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:47:15.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.959 seconds
[2025-12-13T18:47:45.510+0000] {processor.py:186} INFO - Started process (PID=1543) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:47:45.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:47:45.515+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:47:45.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:47:46.378+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:47:46.393+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:47:46.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:47:46.404+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:47:46.404+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:47:46.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.908 seconds
[2025-12-13T18:48:16.750+0000] {processor.py:186} INFO - Started process (PID=1554) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:48:16.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:48:16.755+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:48:16.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:48:18.016+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:48:18.036+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:48:18.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:48:18.051+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:48:18.050+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:48:18.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.318 seconds
[2025-12-13T18:48:48.483+0000] {processor.py:186} INFO - Started process (PID=1565) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:48:48.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:48:48.496+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:48:48.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:48:49.778+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:48:49.807+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:48:49.807+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:48:49.820+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:48:49.820+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:48:49.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.364 seconds
[2025-12-13T18:49:20.279+0000] {processor.py:186} INFO - Started process (PID=1576) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:49:20.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:49:20.287+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:49:20.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:49:21.178+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:49:21.200+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:49:21.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:49:21.211+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:49:21.211+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:49:21.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.949 seconds
[2025-12-13T18:49:51.797+0000] {processor.py:186} INFO - Started process (PID=1587) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:49:51.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:49:51.805+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:49:51.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:49:52.772+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:49:52.793+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:49:52.793+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:49:52.806+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:49:52.806+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:49:52.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.029 seconds
[2025-12-13T18:49:57.949+0000] {processor.py:186} INFO - Started process (PID=1592) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:49:57.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:49:57.956+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:49:57.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:49:59.046+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:49:59.096+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:49:59.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:49:59.117+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:49:59.117+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:49:59.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.199 seconds
[2025-12-13T18:50:29.548+0000] {processor.py:186} INFO - Started process (PID=1613) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:50:29.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:50:29.569+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:50:29.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:50:31.144+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:50:31.165+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:50:31.164+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:50:31.178+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:50:31.178+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:50:31.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.656 seconds
[2025-12-13T18:51:01.624+0000] {processor.py:186} INFO - Started process (PID=1624) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:51:01.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:51:01.632+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:51:01.631+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:51:02.917+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:51:02.953+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:51:02.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:51:02.965+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:51:02.965+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:51:02.978+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.368 seconds
[2025-12-13T18:51:33.241+0000] {processor.py:186} INFO - Started process (PID=1635) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:51:33.242+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:51:33.246+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:51:33.245+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:51:34.570+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:51:34.592+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:51:34.592+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:51:34.606+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:51:34.606+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:51:34.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.391 seconds
[2025-12-13T18:52:04.987+0000] {processor.py:186} INFO - Started process (PID=1646) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:52:04.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:52:04.996+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:52:04.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:52:06.187+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:52:06.202+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:52:06.202+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:52:06.221+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:52:06.221+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:52:06.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.257 seconds
[2025-12-13T18:52:36.363+0000] {processor.py:186} INFO - Started process (PID=1657) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:52:36.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:52:36.368+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:52:36.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:52:37.120+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:52:37.137+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:52:37.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:52:37.147+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:52:37.147+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:52:37.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.810 seconds
[2025-12-13T18:53:07.552+0000] {processor.py:186} INFO - Started process (PID=1668) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:53:07.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:53:07.560+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:53:07.560+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:53:08.999+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:53:09.026+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:53:09.026+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:53:09.039+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:53:09.039+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:53:09.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.517 seconds
[2025-12-13T18:53:39.295+0000] {processor.py:186} INFO - Started process (PID=1679) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:53:39.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:53:39.301+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:53:39.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:53:40.733+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:53:40.751+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:53:40.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:53:40.767+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:53:40.767+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:53:40.777+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.490 seconds
[2025-12-13T18:53:48.936+0000] {processor.py:186} INFO - Started process (PID=1690) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:53:48.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:53:48.951+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:53:48.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:53:49.932+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:53:49.952+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:53:49.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:53:49.969+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:53:49.969+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:53:49.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.055 seconds
[2025-12-13T18:53:51.968+0000] {processor.py:186} INFO - Started process (PID=1695) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:53:51.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:53:51.973+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:53:51.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:53:53.960+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:53:53.975+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:53:53.975+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:53:53.986+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:53:53.986+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:53:54.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.040 seconds
[2025-12-13T18:54:30.976+0000] {processor.py:186} INFO - Started process (PID=1715) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:54:30.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:54:31.075+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:54:31.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:54:35.480+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:54:35.542+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:54:35.541+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:54:35.590+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:54:35.588+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:54:35.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 4.728 seconds
[2025-12-13T18:55:05.792+0000] {processor.py:186} INFO - Started process (PID=1726) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:55:05.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:55:05.797+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:55:05.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:55:06.979+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:55:07.000+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:55:06.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:55:07.012+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:55:07.012+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:55:07.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.239 seconds
[2025-12-13T18:55:38.478+0000] {processor.py:186} INFO - Started process (PID=1737) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:55:38.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:55:38.524+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:55:38.519+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:55:45.067+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:56:20.753+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-13T18:56:54.086+0000] {processor.py:186} INFO - Started process (PID=1754) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:56:54.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:56:54.090+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:56:54.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:56:55.858+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:56:55.998+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:56:55.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:56:56.019+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:56:56.019+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:56:56.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.956 seconds
[2025-12-13T18:57:26.507+0000] {processor.py:186} INFO - Started process (PID=1765) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:57:26.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:57:26.515+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:57:26.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:57:27.542+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:57:27.556+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:57:27.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:57:27.566+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:57:27.565+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:57:27.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.076 seconds
[2025-12-13T18:57:57.795+0000] {processor.py:186} INFO - Started process (PID=1776) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:57:57.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:57:57.797+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:57:57.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:57:59.080+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:57:59.105+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:57:59.104+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:57:59.123+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:57:59.122+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:57:59.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.343 seconds
[2025-12-13T18:58:29.345+0000] {processor.py:186} INFO - Started process (PID=1787) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:58:29.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:58:29.350+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:58:29.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:58:30.617+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:58:30.644+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:58:30.643+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:58:30.664+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:58:30.664+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:58:30.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.341 seconds
[2025-12-13T18:59:00.932+0000] {processor.py:186} INFO - Started process (PID=1798) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:59:00.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:59:00.939+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:59:00.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:59:02.424+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:59:02.453+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:59:02.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:59:02.475+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:59:02.475+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:59:02.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.564 seconds
[2025-12-13T18:59:32.960+0000] {processor.py:186} INFO - Started process (PID=1809) to work on /opt/airflow/dags/airflow.py
[2025-12-13T18:59:32.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T18:59:32.964+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:59:32.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T18:59:34.105+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T18:59:34.130+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:59:34.130+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T18:59:34.143+0000] {logging_mixin.py:190} INFO - [2025-12-13T18:59:34.143+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T18:59:34.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.203 seconds
[2025-12-13T19:00:04.368+0000] {processor.py:186} INFO - Started process (PID=1820) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:00:04.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:00:04.372+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:00:04.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:00:05.210+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:00:05.232+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:00:05.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:00:05.245+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:00:05.245+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:00:05.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.892 seconds
[2025-12-13T19:00:35.693+0000] {processor.py:186} INFO - Started process (PID=1831) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:00:35.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:00:35.699+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:00:35.699+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:00:36.587+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:00:36.613+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:00:36.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:00:36.625+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:00:36.625+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:00:36.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.955 seconds
[2025-12-13T19:01:07.118+0000] {processor.py:186} INFO - Started process (PID=1842) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:01:07.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:01:07.124+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:01:07.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:01:08.637+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:01:08.661+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:01:08.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:01:08.675+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:01:08.675+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:01:08.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.581 seconds
[2025-12-13T19:01:39.079+0000] {processor.py:186} INFO - Started process (PID=1852) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:01:39.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:01:39.082+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:01:39.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:01:40.180+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:01:40.201+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:01:40.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:01:40.216+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:01:40.216+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:01:40.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.262 seconds
[2025-12-13T19:02:10.610+0000] {processor.py:186} INFO - Started process (PID=1863) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:02:10.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:02:10.622+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:02:10.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:02:12.562+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:02:12.582+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:02:12.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:02:12.597+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:02:12.597+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:02:12.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.041 seconds
[2025-12-13T19:02:43.096+0000] {processor.py:186} INFO - Started process (PID=1874) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:02:43.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:02:43.100+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:02:43.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:02:44.299+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:02:44.396+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:02:44.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:02:44.407+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:02:44.407+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:02:44.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.331 seconds
[2025-12-13T19:03:14.811+0000] {processor.py:186} INFO - Started process (PID=1885) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:03:14.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:03:14.815+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:03:14.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:03:15.961+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:03:15.984+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:03:15.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:03:15.995+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:03:15.995+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:03:16.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.201 seconds
[2025-12-13T19:03:46.282+0000] {processor.py:186} INFO - Started process (PID=1895) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:03:46.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:03:46.286+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:03:46.285+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:03:47.745+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:03:47.768+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:03:47.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:03:47.780+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:03:47.780+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:03:47.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.517 seconds
[2025-12-13T19:09:10.497+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:09:10.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:09:10.518+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:09:10.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:09:23.900+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:09:24.016+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:09:24.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:09:24.096+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:09:24.096+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:09:24.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 13.644 seconds
[2025-12-13T19:09:55.259+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:09:55.261+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:09:55.272+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:09:55.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:10:02.283+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:10:02.324+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:10:02.324+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:10:02.342+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:10:02.342+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:10:02.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 7.168 seconds
[2025-12-13T19:10:36.776+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:10:36.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:10:37.036+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:10:37.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:11:00.947+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:11:01.691+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:11:01.678+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:11:02.698+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:11:02.694+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:11:02.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 26.619 seconds
[2025-12-13T19:11:33.912+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:11:33.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:11:33.977+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:11:33.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:11:41.598+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:11:42.764+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:11:42.762+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:11:42.826+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:11:42.825+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:11:42.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 9.015 seconds
[2025-12-13T19:12:13.522+0000] {processor.py:186} INFO - Started process (PID=95) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:12:13.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:12:13.552+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:12:13.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:12:46.963+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:12:46.959+0000] {timeout.py:68} ERROR - Process timed out, PID: 95
[2025-12-13T19:12:46.991+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:12:46.966+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 9, in <module>
    from kafka import KafkaProducer
  File "/home/airflow/.local/lib/python3.12/site-packages/kafka/__init__.py", line 21, in <module>
    from kafka.admin import KafkaAdminClient
  File "/home/airflow/.local/lib/python3.12/site-packages/kafka/admin/__init__.py", line 4, in <module>
    from kafka.admin.client import KafkaAdminClient
  File "/home/airflow/.local/lib/python3.12/site-packages/kafka/admin/client.py", line 15, in <module>
    from kafka.client_async import KafkaClient, selectors
  File "/home/airflow/.local/lib/python3.12/site-packages/kafka/client_async.py", line 21, in <module>
    from kafka.cluster import ClusterMetadata
  File "/home/airflow/.local/lib/python3.12/site-packages/kafka/cluster.py", line 14, in <module>
    from kafka.conn import get_ip_port_afi
  File "/home/airflow/.local/lib/python3.12/site-packages/kafka/conn.py", line 29, in <module>
    from kafka.protocol.fetch import FetchRequest
  File "/home/airflow/.local/lib/python3.12/site-packages/kafka/protocol/fetch.py", line 9, in <module>
    AbortedTransaction = collections.namedtuple("AbortedTransaction",
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/collections/__init__.py", line 441, in namedtuple
    __new__ = eval(code, namespace)
              ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/airflow.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#reducing-dag-complexity, PID: 95
[2025-12-13T19:12:46.993+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:12:47.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 33.681 seconds
[2025-12-13T19:13:24.824+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:13:24.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:13:24.887+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:13:24.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:30:09.528+0000] {processor.py:186} INFO - Started process (PID=30) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:30:09.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:30:09.532+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:30:09.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:30:14.063+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:30:15.042+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:30:15.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:30:15.104+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:30:15.103+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:30:15.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 5.679 seconds
[2025-12-13T19:30:45.514+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:30:45.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:30:45.521+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:30:45.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:31:07.240+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:31:07.602+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:31:07.599+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:31:07.825+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:31:07.824+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:31:08.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 22.394 seconds
[2025-12-13T19:31:39.573+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:31:39.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:31:39.744+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:31:39.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:32:03.279+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:32:05.386+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:32:05.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:32:05.567+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:32:05.567+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:32:05.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 25.746 seconds
[2025-12-13T19:32:40.177+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:32:40.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:32:40.415+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:32:40.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:33:09.286+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:33:09.430+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:33:09.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:33:09.577+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:33:09.577+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:33:09.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 30.030 seconds
[2025-12-13T19:33:41.079+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:33:41.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:33:41.301+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:33:41.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:34:09.327+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:34:09.452+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:34:09.452+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:34:09.507+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:34:09.507+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:34:09.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 28.261 seconds
[2025-12-13T19:34:40.888+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:34:40.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:34:41.044+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:34:41.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:34:50.264+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:34:50.305+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:34:50.304+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:34:50.316+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:34:50.316+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:34:50.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 9.568 seconds
[2025-12-13T19:35:21.356+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:35:21.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:35:21.468+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:35:21.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:35:28.794+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:35:28.824+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:35:28.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:35:28.841+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:35:28.841+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:35:28.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 7.670 seconds
[2025-12-13T19:35:59.845+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:35:59.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:35:59.945+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:35:59.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:36:08.119+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:36:08.177+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:36:08.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:36:08.197+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:36:08.197+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:36:08.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 8.412 seconds
[2025-12-13T19:36:40.019+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:36:40.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:36:40.149+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:36:40.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:36:50.484+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:36:50.533+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:36:50.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:36:50.554+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:36:50.554+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:36:50.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 10.719 seconds
[2025-12-13T19:37:21.461+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:37:21.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:37:21.536+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:37:21.530+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:37:27.332+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:37:30.127+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:37:30.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:37:30.385+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:37:30.385+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:37:30.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 8.850 seconds
[2025-12-13T19:38:02.009+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:38:02.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:38:02.167+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:38:02.151+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:38:12.316+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:38:12.365+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:38:12.364+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:38:12.410+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:38:12.410+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:38:12.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 10.685 seconds
[2025-12-13T19:38:44.321+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:38:44.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:38:44.456+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:38:44.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:38:51.102+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:38:51.145+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:38:51.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:38:51.200+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:38:51.199+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:38:51.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 7.301 seconds
[2025-12-13T19:39:22.367+0000] {processor.py:186} INFO - Started process (PID=222) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:39:22.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:39:22.413+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:39:22.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:39:32.841+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:39:32.965+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:39:32.965+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:39:33.060+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:39:33.060+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:39:33.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 10.792 seconds
[2025-12-13T19:40:03.856+0000] {processor.py:186} INFO - Started process (PID=233) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:40:03.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:40:03.905+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:40:03.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:40:03.959+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:40:03.951+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 596
    TARGET_FILE = "final_data.csv"
                                  ^
IndentationError: unindent does not match any outer indentation level
[2025-12-13T19:40:03.960+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:40:04.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.373 seconds
[2025-12-13T19:40:04.754+0000] {processor.py:186} INFO - Started process (PID=234) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:40:04.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:40:04.758+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:40:04.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:40:23.535+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:40:23.627+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:40:23.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:40:23.684+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:40:23.683+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:40:23.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 19.089 seconds
[2025-12-13T19:40:55.803+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:40:55.808+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:40:55.867+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:40:55.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:41:02.394+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:41:03.903+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:41:03.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:41:04.009+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:41:04.008+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:41:04.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 8.376 seconds
[2025-12-13T19:41:34.557+0000] {processor.py:186} INFO - Started process (PID=262) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:41:34.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:41:34.581+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:41:34.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:41:36.862+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:41:36.881+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:41:36.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:41:36.892+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:41:36.892+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:41:36.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.376 seconds
[2025-12-13T19:42:07.138+0000] {processor.py:186} INFO - Started process (PID=273) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:42:07.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:42:07.153+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:42:07.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:42:09.889+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:42:09.957+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:42:09.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:42:10.038+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:42:10.038+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:42:10.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.990 seconds
[2025-12-13T19:42:40.541+0000] {processor.py:186} INFO - Started process (PID=284) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:42:40.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:42:40.560+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:42:40.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:42:44.348+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:42:44.395+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:42:44.394+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:42:44.440+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:42:44.439+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:42:44.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.931 seconds
[2025-12-13T19:43:15.313+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:43:15.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:43:15.327+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:43:15.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:43:21.975+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:43:22.050+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:43:22.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:43:22.114+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:43:22.113+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:43:22.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 6.907 seconds
[2025-12-13T19:43:53.465+0000] {processor.py:186} INFO - Started process (PID=317) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:43:53.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:43:53.509+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:43:53.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:44:04.888+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:44:04.942+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:44:04.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:44:04.969+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:44:04.969+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:44:05.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 11.628 seconds
[2025-12-13T19:44:37.677+0000] {processor.py:186} INFO - Started process (PID=333) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:44:37.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:44:37.848+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:44:37.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:44:59.270+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:44:59.878+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:44:59.866+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:44:59.991+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:44:59.991+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:45:00.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 22.498 seconds
[2025-12-13T19:45:31.747+0000] {processor.py:186} INFO - Started process (PID=350) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:45:31.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:45:31.938+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:45:31.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:45:57.852+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:45:57.906+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:45:57.905+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:45:57.965+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:45:57.965+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:45:58.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 26.506 seconds
[2025-12-13T19:46:29.718+0000] {processor.py:186} INFO - Started process (PID=361) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:46:29.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:46:29.978+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:46:29.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:46:38.325+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:46:38.426+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:46:38.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:46:38.447+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:46:38.446+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:46:38.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 9.074 seconds
[2025-12-13T19:47:04.376+0000] {processor.py:186} INFO - Started process (PID=377) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:47:04.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:47:04.623+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:47:04.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:47:25.604+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:47:25.696+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:47:25.695+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:47:25.740+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:47:25.740+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:47:25.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 21.761 seconds
[2025-12-13T19:47:57.162+0000] {processor.py:186} INFO - Started process (PID=394) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:47:57.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:47:57.232+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:47:57.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:48:24.635+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:48:42.968+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:48:42.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:48:43.059+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:48:43.058+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:48:43.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 46.235 seconds
[2025-12-13T19:48:59.567+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:48:59.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:48:59.571+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:48:59.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:49:04.274+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:49:04.340+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:04.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:49:04.374+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:04.374+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:49:04.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 4.771 seconds
[2025-12-13T19:49:09.764+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:49:09.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:49:09.777+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:09.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:49:15.357+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:49:15.466+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:15.465+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'stock_portfolio_pipeline_datafrogs', 'Task Id': 'clean_missing_values', 'Run Id': 'manual__2025-12-13T19:47:22.009225+00:00', 'Hostname': 'fc66782e0078', 'External Executor Id': '2044c6b4-35ab-4f93-8712-dff93c7b1820'}
[2025-12-13T19:49:15.647+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:15.646+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=stock_portfolio_pipeline_datafrogs, task_id=clean_missing_values, run_id=manual__2025-12-13T19:47:22.009225+00:00, execution_date=20251213T194722, start_date=20251213T194737, end_date=20251213T194915
[2025-12-13T19:49:15.779+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:15.778+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: stock_portfolio_pipeline_datafrogs.clean_missing_values manual__2025-12-13T19:47:22.009225+00:00 [up_for_retry]> in state up_for_retry
[2025-12-13T19:49:15.944+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:15.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:49:16.142+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:16.132+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:49:16.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 6.560 seconds
[2025-12-13T19:49:20.185+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:49:20.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:49:20.242+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:20.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:49:26.477+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:49:26.490+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:26.490+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'stock_portfolio_pipeline_datafrogs', 'Task Id': 'prepare_streaming_data', 'Run Id': 'manual__2025-12-13T19:47:22.009225+00:00', 'Hostname': 'fc66782e0078', 'External Executor Id': '21c86c9d-d412-46dd-9f5a-1a6958e62e05'}
[2025-12-13T19:49:26.503+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:26.503+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=stock_portfolio_pipeline_datafrogs, task_id=prepare_streaming_data, run_id=manual__2025-12-13T19:47:22.009225+00:00, execution_date=20251213T194722, start_date=20251213T194737, end_date=20251213T194926
[2025-12-13T19:49:26.516+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:26.516+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: stock_portfolio_pipeline_datafrogs.prepare_streaming_data manual__2025-12-13T19:47:22.009225+00:00 [up_for_retry]> in state up_for_retry
[2025-12-13T19:49:26.518+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:26.518+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'stock_portfolio_pipeline_datafrogs', 'Task Id': 'prepare_streaming_data', 'Run Id': 'manual__2025-12-13T19:47:22.009225+00:00', 'Hostname': 'fc66782e0078', 'External Executor Id': '21c86c9d-d412-46dd-9f5a-1a6958e62e05'}
[2025-12-13T19:49:26.522+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:26.522+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=stock_portfolio_pipeline_datafrogs, task_id=prepare_streaming_data, run_id=manual__2025-12-13T19:47:22.009225+00:00, execution_date=20251213T194722, start_date=20251213T194737, end_date=20251213T194926
[2025-12-13T19:49:26.525+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:26.525+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: stock_portfolio_pipeline_datafrogs.prepare_streaming_data manual__2025-12-13T19:47:22.009225+00:00 [up_for_retry]> in state up_for_retry
[2025-12-13T19:49:26.538+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:26.538+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:49:26.547+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:26.547+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:49:26.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 6.449 seconds
[2025-12-13T19:49:56.842+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:49:56.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:49:56.856+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:56.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:49:58.359+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:49:58.380+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:58.380+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:49:58.398+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:49:58.397+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:49:58.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.584 seconds
[2025-12-13T19:50:28.879+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:50:28.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:50:28.896+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:50:28.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:50:33.236+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:50:33.279+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:50:33.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:50:33.303+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:50:33.303+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:50:33.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 4.458 seconds
[2025-12-13T19:50:44.153+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:50:44.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:50:44.159+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:50:44.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:50:44.168+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:50:44.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.044 seconds
[2025-12-13T19:51:14.519+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:51:14.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:51:14.525+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:51:14.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:51:15.511+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:51:15.526+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:51:15.525+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:51:15.535+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:51:15.535+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:51:15.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.036 seconds
[2025-12-13T19:51:45.841+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:51:45.842+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:51:45.844+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:51:45.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:51:46.601+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:51:46.623+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:51:46.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:51:46.634+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:51:46.634+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:51:46.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.805 seconds
[2025-12-13T19:52:16.868+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:52:16.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:52:16.874+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:52:16.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:52:17.812+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:52:17.827+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:52:17.827+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:52:17.837+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:52:17.837+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:52:17.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.983 seconds
[2025-12-13T19:52:48.166+0000] {processor.py:186} INFO - Started process (PID=126) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:52:48.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:52:48.173+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:52:48.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:52:49.167+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:52:49.181+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:52:49.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:52:49.193+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:52:49.193+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:52:49.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.048 seconds
[2025-12-13T19:52:56.217+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:52:56.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:52:56.220+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:52:56.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:52:57.290+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:52:57.310+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:52:57.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:52:57.326+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:52:57.326+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:52:57.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.131 seconds
[2025-12-13T19:53:01.333+0000] {processor.py:186} INFO - Started process (PID=142) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:53:01.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:53:01.342+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:53:01.340+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:53:02.938+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:53:02.961+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:53:02.961+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:53:02.996+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:53:02.996+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:53:03.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.695 seconds
[2025-12-13T19:53:37.443+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:53:37.449+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:53:37.467+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:53:37.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:54:08.626+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:54:08.606+0000] {timeout.py:68} ERROR - Process timed out, PID: 160
[2025-12-13T19:54:08.936+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:54:08.635+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 2, in <module>
    from sklearn import preprocessing
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/__init__.py", line 70, in <module>
    from sklearn.base import clone  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/base.py", line 19, in <module>
    from sklearn.utils._metadata_requests import _MetadataRequester, _routing_enabled
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/__init__.py", line 9, in <module>
    from sklearn.utils._chunking import gen_batches, gen_even_slices
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_chunking.py", line 11, in <module>
    from sklearn.utils._param_validation import Interval, validate_params
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py", line 17, in <module>
    from sklearn.utils.validation import _is_arraylike_not_scalar
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/validation.py", line 24, in <module>
    from sklearn.utils._array_api import (
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_array_api.py", line 13, in <module>
    import scipy.special as special
  File "/home/airflow/.local/lib/python3.12/site-packages/scipy/special/__init__.py", line 798, in <module>
    from . import _orthogonal
  File "/home/airflow/.local/lib/python3.12/site-packages/scipy/special/_orthogonal.py", line 81, in <module>
    from scipy import linalg
  File "<frozen importlib._bootstrap>", line 1412, in _handle_fromlist
  File "/home/airflow/.local/lib/python3.12/site-packages/scipy/__init__.py", line 131, in __getattr__
    return _importlib.import_module(f'scipy.{name}')
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/scipy/linalg/__init__.py", line 203, in <module>
    from ._misc import *
  File "/home/airflow/.local/lib/python3.12/site-packages/scipy/linalg/_misc.py", line 4, in <module>
    from .lapack import get_lapack_funcs
  File "/home/airflow/.local/lib/python3.12/site-packages/scipy/linalg/lapack.py", line 871, in <module>
    from scipy.linalg import _flapack
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/airflow.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#reducing-dag-complexity, PID: 160
[2025-12-13T19:54:08.990+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:54:09.161+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 30.743 seconds
[2025-12-13T19:54:49.537+0000] {processor.py:186} INFO - Started process (PID=170) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:54:49.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:54:49.587+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:54:49.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:55:38.829+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:55:38.749+0000] {timeout.py:68} ERROR - Process timed out, PID: 170
[2025-12-13T19:55:55.151+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:55:55.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:55:55.166+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:55:55.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:55:56.179+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:55:56.349+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:55:56.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:55:56.362+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:55:56.362+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:55:56.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.652 seconds
[2025-12-13T19:56:26.869+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:56:26.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:56:26.875+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:56:26.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:56:27.857+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:56:27.873+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:56:27.873+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:56:27.883+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:56:27.883+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:56:27.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.030 seconds
[2025-12-13T19:56:41.041+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:56:41.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:56:41.046+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:56:41.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:56:42.274+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:56:42.602+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:56:42.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:56:42.657+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:56:42.657+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:56:42.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.665 seconds
[2025-12-13T19:56:54.943+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:56:54.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:56:54.956+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:56:54.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:56:56.273+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:56:56.281+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:56:56.281+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:56:56.293+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:56:56.293+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:56:56.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.384 seconds
[2025-12-13T19:57:26.825+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:57:26.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:57:26.831+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:57:26.830+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:57:29.256+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:57:29.282+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:57:29.282+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:57:29.300+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:57:29.300+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:57:29.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.493 seconds
[2025-12-13T19:57:59.611+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:57:59.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:57:59.622+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:57:59.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:58:01.697+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:58:01.714+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:58:01.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:58:01.727+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:58:01.727+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:58:01.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.147 seconds
[2025-12-13T19:58:38.293+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:58:38.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:58:38.340+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:58:38.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:58:41.629+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:58:41.661+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:58:41.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:58:41.677+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:58:41.676+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:58:41.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.447 seconds
[2025-12-13T19:59:12.007+0000] {processor.py:186} INFO - Started process (PID=127) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:59:12.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:59:12.011+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:59:12.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:59:13.200+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:59:13.233+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:59:13.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:59:13.249+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:59:13.249+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:59:13.262+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.262 seconds
[2025-12-13T19:59:29.393+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/airflow.py
[2025-12-13T19:59:29.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T19:59:29.398+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:59:29.397+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T19:59:30.574+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T19:59:30.816+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:59:30.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T19:59:30.834+0000] {logging_mixin.py:190} INFO - [2025-12-13T19:59:30.834+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T19:59:30.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.485 seconds
[2025-12-13T20:00:02.618+0000] {processor.py:186} INFO - Started process (PID=149) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:00:02.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:00:02.627+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:00:02.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:00:26.060+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:00:26.106+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:00:26.105+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:00:26.141+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:00:26.140+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:00:26.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 23.589 seconds
[2025-12-13T20:00:56.588+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:00:56.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:00:56.601+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:00:56.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:00:58.040+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:00:58.059+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:00:58.059+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:00:58.071+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:00:58.071+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:00:58.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.509 seconds
[2025-12-13T20:01:28.168+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:01:28.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:01:28.174+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:01:28.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:01:29.407+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:01:29.448+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:01:29.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:01:29.469+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:01:29.469+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:01:29.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.323 seconds
[2025-12-13T20:01:59.881+0000] {processor.py:186} INFO - Started process (PID=182) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:01:59.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:01:59.887+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:01:59.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:02:00.718+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:02:00.739+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:02:00.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:02:00.751+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:02:00.751+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:02:00.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.893 seconds
[2025-12-13T20:02:31.140+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:02:31.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:02:31.144+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:02:31.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:02:32.023+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:02:32.038+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:02:32.038+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:02:32.049+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:02:32.049+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:02:32.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.925 seconds
[2025-12-13T20:03:02.451+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:03:02.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:03:02.456+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:03:02.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:03:03.421+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:03:03.442+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:03:03.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:03:03.453+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:03:03.453+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:03:03.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.017 seconds
[2025-12-13T20:03:33.900+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:03:33.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:03:33.906+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:03:33.905+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:03:34.726+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:03:34.743+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:03:34.743+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:03:34.758+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:03:34.758+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:03:34.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.880 seconds
[2025-12-13T20:04:05.263+0000] {processor.py:186} INFO - Started process (PID=225) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:04:05.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:04:05.268+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:04:05.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:04:06.057+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:04:06.079+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:04:06.078+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:04:06.093+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:04:06.092+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:04:06.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.852 seconds
[2025-12-13T20:04:36.734+0000] {processor.py:186} INFO - Started process (PID=236) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:04:36.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:04:36.739+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:04:36.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:04:37.624+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:04:37.646+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:04:37.645+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:04:37.657+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:04:37.657+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:04:37.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.939 seconds
[2025-12-13T20:05:08.173+0000] {processor.py:186} INFO - Started process (PID=247) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:05:08.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:05:08.181+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:05:08.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:05:09.326+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:05:09.348+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:05:09.348+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:05:09.359+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:05:09.359+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:05:09.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.203 seconds
[2025-12-13T20:05:39.482+0000] {processor.py:186} INFO - Started process (PID=258) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:05:39.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:05:39.487+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:05:39.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:05:40.453+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:05:40.468+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:05:40.468+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:05:40.481+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:05:40.480+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:05:40.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.014 seconds
[2025-12-13T20:06:12.170+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:06:12.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:06:12.214+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:06:12.206+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:06:20.487+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:06:20.511+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:06:20.511+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:06:20.528+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:06:20.528+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:06:20.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 9.714 seconds
[2025-12-13T20:06:50.768+0000] {processor.py:186} INFO - Started process (PID=279) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:06:50.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:06:50.777+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:06:50.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:06:51.969+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:06:51.987+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:06:51.987+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:06:51.998+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:06:51.998+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:06:52.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.249 seconds
[2025-12-13T20:07:22.217+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:07:22.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:07:22.225+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:07:22.225+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:07:23.186+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:07:23.212+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:07:23.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:07:23.230+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:07:23.230+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:07:23.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.041 seconds
[2025-12-13T20:07:29.272+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:07:29.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:07:29.276+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:07:29.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:07:30.224+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:07:30.241+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:07:30.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:07:30.253+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:07:30.252+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:07:30.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.002 seconds
[2025-12-13T20:07:31.290+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:07:31.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:07:31.294+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:07:31.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:07:31.943+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:07:31.957+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:07:31.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:07:31.968+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:07:31.968+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:07:31.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.696 seconds
[2025-12-13T20:08:04.043+0000] {processor.py:186} INFO - Started process (PID=316) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:08:04.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:08:04.072+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:08:04.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:08:14.256+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:08:14.364+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:08:14.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:08:14.448+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:08:14.445+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:08:14.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 10.873 seconds
[2025-12-13T20:08:47.185+0000] {processor.py:186} INFO - Started process (PID=326) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:08:47.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:08:47.197+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:08:47.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:08:50.893+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:08:50.928+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:08:50.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:08:50.952+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:08:50.951+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:08:50.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.810 seconds
[2025-12-13T20:09:21.251+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:09:21.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:09:21.258+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:09:21.257+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:09:22.654+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:09:22.675+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:09:22.674+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:09:22.686+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:09:22.686+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:09:22.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.457 seconds
[2025-12-13T20:09:53.063+0000] {processor.py:186} INFO - Started process (PID=352) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:09:53.069+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:09:53.077+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:09:53.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:09:54.064+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:09:54.087+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:09:54.087+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:09:54.100+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:09:54.100+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:09:54.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.053 seconds
[2025-12-13T20:10:24.550+0000] {processor.py:186} INFO - Started process (PID=363) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:10:24.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:10:24.555+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:10:24.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:10:25.535+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:10:25.556+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:10:25.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:10:25.566+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:10:25.566+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:10:25.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.037 seconds
[2025-12-13T20:10:56.110+0000] {processor.py:186} INFO - Started process (PID=374) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:10:56.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:10:56.117+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:10:56.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:10:57.018+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:10:57.037+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:10:57.037+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:10:57.048+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:10:57.047+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:10:57.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.954 seconds
[2025-12-13T20:11:27.806+0000] {processor.py:186} INFO - Started process (PID=385) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:11:27.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:11:27.857+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:11:27.851+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:11:28.997+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:11:29.021+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:11:29.021+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:11:29.033+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:11:29.033+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:11:29.043+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.283 seconds
[2025-12-13T20:11:59.187+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:11:59.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:11:59.194+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:11:59.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:12:00.095+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:12:00.126+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:12:00.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:12:00.143+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:12:00.143+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:12:00.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.980 seconds
[2025-12-13T20:12:30.660+0000] {processor.py:186} INFO - Started process (PID=407) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:12:30.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:12:30.666+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:12:30.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:12:31.639+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:12:31.659+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:12:31.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:12:31.671+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:12:31.671+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:12:31.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.029 seconds
[2025-12-13T20:13:02.083+0000] {processor.py:186} INFO - Started process (PID=418) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:13:02.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:13:02.091+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:13:02.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:13:02.899+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:13:02.912+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:13:02.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:13:02.921+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:13:02.921+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:13:02.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.855 seconds
[2025-12-13T20:13:33.324+0000] {processor.py:186} INFO - Started process (PID=430) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:13:33.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:13:33.331+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:13:33.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:13:34.760+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:13:34.776+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:13:34.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:13:34.792+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:13:34.792+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:13:34.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.488 seconds
[2025-12-13T20:14:05.231+0000] {processor.py:186} INFO - Started process (PID=445) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:14:05.233+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:14:05.247+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:14:05.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:14:47.622+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:14:47.438+0000] {timeout.py:68} ERROR - Process timed out, PID: 445
[2025-12-13T20:14:47.703+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:14:47.644+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 2, in <module>
    from sklearn import preprocessing
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/__init__.py", line 70, in <module>
    from sklearn.base import clone  # noqa: E402
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/base.py", line 19, in <module>
    from sklearn.utils._metadata_requests import _MetadataRequester, _routing_enabled
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/__init__.py", line 9, in <module>
    from sklearn.utils._chunking import gen_batches, gen_even_slices
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_chunking.py", line 11, in <module>
    from sklearn.utils._param_validation import Interval, validate_params
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py", line 17, in <module>
    from sklearn.utils.validation import _is_arraylike_not_scalar
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/validation.py", line 24, in <module>
    from sklearn.utils._array_api import (
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/_array_api.py", line 20, in <module>
    from sklearn.utils.fixes import parse_version
  File "/home/airflow/.local/lib/python3.12/site-packages/sklearn/utils/fixes.py", line 19, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/__init__.py", line 23, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.12/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
  File "<frozen importlib._bootstrap>", line 645, in parent
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/airflow.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.3/best-practices.html#reducing-dag-complexity, PID: 445
[2025-12-13T20:14:47.711+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:14:47.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 42.569 seconds
[2025-12-13T20:15:10.033+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:15:10.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:15:10.043+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:15:10.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:15:11.814+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:15:11.835+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:15:11.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:15:11.844+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:15:11.844+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:15:11.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.806 seconds
[2025-12-13T20:15:42.087+0000] {processor.py:186} INFO - Started process (PID=42) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:15:42.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:15:42.091+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:15:42.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:15:43.876+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:15:43.907+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:15:43.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:15:43.920+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:15:43.920+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:15:43.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.849 seconds
[2025-12-13T20:16:14.188+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:16:14.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:16:14.194+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:16:14.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:16:16.736+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:16:16.754+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:16:16.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:16:16.765+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:16:16.765+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:16:16.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.592 seconds
[2025-12-13T20:16:47.111+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:16:47.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:16:47.122+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:16:47.122+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:16:54.658+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:16:55.276+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:16:55.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:16:55.345+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:16:55.345+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:16:55.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 8.288 seconds
[2025-12-13T20:17:26.231+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:17:26.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:17:26.242+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:17:26.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:17:28.158+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:17:28.197+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:17:28.196+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:17:28.219+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:17:28.219+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:17:28.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.011 seconds
[2025-12-13T20:17:58.495+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:17:58.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:17:58.501+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:17:58.500+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:17:59.443+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:17:59.460+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:17:59.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:17:59.476+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:17:59.476+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:17:59.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.996 seconds
[2025-12-13T20:18:30.125+0000] {processor.py:186} INFO - Started process (PID=108) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:18:30.128+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:18:30.135+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:18:30.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:18:31.129+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:18:31.146+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:18:31.146+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:18:31.166+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:18:31.165+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:18:31.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.065 seconds
[2025-12-13T20:19:01.431+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:19:01.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:19:01.436+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:19:01.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:19:02.430+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:19:02.445+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:19:02.445+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:19:02.460+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:19:02.460+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:19:02.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.045 seconds
[2025-12-13T20:19:32.701+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:19:32.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:19:32.705+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:19:32.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:19:33.878+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:19:33.896+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:19:33.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:19:33.909+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:19:33.909+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:19:33.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.225 seconds
[2025-12-13T20:21:43.269+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:21:43.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:21:43.278+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:21:43.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:21:52.094+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:21:52.351+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:21:52.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:21:52.419+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:21:52.417+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:21:52.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 9.416 seconds
[2025-12-13T20:22:23.599+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:22:23.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:22:23.661+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:22:23.659+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:22:38.012+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:22:40.894+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:22:40.879+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:22:41.213+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:22:41.207+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:22:47.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 23.010 seconds
[2025-12-13T20:23:19.618+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:23:19.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:23:19.712+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:23:19.708+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:23:41.380+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:23:41.672+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:23:41.670+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:23:41.790+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:23:41.790+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:23:41.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 22.508 seconds
[2025-12-13T20:24:13.142+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:24:13.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:24:13.201+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:24:13.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:24:21.653+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:24:21.704+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:24:21.704+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:24:21.732+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:24:21.731+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:24:21.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 8.780 seconds
[2025-12-13T20:24:52.679+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:24:52.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:24:52.716+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:24:52.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:24:58.088+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:24:58.151+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:24:58.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:24:58.200+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:24:58.200+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:24:58.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 5.601 seconds
[2025-12-13T20:25:09.894+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:25:09.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:25:09.913+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:25:09.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:25:17.379+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:25:17.412+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:25:17.412+0000] {taskinstance.py:3313} ERROR - {'DAG Id': 'stock_portfolio_pipeline_datafrogs', 'Task Id': 'consume_and_process_stream', 'Run Id': 'manual__2025-12-13T20:16:28.992248+00:00', 'Hostname': 'fc66782e0078', 'External Executor Id': '8ca8ea34-436a-47fa-a7d3-c833cca03450'}
[2025-12-13T20:25:17.432+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:25:17.432+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=stock_portfolio_pipeline_datafrogs, task_id=consume_and_process_stream, run_id=manual__2025-12-13T20:16:28.992248+00:00, execution_date=20251213T201628, start_date=20251213T201918, end_date=20251213T202517
[2025-12-13T20:25:17.453+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:25:17.453+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: stock_portfolio_pipeline_datafrogs.consume_and_process_stream manual__2025-12-13T20:16:28.992248+00:00 [up_for_retry]> in state up_for_retry
[2025-12-13T20:25:17.464+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:25:17.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:25:17.476+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:25:17.476+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:25:17.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 7.627 seconds
[2025-12-13T20:25:48.355+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:25:48.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:25:48.371+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:25:48.369+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:25:50.587+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:25:50.625+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:25:50.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:25:50.645+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:25:50.644+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:25:50.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.326 seconds
[2025-12-13T20:26:20.792+0000] {processor.py:186} INFO - Started process (PID=126) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:26:20.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:26:20.797+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:26:20.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:26:21.747+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:26:21.763+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:26:21.762+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:26:21.773+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:26:21.773+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:26:21.782+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.998 seconds
[2025-12-13T20:26:52.137+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:26:52.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:26:52.141+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:26:52.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:26:52.910+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:26:52.924+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:26:52.924+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:26:52.934+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:26:52.934+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:26:52.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.812 seconds
[2025-12-13T20:27:23.444+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:27:23.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:27:23.448+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:27:23.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:27:24.105+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:27:24.119+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:27:24.119+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:27:24.128+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:27:24.128+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:27:24.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.699 seconds
[2025-12-13T20:27:54.553+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/airflow.py
[2025-12-13T20:27:54.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T20:27:54.559+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:27:54.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T20:27:55.353+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T20:27:55.369+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:27:55.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T20:27:55.379+0000] {logging_mixin.py:190} INFO - [2025-12-13T20:27:55.379+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T20:27:55.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 0.846 seconds
