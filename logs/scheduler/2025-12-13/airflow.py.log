[2025-12-13T01:11:44.075+0000] {processor.py:186} INFO - Started process (PID=1367) to work on /opt/airflow/dags/airflow.py
[2025-12-13T01:11:44.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T01:11:44.083+0000] {logging_mixin.py:190} INFO - [2025-12-13T01:11:44.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T01:11:47.415+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T01:13:19.492+0000] {logging_mixin.py:190} INFO - [2025-12-13T01:13:19.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T01:13:20.106+0000] {logging_mixin.py:190} INFO - [2025-12-13T01:13:20.106+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-12 00:00:00+00:00, run_after=2025-12-13 00:00:00+00:00
[2025-12-13T09:47:58.021+0000] {processor.py:186} INFO - Started process (PID=1380) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:47:58.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:47:58.028+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:47:58.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:47:59.837+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:48:00.011+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:48:00.010+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:48:00.044+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:48:00.044+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-12 00:00:00+00:00, run_after=2025-12-13 00:00:00+00:00
[2025-12-13T09:48:00.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.073 seconds
[2025-12-13T09:49:34.707+0000] {processor.py:186} INFO - Started process (PID=1397) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:49:34.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:49:34.710+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:34.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:48:04.592+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:48:04.614+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:48:04.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:48:04.655+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:48:04.655+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:48:04.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.112 seconds
[2025-12-13T09:49:44.949+0000] {processor.py:186} INFO - Started process (PID=1424) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:49:44.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:49:44.953+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:44.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:48:15.789+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:48:15.806+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:48:15.805+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:48:15.838+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:48:15.837+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:48:15.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.628 seconds
[2025-12-13T09:49:49.662+0000] {processor.py:186} INFO - Started process (PID=1437) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:49:49.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:49:49.665+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:49.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:51.381+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:51.409+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:51.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:49:51.436+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:51.435+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:49:51.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.803 seconds
[2025-12-13T09:50:21.745+0000] {processor.py:186} INFO - Started process (PID=1456) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:50:21.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:50:21.749+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:21.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:50:23.087+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:50:23.117+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:23.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:50:23.140+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:23.140+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:50:23.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.428 seconds
[2025-12-13T09:50:59.636+0000] {processor.py:186} INFO - Started process (PID=1475) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:50:59.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:50:59.639+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:59.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:28.887+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:28.910+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:28.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:49:28.929+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:28.929+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:49:28.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.143 seconds
[2025-12-13T09:51:19.998+0000] {processor.py:186} INFO - Started process (PID=1494) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:51:20.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:51:20.002+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:51:20.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:49.591+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:49.613+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:49.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:49:49.633+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:49.633+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:49:49.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.332 seconds
[2025-12-13T09:49:52.743+0000] {processor.py:186} INFO - Started process (PID=1507) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:49:52.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:49:52.747+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:52.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:54.685+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:49:54.769+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:54.769+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:49:54.836+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:49:54.836+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:49:54.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.159 seconds
[2025-12-13T09:51:44.568+0000] {processor.py:186} INFO - Started process (PID=1526) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:51:44.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:51:44.571+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:51:44.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:50:14.122+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:50:14.154+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:14.154+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:50:14.180+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:14.180+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:50:14.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.445 seconds
[2025-12-13T09:51:50.102+0000] {processor.py:186} INFO - Started process (PID=1539) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:51:50.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:51:50.106+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:51:50.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T09:50:19.661+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T09:50:19.711+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:19.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T09:50:19.775+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:19.775+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T09:50:19.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.766 seconds
[2025-12-13T09:50:50.614+0000] {processor.py:186} INFO - Started process (PID=1558) to work on /opt/airflow/dags/airflow.py
[2025-12-13T09:50:50.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T09:50:50.619+0000] {logging_mixin.py:190} INFO - [2025-12-13T09:50:50.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:04:19.456+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:04:19.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:04:19.460+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:04:19.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:07:23.641+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:05:51.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:05:51.498+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:05:51.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:05:52.849+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:05:52.980+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:05:52.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:05:53.000+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:05:53.000+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:05:53.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.531 seconds
[2025-12-13T10:07:50.919+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:07:50.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:07:50.921+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:07:50.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:06:20.105+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:06:20.118+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:06:20.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:06:20.146+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:06:20.146+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:06:20.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.407 seconds
[2025-12-13T10:06:38.827+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:06:38.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:06:38.829+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:06:38.829+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:06:40.162+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:06:40.189+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:06:40.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:06:40.208+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:06:40.208+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:06:40.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.402 seconds
[2025-12-13T10:08:23.468+0000] {processor.py:186} INFO - Started process (PID=141) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:08:23.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:08:23.471+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:23.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:06:52.531+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:06:52.556+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:06:52.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:06:52.576+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:06:52.576+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:06:52.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.283 seconds
[2025-12-13T10:07:13.852+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:07:13.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:07:13.855+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:07:13.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:07:14.994+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:07:15.018+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:07:15.018+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:07:15.038+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:07:15.038+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:07:15.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.220 seconds
[2025-12-13T10:07:45.188+0000] {processor.py:186} INFO - Started process (PID=179) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:07:45.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:07:45.191+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:07:45.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:07:46.315+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:07:46.338+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:07:46.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:07:46.357+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:07:46.357+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:07:46.380+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.200 seconds
[2025-12-13T10:08:16.686+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:08:16.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:08:16.688+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:16.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:17.833+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:17.855+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:17.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:08:17.875+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:17.874+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:08:17.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.210 seconds
[2025-12-13T10:10:11.067+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:11.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:11.069+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:11.069+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:40.172+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:40.197+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:40.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:08:40.219+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:40.219+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:08:40.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.326 seconds
[2025-12-13T10:10:16.100+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:16.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:16.103+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:16.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:45.055+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:45.079+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:45.079+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:08:45.098+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:45.098+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:08:45.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.173 seconds
[2025-12-13T10:08:48.995+0000] {processor.py:186} INFO - Started process (PID=243) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:08:48.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:08:48.997+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:48.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:50.305+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:08:50.327+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:50.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:08:50.346+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:08:50.345+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:08:50.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.372 seconds
[2025-12-13T10:09:15.992+0000] {processor.py:186} INFO - Started process (PID=262) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:15.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:15.995+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:15.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:17.298+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:17.400+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:17.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:17.421+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:17.421+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:17.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.475 seconds
[2025-12-13T10:09:17.519+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:17.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:17.522+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:17.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:19.027+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:51.192+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:51.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:51.217+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:51.217+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:51.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.581 seconds
[2025-12-13T10:09:19.171+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:19.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:19.173+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:19.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:20.378+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:20.387+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:20.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:20.406+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:20.406+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:20.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.263 seconds
[2025-12-13T10:09:20.479+0000] {processor.py:186} INFO - Started process (PID=301) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:20.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:20.482+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:20.482+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:21.693+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:21.712+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:21.712+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:21.745+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:21.745+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:21.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.303 seconds
[2025-12-13T10:09:21.877+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:21.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:21.885+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:21.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:24.437+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:24.454+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:24.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:24.490+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:24.490+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:24.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.680 seconds
[2025-12-13T10:09:24.652+0000] {processor.py:186} INFO - Started process (PID=333) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:24.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:24.660+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:24.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:25.922+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:25.933+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:25.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:25.956+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:25.956+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:25.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.331 seconds
[2025-12-13T10:09:26.027+0000] {processor.py:186} INFO - Started process (PID=346) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:26.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:26.030+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:26.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:27.239+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:27.251+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:27.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:27.279+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:27.279+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:27.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.281 seconds
[2025-12-13T10:09:27.362+0000] {processor.py:186} INFO - Started process (PID=359) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:27.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:27.364+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:27.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:28.700+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:28.711+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:28.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:28.732+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:28.732+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:28.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.397 seconds
[2025-12-13T10:09:28.802+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:28.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:28.804+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:28.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:29.922+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:29.933+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:29.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:29.958+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:29.957+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:29.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.179 seconds
[2025-12-13T10:09:30.039+0000] {processor.py:186} INFO - Started process (PID=385) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:30.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:30.043+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:30.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:31.132+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:31.141+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:31.141+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:31.161+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:31.161+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:31.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.144 seconds
[2025-12-13T10:09:31.225+0000] {processor.py:186} INFO - Started process (PID=398) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:31.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:31.228+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:31.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:32.328+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:32.339+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:32.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:32.359+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:32.359+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:32.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.157 seconds
[2025-12-13T10:09:32.425+0000] {processor.py:186} INFO - Started process (PID=411) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:32.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:32.428+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:32.427+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:33.430+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:33.440+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:33.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:33.460+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:33.459+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:33.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.056 seconds
[2025-12-13T10:09:33.530+0000] {processor.py:186} INFO - Started process (PID=424) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:33.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:33.532+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:33.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:34.571+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:34.580+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:34.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:34.599+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:34.599+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:34.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.095 seconds
[2025-12-13T10:09:34.665+0000] {processor.py:186} INFO - Started process (PID=437) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:34.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:34.668+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:34.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:35.774+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:35.784+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:35.784+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:35.803+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:35.803+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:35.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.161 seconds
[2025-12-13T10:09:35.869+0000] {processor.py:186} INFO - Started process (PID=450) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:35.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:35.871+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:35.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:36.898+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:36.907+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:36.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:36.926+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:36.926+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:36.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.080 seconds
[2025-12-13T10:09:36.996+0000] {processor.py:186} INFO - Started process (PID=463) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:36.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:36.998+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:36.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:38.059+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:38.069+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:38.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:38.094+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:38.094+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:38.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.125 seconds
[2025-12-13T10:09:38.171+0000] {processor.py:186} INFO - Started process (PID=476) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:38.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:38.173+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:38.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:39.742+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:39.757+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:39.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:39.801+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:39.800+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:39.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.671 seconds
[2025-12-13T10:09:39.929+0000] {processor.py:186} INFO - Started process (PID=489) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:39.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:39.933+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:39.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:42.016+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:42.028+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:42.028+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:42.057+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:42.056+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:42.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.159 seconds
[2025-12-13T10:09:42.137+0000] {processor.py:186} INFO - Started process (PID=502) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:42.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:42.140+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:42.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:43.423+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:43.435+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:43.435+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:43.459+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:43.459+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:43.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.349 seconds
[2025-12-13T10:09:43.535+0000] {processor.py:186} INFO - Started process (PID=515) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:43.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:43.538+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:43.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:44.376+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:44.385+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:44.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:44.406+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:44.406+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:44.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.179 seconds
[2025-12-13T10:09:44.483+0000] {processor.py:186} INFO - Started process (PID=528) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:44.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:44.487+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:44.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:45.615+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:45.625+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:45.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:45.644+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:45.644+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:45.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.200 seconds
[2025-12-13T10:09:45.731+0000] {processor.py:186} INFO - Started process (PID=541) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:45.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:45.733+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:45.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:46.932+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:46.943+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:46.943+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:46.966+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:46.966+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:46.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.258 seconds
[2025-12-13T10:09:47.040+0000] {processor.py:186} INFO - Started process (PID=554) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:47.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:47.042+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:47.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:48.216+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:48.245+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:48.244+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:48.270+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:48.269+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:48.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.266 seconds
[2025-12-13T10:09:48.364+0000] {processor.py:186} INFO - Started process (PID=567) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:48.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:48.367+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:48.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:49.296+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:49.322+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:49.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:49.348+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:49.347+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:49.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.432 seconds
[2025-12-13T10:09:49.438+0000] {processor.py:186} INFO - Started process (PID=580) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:49.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:49.441+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:49.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:50.606+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:50.633+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:50.633+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:50.655+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:50.655+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:50.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.310 seconds
[2025-12-13T10:09:50.730+0000] {processor.py:186} INFO - Started process (PID=593) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:50.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:50.732+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:50.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:52.050+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:52.072+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:52.072+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:52.091+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:52.091+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:52.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.392 seconds
[2025-12-13T10:09:52.167+0000] {processor.py:186} INFO - Started process (PID=612) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:52.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:52.169+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:52.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:53.297+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:53.319+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:53.319+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:53.340+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:53.340+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:53.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.200 seconds
[2025-12-13T10:09:53.413+0000] {processor.py:186} INFO - Started process (PID=625) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:53.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:53.416+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:53.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:54.222+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:54.242+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:54.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:54.264+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:54.263+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:54.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.221 seconds
[2025-12-13T10:09:54.333+0000] {processor.py:186} INFO - Started process (PID=638) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:54.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:54.336+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:54.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:55.469+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:55.493+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:55.492+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:55.517+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:55.517+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:55.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.206 seconds
[2025-12-13T10:09:55.584+0000] {processor.py:186} INFO - Started process (PID=651) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:55.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:55.587+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:55.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:56.745+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:56.766+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:56.766+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:56.786+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:56.786+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:56.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.225 seconds
[2025-12-13T10:09:56.857+0000] {processor.py:186} INFO - Started process (PID=664) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:56.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:56.859+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:56.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:57.973+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:57.999+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:57.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:58.021+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:58.020+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:58.047+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.196 seconds
[2025-12-13T10:09:58.099+0000] {processor.py:186} INFO - Started process (PID=677) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:58.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:58.101+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:58.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:59.185+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:09:59.207+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:59.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:09:59.226+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:59.226+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:09:59.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.154 seconds
[2025-12-13T10:09:59.290+0000] {processor.py:186} INFO - Started process (PID=690) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:09:59.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:09:59.293+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:09:59.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:00.334+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:00.355+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:00.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:00.373+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:00.373+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:00.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.111 seconds
[2025-12-13T10:10:00.445+0000] {processor.py:186} INFO - Started process (PID=703) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:00.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:00.448+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:00.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:01.513+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:01.551+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:01.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:01.576+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:01.576+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:01.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.158 seconds
[2025-12-13T10:10:01.653+0000] {processor.py:186} INFO - Started process (PID=716) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:01.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:01.656+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:01.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:02.735+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:02.759+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:02.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:02.779+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:02.779+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:02.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.161 seconds
[2025-12-13T10:10:02.859+0000] {processor.py:186} INFO - Started process (PID=729) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:02.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:02.862+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:02.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:03.932+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:03.956+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:03.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:03.977+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:03.977+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:04.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.148 seconds
[2025-12-13T10:10:04.051+0000] {processor.py:186} INFO - Started process (PID=742) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:04.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:04.053+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:04.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:05.245+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:05.273+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:05.273+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:05.299+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:05.298+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:05.317+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.268 seconds
[2025-12-13T10:10:05.372+0000] {processor.py:186} INFO - Started process (PID=755) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:05.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:05.375+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:05.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:06.445+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:06.466+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:06.466+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:06.483+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:06.483+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:06.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.135 seconds
[2025-12-13T10:10:06.548+0000] {processor.py:186} INFO - Started process (PID=768) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:06.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:06.550+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:06.550+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:07.554+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:07.574+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:07.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:07.593+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:07.593+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:07.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.074 seconds
[2025-12-13T10:10:07.664+0000] {processor.py:186} INFO - Started process (PID=781) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:07.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:07.666+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:07.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:08.693+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:08.714+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:08.714+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:08.733+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:08.733+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:08.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.091 seconds
[2025-12-13T10:10:08.797+0000] {processor.py:186} INFO - Started process (PID=794) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:08.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:08.799+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:08.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:09.835+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:09.856+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:09.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:09.876+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:09.875+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:09.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.103 seconds
[2025-12-13T10:10:09.950+0000] {processor.py:186} INFO - Started process (PID=807) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:09.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:09.952+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:09.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:10.977+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:10.996+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:10.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:11.016+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:11.016+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:11.036+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.093 seconds
[2025-12-13T10:10:11.085+0000] {processor.py:186} INFO - Started process (PID=820) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:11.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:11.087+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:11.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:12.113+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:12.136+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:12.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:12.157+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:12.157+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:12.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.096 seconds
[2025-12-13T10:10:12.225+0000] {processor.py:186} INFO - Started process (PID=833) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:12.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:12.227+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:12.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:13.315+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:13.338+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:13.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:13.357+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:13.357+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:13.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.155 seconds
[2025-12-13T10:10:13.426+0000] {processor.py:186} INFO - Started process (PID=846) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:13.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:13.428+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:13.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:14.579+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:14.606+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:14.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:14.626+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:14.626+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:14.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.223 seconds
[2025-12-13T10:10:14.697+0000] {processor.py:186} INFO - Started process (PID=859) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:14.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:14.699+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:14.699+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:15.816+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:15.843+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:15.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:15.866+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:15.866+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:15.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.193 seconds
[2025-12-13T10:10:15.936+0000] {processor.py:186} INFO - Started process (PID=872) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:15.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:15.938+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:15.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:16.979+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:17.000+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:16.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:17.018+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:17.018+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:17.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.110 seconds
[2025-12-13T10:10:17.089+0000] {processor.py:186} INFO - Started process (PID=885) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:17.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:17.091+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:17.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:18.190+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:18.210+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:18.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:18.228+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:18.228+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:18.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.170 seconds
[2025-12-13T10:10:18.340+0000] {processor.py:186} INFO - Started process (PID=898) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:10:18.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:10:18.344+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:18.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:19.500+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:10:19.527+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:19.527+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:10:19.553+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:10:19.553+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:10:19.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.252 seconds
[2025-12-13T10:13:11.405+0000] {processor.py:186} INFO - Started process (PID=929) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:13:11.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:13:11.408+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:11.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:11:40.349+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:11:40.441+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:11:40.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:11:40.458+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:11:40.458+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:11:40.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.232 seconds
[2025-12-13T10:11:44.293+0000] {processor.py:186} INFO - Started process (PID=942) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:11:44.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:11:44.295+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:11:44.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:11:45.390+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:11:45.400+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:11:45.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:11:45.421+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:11:45.420+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:11:45.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.156 seconds
[2025-12-13T10:12:15.633+0000] {processor.py:186} INFO - Started process (PID=961) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:12:15.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:12:15.636+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:12:15.636+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:12:16.705+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:12:16.727+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:12:16.727+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:12:16.747+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:12:16.747+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:12:16.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.143 seconds
[2025-12-13T10:12:46.987+0000] {processor.py:186} INFO - Started process (PID=980) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:12:46.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:12:46.990+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:12:46.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:12:48.070+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:12:48.092+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:12:48.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:12:48.111+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:12:48.111+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:12:48.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.153 seconds
[2025-12-13T10:14:41.483+0000] {processor.py:186} INFO - Started process (PID=999) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:41.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:41.485+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:41.485+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:13:10.370+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:13:10.392+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:10.392+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:13:10.412+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:10.412+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:13:10.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.120 seconds
[2025-12-13T10:14:46.526+0000] {processor.py:186} INFO - Started process (PID=1012) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:46.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:46.528+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:46.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:13:15.408+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:13:15.430+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:15.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:13:15.451+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:15.451+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:13:15.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.130 seconds
[2025-12-13T10:13:45.619+0000] {processor.py:186} INFO - Started process (PID=1031) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:13:45.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:13:45.621+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:45.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:13:46.798+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:13:46.832+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:46.831+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:13:46.856+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:13:46.855+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:13:46.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.271 seconds
[2025-12-13T10:14:00.854+0000] {processor.py:186} INFO - Started process (PID=1050) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:00.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:00.857+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:00.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:02.618+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:02.643+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:02.643+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:02.666+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:02.666+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:02.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.847 seconds
[2025-12-13T10:14:02.752+0000] {processor.py:186} INFO - Started process (PID=1063) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:02.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:02.755+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:02.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:03.891+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:03.924+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:03.924+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:03.946+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:03.946+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:03.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.219 seconds
[2025-12-13T10:14:04.024+0000] {processor.py:186} INFO - Started process (PID=1076) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:04.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:04.026+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:04.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:05.141+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:05.162+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:05.162+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:05.181+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:05.181+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:05.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.180 seconds
[2025-12-13T10:14:05.245+0000] {processor.py:186} INFO - Started process (PID=1089) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:05.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:05.247+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:05.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:06.266+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:06.289+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:06.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:06.309+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:06.309+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:06.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.086 seconds
[2025-12-13T10:14:06.384+0000] {processor.py:186} INFO - Started process (PID=1102) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:06.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:06.387+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:06.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:07.436+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:07.457+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:07.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:07.475+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:07.475+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:07.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.119 seconds
[2025-12-13T10:14:07.547+0000] {processor.py:186} INFO - Started process (PID=1115) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:07.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:07.550+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:07.549+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:08.670+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:08.693+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:08.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:08.713+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:08.712+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:08.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.192 seconds
[2025-12-13T10:14:08.784+0000] {processor.py:186} INFO - Started process (PID=1128) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:08.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:08.786+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:08.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:09.885+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:09.911+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:09.911+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:09.935+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:09.935+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:09.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.181 seconds
[2025-12-13T10:14:10.011+0000] {processor.py:186} INFO - Started process (PID=1141) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:10.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:10.015+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:10.014+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:11.203+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:11.232+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:11.231+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:11.259+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:11.259+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:11.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.275 seconds
[2025-12-13T10:14:11.341+0000] {processor.py:186} INFO - Started process (PID=1154) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:11.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:11.345+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:11.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:12.622+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:12.647+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:12.647+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:12.687+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:12.684+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:12.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.378 seconds
[2025-12-13T10:14:12.761+0000] {processor.py:186} INFO - Started process (PID=1167) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:12.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:12.763+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:12.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:14.381+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:14.410+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:14.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:14.435+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:14.434+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:14.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.700 seconds
[2025-12-13T10:15:46.545+0000] {processor.py:186} INFO - Started process (PID=1180) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:15:46.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:15:46.548+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:15:46.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:15.528+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:15.553+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:15.553+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:15.572+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:15.572+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:15.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.211 seconds
[2025-12-13T10:14:15.647+0000] {processor.py:186} INFO - Started process (PID=1193) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:15.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:15.649+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:15.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:16.794+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:16.823+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:16.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:16.850+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:16.850+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:16.874+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.234 seconds
[2025-12-13T10:14:16.934+0000] {processor.py:186} INFO - Started process (PID=1206) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:16.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:16.936+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:16.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:18.198+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:14:18.227+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:18.227+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:14:18.253+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:18.253+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:14:18.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.352 seconds
[2025-12-13T10:14:18.342+0000] {processor.py:186} INFO - Started process (PID=1219) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:14:18.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:14:18.344+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:14:18.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:17:11.755+0000] {processor.py:186} INFO - Started process (PID=1250) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:17:11.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:17:11.758+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:17:11.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:15:40.750+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:15:40.847+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:15:40.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:15:40.865+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:15:40.865+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:15:40.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.291 seconds
[2025-12-13T10:15:44.646+0000] {processor.py:186} INFO - Started process (PID=1263) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:15:44.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:15:44.649+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:15:44.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:15:45.712+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:15:45.723+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:15:45.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:15:45.744+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:15:45.744+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:15:45.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.129 seconds
[2025-12-13T10:16:15.951+0000] {processor.py:186} INFO - Started process (PID=1282) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:16:15.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:16:15.953+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:16:15.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:16:16.981+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:16:17.003+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:16:17.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:16:17.022+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:16:17.021+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:16:17.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.094 seconds
[2025-12-13T10:16:47.374+0000] {processor.py:186} INFO - Started process (PID=1301) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:16:47.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:16:47.376+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:16:47.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:16:48.421+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:16:48.444+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:16:48.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:16:48.465+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:16:48.465+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:16:48.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.121 seconds
[2025-12-13T10:17:14.781+0000] {processor.py:186} INFO - Started process (PID=1320) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:17:14.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:17:14.784+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:17:14.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:17:15.799+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:17:15.820+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:17:15.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:17:15.838+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:17:15.838+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:17:15.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.078 seconds
[2025-12-13T10:17:46.139+0000] {processor.py:186} INFO - Started process (PID=1339) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:17:46.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:17:46.141+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:17:46.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:17:47.209+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:17:47.233+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:17:47.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:17:47.254+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:17:47.254+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:17:47.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.146 seconds
[2025-12-13T10:18:17.497+0000] {processor.py:186} INFO - Started process (PID=1358) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:18:17.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:18:17.499+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:18:17.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:18:18.570+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:18:18.593+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:18:18.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:18:18.619+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:18:18.619+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:18:18.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.151 seconds
[2025-12-13T10:19:28.133+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:19:28.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:19:28.139+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:19:28.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:19:31.322+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:19:31.362+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:19:31.362+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:19:31.383+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:19:31.383+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:19:31.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.293 seconds
[2025-12-13T10:20:01.678+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:20:01.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:20:01.685+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:01.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:03.695+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:03.744+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:03.744+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:20:03.781+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:03.780+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:20:03.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.145 seconds
[2025-12-13T10:21:51.096+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:21:51.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:21:51.100+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:21:51.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:20.285+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:20.313+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:20.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:20:20.352+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:20.351+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:20:20.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.443 seconds
[2025-12-13T10:22:02.184+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:22:02.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:22:02.189+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:22:02.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:32.029+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:32.052+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:32.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:20:32.073+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:32.073+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:20:32.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.068 seconds
[2025-12-13T10:20:35.082+0000] {processor.py:186} INFO - Started process (PID=141) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:20:35.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:20:35.086+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:35.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:36.312+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:20:36.335+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:36.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:20:36.354+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:20:36.354+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:20:36.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.308 seconds
[2025-12-13T10:21:06.648+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:21:06.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:21:06.656+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:21:06.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:21:07.829+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:21:07.849+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:21:07.849+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:21:07.869+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:21:07.869+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:21:07.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.250 seconds
[2025-12-13T10:21:19.006+0000] {processor.py:186} INFO - Started process (PID=173) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:21:19.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:21:19.009+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:21:19.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:21:20.250+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:21:20.270+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:21:20.270+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:21:20.290+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:21:20.290+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:21:20.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.309 seconds
[2025-12-13T10:22:45.091+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:22:45.093+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:22:45.095+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:22:45.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:22:48.105+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:22:48.149+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:22:48.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:22:48.191+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:22:48.191+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:22:48.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.147 seconds
[2025-12-13T10:24:27.365+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:24:27.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:24:27.370+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:27.370+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:22:56.710+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:22:56.732+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:22:56.732+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:22:56.755+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:22:56.754+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:22:56.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.570 seconds
[2025-12-13T10:23:27.043+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:23:27.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:23:27.047+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:23:27.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:23:28.434+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:23:28.456+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:23:28.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:23:28.477+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:23:28.477+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:23:28.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.457 seconds
[2025-12-13T10:23:58.770+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:23:58.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:23:58.774+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:23:58.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:23:59.955+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:23:59.976+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:23:59.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:23:59.994+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:23:59.994+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:24:00.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.244 seconds
[2025-12-13T10:24:30.464+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:24:30.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:24:30.468+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:30.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:24:31.453+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:24:31.489+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:31.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:24:31.520+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:31.520+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:24:31.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.503 seconds
[2025-12-13T10:26:22.511+0000] {processor.py:186} INFO - Started process (PID=167) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:26:22.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:26:22.515+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:26:22.514+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:24:51.927+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:24:51.950+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:51.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:24:51.974+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:51.974+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:24:51.995+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.649 seconds
[2025-12-13T10:24:55.444+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:24:55.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:24:55.448+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:55.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:24:56.710+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:24:56.731+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:56.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:24:56.749+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:24:56.749+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:24:56.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.334 seconds
[2025-12-13T10:25:27.139+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:25:27.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:25:27.144+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:25:27.143+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:25:28.351+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:25:28.386+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:25:28.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:25:28.422+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:25:28.422+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:25:28.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.318 seconds
[2025-12-13T10:25:58.676+0000] {processor.py:186} INFO - Started process (PID=218) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:25:58.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:25:58.680+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:25:58.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:27:32.582+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:27:32.625+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:32.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:26:00.505+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:26:00.505+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:26:00.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.898 seconds
[2025-12-13T10:27:47.654+0000] {processor.py:186} INFO - Started process (PID=231) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:27:47.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:27:47.658+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:47.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:26:16.807+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:26:16.836+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:26:16.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:26:16.860+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:26:16.860+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:26:16.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.392 seconds
[2025-12-13T10:26:47.089+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:26:47.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:26:47.093+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:26:47.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:26:48.503+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:26:48.540+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:26:48.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:26:48.572+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:26:48.572+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:26:48.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.495 seconds
[2025-12-13T10:27:17.279+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:27:17.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:27:17.284+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:17.284+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:27:18.672+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:27:18.695+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:18.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:27:18.715+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:18.715+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:27:18.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.464 seconds
[2025-12-13T10:27:48.953+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:27:48.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:27:48.956+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:48.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:27:50.215+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:27:50.237+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:50.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:27:50.258+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:27:50.258+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:27:50.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.330 seconds
[2025-12-13T10:28:20.587+0000] {processor.py:186} INFO - Started process (PID=314) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:28:20.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:28:20.593+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:20.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:28:21.749+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:28:21.772+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:21.772+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:28:21.791+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:21.791+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:28:21.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.235 seconds
[2025-12-13T10:30:02.832+0000] {processor.py:186} INFO - Started process (PID=327) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:30:02.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:30:02.836+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:30:02.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:28:31.822+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:28:31.844+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:31.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:28:31.863+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:31.863+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:28:31.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.213 seconds
[2025-12-13T10:28:35.738+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:28:35.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:28:35.748+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:35.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:28:36.871+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:28:36.892+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:36.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:28:36.910+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:28:36.910+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:28:36.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.203 seconds
[2025-12-13T10:29:07.041+0000] {processor.py:186} INFO - Started process (PID=359) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:29:07.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:29:07.048+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:07.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:29:08.325+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:29:08.368+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:08.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:29:08.398+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:08.398+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:29:08.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.402 seconds
[2025-12-13T10:29:38.529+0000] {processor.py:186} INFO - Started process (PID=378) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:29:38.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:29:38.536+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:38.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:29:39.846+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:29:39.867+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:39.867+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:29:39.887+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:39.887+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:29:39.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.384 seconds
[2025-12-13T10:29:45.887+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:29:45.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:29:45.890+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:45.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:29:46.962+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:29:46.984+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:46.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:29:47.005+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:29:47.005+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:29:47.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.148 seconds
[2025-12-13T10:31:48.863+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:31:48.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:30:16.704+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:30:16.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:30:18.017+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:30:18.049+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:30:18.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:30:18.080+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:30:18.080+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:30:18.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.415 seconds
[2025-12-13T10:30:48.526+0000] {processor.py:186} INFO - Started process (PID=435) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:30:48.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:30:48.531+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:30:48.530+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:30:49.669+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:30:49.691+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:30:49.691+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:30:49.710+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:30:49.710+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:30:49.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.209 seconds
[2025-12-13T10:31:19.945+0000] {processor.py:186} INFO - Started process (PID=454) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:31:19.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:31:19.949+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:31:19.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:31:21.185+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:31:21.210+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:31:21.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:31:21.238+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:31:21.238+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:31:21.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.311 seconds
[2025-12-13T10:33:13.274+0000] {processor.py:186} INFO - Started process (PID=467) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:33:13.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:33:13.278+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:13.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:31:42.437+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:31:42.462+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:31:42.461+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:31:42.495+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:31:42.494+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:31:42.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.413 seconds
[2025-12-13T10:33:28.701+0000] {processor.py:186} INFO - Started process (PID=486) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:33:28.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:33:28.705+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:28.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:33:29.931+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:33:29.954+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:29.953+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:33:29.975+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:29.975+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:33:29.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.295 seconds
[2025-12-13T10:32:45.134+0000] {processor.py:186} INFO - Started process (PID=505) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:32:45.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:32:45.138+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:32:45.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:32:46.322+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:32:46.344+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:32:46.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:32:46.365+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:32:46.364+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:32:46.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.254 seconds
[2025-12-13T10:34:33.378+0000] {processor.py:186} INFO - Started process (PID=524) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:34:33.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:34:33.382+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:34:33.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:33:02.443+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:33:02.464+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:02.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:33:02.483+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:02.482+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:33:02.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.306 seconds
[2025-12-13T10:33:32.680+0000] {processor.py:186} INFO - Started process (PID=543) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:33:32.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:33:32.684+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:32.683+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:33:33.731+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:33:33.752+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:33.752+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:33:33.771+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:33:33.771+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:33:33.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.113 seconds
[2025-12-13T10:34:03.944+0000] {processor.py:186} INFO - Started process (PID=562) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:34:03.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:34:03.948+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:34:03.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:34:04.960+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:34:04.983+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:34:04.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:34:05.013+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:34:05.012+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:34:05.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.096 seconds
[2025-12-13T10:34:35.192+0000] {processor.py:186} INFO - Started process (PID=581) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:34:35.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:34:35.195+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:34:35.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:34:36.244+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:34:36.266+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:34:36.266+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:34:36.284+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:34:36.284+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:36:08.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.120 seconds
[2025-12-13T10:36:15.131+0000] {processor.py:186} INFO - Started process (PID=612) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:36:15.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:36:15.134+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:36:15.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:36:16.264+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:37:48.629+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:37:48.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:37:48.651+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:37:48.651+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:37:48.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.382 seconds
[2025-12-13T10:36:46.823+0000] {processor.py:186} INFO - Started process (PID=637) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:36:46.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:36:46.825+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:36:46.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:36:47.973+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:36:47.996+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:36:47.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:36:48.016+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:36:48.016+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:36:48.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.222 seconds
[2025-12-13T10:37:16.592+0000] {processor.py:186} INFO - Started process (PID=656) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:37:16.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:37:16.594+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:37:16.594+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:37:17.701+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:37:17.723+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:37:17.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:37:17.742+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:37:17.741+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:37:17.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.172 seconds
[2025-12-13T10:39:13.731+0000] {processor.py:186} INFO - Started process (PID=669) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:39:13.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:39:13.733+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:39:13.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:37:42.767+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:37:42.792+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:37:42.792+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:37:42.816+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:37:42.815+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:37:42.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.280 seconds
[2025-12-13T10:46:44.923+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:46:44.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:46:44.928+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:46:44.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:46:48.086+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:46:48.127+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:46:48.127+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:46:48.150+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:46:48.149+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:46:48.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.257 seconds
[2025-12-13T10:48:39.511+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:48:39.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:48:39.516+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:39.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:08.600+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:08.620+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:08.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:47:08.637+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:08.637+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:47:08.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.343 seconds
[2025-12-13T10:47:12.404+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:47:12.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:47:12.409+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:12.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:14.197+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:14.223+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:14.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:47:14.253+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:14.253+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:47:14.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.883 seconds
[2025-12-13T10:48:49.532+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:48:49.534+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:48:49.538+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:49.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:19.069+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:19.107+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:19.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:47:19.135+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:19.135+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:47:19.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.812 seconds
[2025-12-13T10:49:09.530+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:49:09.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:49:09.533+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:09.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:38.660+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:38.685+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:38.685+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:47:38.714+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:38.713+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:47:38.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.379 seconds
[2025-12-13T10:47:42.413+0000] {processor.py:186} INFO - Started process (PID=149) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:47:42.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:47:42.417+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:42.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:43.604+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:43.626+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:43.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:47:43.645+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:43.645+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:47:43.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.256 seconds
[2025-12-13T10:49:24.555+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:49:24.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:49:24.559+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:24.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:53.762+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:47:53.788+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:53.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:47:53.809+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:47:53.809+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:47:53.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.453 seconds
[2025-12-13T10:48:10.753+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:48:10.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:48:10.758+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:10.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:12.025+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:12.048+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:12.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:48:12.067+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:12.066+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:48:12.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.338 seconds
[2025-12-13T10:48:42.393+0000] {processor.py:186} INFO - Started process (PID=200) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:48:42.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:48:42.398+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:42.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:43.661+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:43.683+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:43.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:48:43.700+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:43.700+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:48:43.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.326 seconds
[2025-12-13T10:50:19.651+0000] {processor.py:186} INFO - Started process (PID=213) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:50:19.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:50:19.654+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:19.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:48.666+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:48.689+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:48.688+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:48:48.708+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:48.708+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:48:48.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.251 seconds
[2025-12-13T10:48:52.565+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:48:52.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:48:52.569+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:52.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:53.812+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:48:53.836+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:53.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:48:53.859+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:48:53.859+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:48:53.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.331 seconds
[2025-12-13T10:49:24.149+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:49:24.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:49:24.154+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:24.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:49:25.399+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:49:25.420+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:25.420+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:49:25.442+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:25.442+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:49:25.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.324 seconds
[2025-12-13T10:50:59.708+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:50:59.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:50:59.711+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:59.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:49:28.731+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:49:28.756+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:28.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:49:28.781+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:28.780+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:49:28.799+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.268 seconds
[2025-12-13T10:49:32.591+0000] {processor.py:186} INFO - Started process (PID=277) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:49:32.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:49:32.597+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:32.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:49:34.031+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:49:34.056+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:34.056+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:49:34.077+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:49:34.077+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:49:34.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.520 seconds
[2025-12-13T10:50:04.403+0000] {processor.py:186} INFO - Started process (PID=296) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:50:04.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:50:04.407+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:04.407+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:50:05.780+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:50:05.806+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:05.806+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:50:05.829+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:05.829+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:50:05.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.453 seconds
[2025-12-13T10:50:36.058+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:50:36.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:50:36.064+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:36.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:50:37.282+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:50:37.303+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:37.303+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:50:37.323+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:50:37.323+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:50:37.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.289 seconds
[2025-12-13T10:51:07.547+0000] {processor.py:186} INFO - Started process (PID=334) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:51:07.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:51:07.553+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:07.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:08.819+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:08.845+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:08.845+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:51:08.869+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:08.869+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:51:08.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.344 seconds
[2025-12-13T10:52:59.864+0000] {processor.py:186} INFO - Started process (PID=353) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:52:59.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:52:59.868+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:52:59.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:28.899+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:28.923+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:28.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:51:28.944+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:28.944+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:51:28.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.282 seconds
[2025-12-13T10:51:32.756+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:51:32.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:51:32.763+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:32.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:33.859+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:33.881+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:33.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:51:33.899+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:33.899+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:51:33.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.170 seconds
[2025-12-13T10:51:37.797+0000] {processor.py:186} INFO - Started process (PID=379) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:51:37.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:51:37.801+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:37.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:38.873+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:51:38.893+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:38.893+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:51:38.911+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:51:38.911+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:51:38.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.138 seconds
[2025-12-13T10:52:09.064+0000] {processor.py:186} INFO - Started process (PID=398) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:52:09.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:52:09.068+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:52:09.067+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:52:10.113+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:52:10.134+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:52:10.134+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:52:10.152+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:52:10.152+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:52:10.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.120 seconds
[2025-12-13T10:52:41.236+0000] {processor.py:186} INFO - Started process (PID=417) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:52:41.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:52:41.240+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:52:41.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:52:42.423+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:52:42.444+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:52:42.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:52:42.468+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:52:42.467+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:52:42.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.255 seconds
[2025-12-13T10:53:12.740+0000] {processor.py:186} INFO - Started process (PID=436) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:53:12.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:53:12.743+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:53:12.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:53:13.911+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:53:13.936+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:53:13.936+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:53:13.956+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:53:13.956+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:53:13.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.240 seconds
[2025-12-13T10:53:44.475+0000] {processor.py:186} INFO - Started process (PID=455) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:53:44.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:53:44.479+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:53:44.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:53:45.666+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:53:45.687+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:53:45.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:53:45.705+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:53:45.704+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:53:45.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.251 seconds
[2025-12-13T10:55:35.097+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:55:35.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:55:35.101+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:35.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:04.203+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:04.227+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:04.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:54:04.249+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:04.249+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:54:04.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.352 seconds
[2025-12-13T10:55:40.181+0000] {processor.py:186} INFO - Started process (PID=487) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:55:40.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:54:08.016+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:40.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:09.190+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:09.212+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:09.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:54:09.232+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:09.232+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:54:09.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.254 seconds
[2025-12-13T10:54:13.037+0000] {processor.py:186} INFO - Started process (PID=500) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:54:13.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:54:13.041+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:13.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:14.138+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:14.163+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:14.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:54:14.185+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:14.185+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:54:14.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.171 seconds
[2025-12-13T10:54:44.490+0000] {processor.py:186} INFO - Started process (PID=519) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:54:44.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:54:44.494+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:44.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:45.555+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:54:45.579+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:45.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:54:45.600+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:54:45.599+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:54:45.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.134 seconds
[2025-12-13T10:55:15.713+0000] {processor.py:186} INFO - Started process (PID=544) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:55:15.714+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:55:15.717+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:15.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:55:16.859+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:55:16.883+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:16.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:55:16.904+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:16.904+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:55:16.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.220 seconds
[2025-12-13T10:55:23.110+0000] {processor.py:186} INFO - Started process (PID=557) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:55:23.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:55:23.114+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:23.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:55:24.197+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:55:24.222+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:24.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:55:24.241+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:24.241+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:55:24.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.155 seconds
[2025-12-13T10:55:54.524+0000] {processor.py:186} INFO - Started process (PID=576) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:55:54.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:55:54.528+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:54.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:55:55.611+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:55:55.634+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:55.633+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:55:55.653+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:55:55.653+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:55:55.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.158 seconds
[2025-12-13T10:56:25.853+0000] {processor.py:186} INFO - Started process (PID=595) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:56:25.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:56:25.858+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:56:25.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:56:27.029+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:56:27.052+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:56:27.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:56:27.072+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:56:27.072+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:56:27.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.247 seconds
[2025-12-13T10:56:28.188+0000] {processor.py:186} INFO - Started process (PID=608) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:56:28.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:56:28.193+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:56:28.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:56:29.334+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:56:29.360+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:56:29.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:56:29.381+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:56:29.380+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:56:29.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.216 seconds
[2025-12-13T10:56:59.750+0000] {processor.py:186} INFO - Started process (PID=627) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:56:59.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:56:59.756+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:56:59.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:01.064+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:01.093+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:01.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:01.121+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:01.120+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:01.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.408 seconds
[2025-12-13T10:58:40.446+0000] {processor.py:186} INFO - Started process (PID=640) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:40.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:40.451+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:40.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:09.908+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:09.930+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:09.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:09.947+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:09.947+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:09.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.688 seconds
[2025-12-13T10:58:55.463+0000] {processor.py:186} INFO - Started process (PID=659) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:55.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:55.467+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:55.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:24.910+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:24.949+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:24.948+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:24.980+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:24.980+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:25.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.728 seconds
[2025-12-13T10:57:28.333+0000] {processor.py:186} INFO - Started process (PID=672) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:57:28.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:57:28.337+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:28.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:29.418+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:29.440+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:29.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:29.459+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:29.459+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:29.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.155 seconds
[2025-12-13T10:57:53.946+0000] {processor.py:186} INFO - Started process (PID=691) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:57:53.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:57:53.950+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:53.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:55.202+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:55.223+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:55.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:55.245+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:55.244+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:55.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.331 seconds
[2025-12-13T10:57:55.319+0000] {processor.py:186} INFO - Started process (PID=704) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:57:55.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:57:55.323+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:55.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:56.451+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:56.471+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:56.471+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:56.490+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:56.489+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:56.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.193 seconds
[2025-12-13T10:57:56.558+0000] {processor.py:186} INFO - Started process (PID=717) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:57:56.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:57:56.561+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:56.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:57.628+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:57.651+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:57.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:57.671+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:57.671+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:57.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.138 seconds
[2025-12-13T10:57:57.741+0000] {processor.py:186} INFO - Started process (PID=730) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:57:57.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:57:57.745+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:57.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:58.888+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:57:58.910+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:58.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:57:58.933+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:58.932+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:57:58.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.225 seconds
[2025-12-13T10:57:59.020+0000] {processor.py:186} INFO - Started process (PID=743) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:57:59.021+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:57:59.024+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:57:59.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:00.070+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:00.092+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:00.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:58:00.112+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:00.112+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:58:00.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.120 seconds
[2025-12-13T10:58:00.185+0000] {processor.py:186} INFO - Started process (PID=756) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:00.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:00.189+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:00.189+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:01.329+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:01.363+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:01.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:58:01.387+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:01.386+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:58:01.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.234 seconds
[2025-12-13T10:58:01.469+0000] {processor.py:186} INFO - Started process (PID=769) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:01.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:01.473+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:01.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:02.599+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:02.622+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:02.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:58:02.642+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:02.641+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:58:02.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.202 seconds
[2025-12-13T10:58:02.718+0000] {processor.py:186} INFO - Started process (PID=782) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:02.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:02.722+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:02.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:03.829+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:03.854+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:03.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:58:03.876+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:03.876+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:58:03.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.181 seconds
[2025-12-13T10:58:03.955+0000] {processor.py:186} INFO - Started process (PID=795) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:03.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:03.959+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:03.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:33.828+0000] {processor.py:186} INFO - Started process (PID=814) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:33.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:33.832+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:33.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:34.954+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:35.146+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:35.146+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:58:35.163+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:35.163+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:58:35.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.371 seconds
[2025-12-13T10:58:35.235+0000] {processor.py:186} INFO - Started process (PID=827) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:35.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:35.237+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:35.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:36.300+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:58:36.310+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:36.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:58:36.330+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:36.330+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:58:36.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.119 seconds
[2025-12-13T10:58:36.403+0000] {processor.py:186} INFO - Started process (PID=840) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:58:36.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:58:36.406+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:58:36.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:43.052+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:43.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:43.056+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:43.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:46.150+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:46.186+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:46.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:46.207+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:46.207+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:46.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.185 seconds
[2025-12-13T10:59:46.296+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:46.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:46.301+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:46.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:47.991+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:48.025+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:48.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:48.056+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:48.056+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:48.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.795 seconds
[2025-12-13T10:59:48.152+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:48.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:48.156+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:48.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:49.555+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:49.579+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:49.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:49.601+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:49.601+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:49.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.473 seconds
[2025-12-13T10:59:49.679+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:49.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:49.683+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:49.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:50.886+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:50.907+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:50.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:50.926+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:50.926+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:50.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.278 seconds
[2025-12-13T10:59:51.004+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:51.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:51.008+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:51.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:52.248+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:52.270+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:52.269+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:52.293+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:52.293+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:52.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.314 seconds
[2025-12-13T10:59:52.373+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:52.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:52.377+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:52.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:01:25.724+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:01:25.747+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:01:25.747+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:01:25.769+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:01:25.769+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:53.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.253 seconds
[2025-12-13T10:59:53.674+0000] {processor.py:186} INFO - Started process (PID=145) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:53.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:53.679+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:53.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:55.139+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:55.172+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:55.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:55.197+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:55.197+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:55.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.549 seconds
[2025-12-13T10:59:55.269+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:55.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:55.273+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:55.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:56.439+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:56.462+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:56.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:56.485+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:56.485+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:56.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.239 seconds
[2025-12-13T10:59:56.553+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:56.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:56.557+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:56.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:57.715+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T10:59:57.738+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:57.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T10:59:57.758+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:57.757+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T10:59:57.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.227 seconds
[2025-12-13T10:59:57.823+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/airflow.py
[2025-12-13T10:59:57.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T10:59:57.827+0000] {logging_mixin.py:190} INFO - [2025-12-13T10:59:57.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:02:00.976+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:02:00.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:02:00.980+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:00.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:02:02.206+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:02:02.230+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:02.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:02:02.251+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:02.251+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:02:02.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.299 seconds
[2025-12-13T11:02:32.408+0000] {processor.py:186} INFO - Started process (PID=249) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:02:32.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:02:32.414+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:32.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:02:33.550+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:02:33.574+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:33.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:02:33.594+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:33.594+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:02:33.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.220 seconds
[2025-12-13T11:04:26.043+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:04:26.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:04:26.047+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:04:26.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:02:55.229+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:02:55.256+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:55.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:02:55.285+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:02:55.284+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:02:55.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.467 seconds
[2025-12-13T11:03:25.630+0000] {processor.py:186} INFO - Started process (PID=287) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:03:25.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:03:25.634+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:03:25.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:03:26.985+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:03:27.014+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:03:27.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:03:27.040+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:03:27.040+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:03:27.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.444 seconds
[2025-12-13T11:03:34.207+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:03:34.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:03:34.211+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:03:34.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:03:35.661+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:03:35.683+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:03:35.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:03:35.703+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:03:35.703+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:03:35.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.525 seconds
[2025-12-13T11:05:31.094+0000] {processor.py:186} INFO - Started process (PID=319) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:31.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:31.103+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:31.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:04:01.286+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:04:01.311+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:04:01.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:04:01.341+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:04:01.341+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:04:01.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.458 seconds
[2025-12-13T11:04:19.114+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:04:19.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:04:19.118+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:04:19.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:04:20.449+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:04:20.501+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:04:20.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:04:20.552+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:04:20.552+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:04:20.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.508 seconds
[2025-12-13T11:04:31.305+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:04:31.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:04:31.309+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:04:31.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:43.563+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:43.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:43.567+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:43.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:46.525+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:46.564+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:46.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:46.586+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:46.586+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:46.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 3.066 seconds
[2025-12-13T11:05:46.681+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:46.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:46.685+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:46.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:48.139+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:48.160+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:48.160+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:48.178+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:48.178+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:48.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.527 seconds
[2025-12-13T11:05:48.257+0000] {processor.py:186} INFO - Started process (PID=94) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:48.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:48.261+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:48.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:49.746+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:49.774+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:49.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:49.796+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:49.796+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:49.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.552 seconds
[2025-12-13T11:05:49.875+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:49.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:49.880+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:49.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:51.114+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:51.136+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:51.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:51.155+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:51.154+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:51.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.302 seconds
[2025-12-13T11:05:51.224+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:51.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:51.229+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:51.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:52.433+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:52.453+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:52.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:52.476+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:52.476+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:52.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.275 seconds
[2025-12-13T11:05:52.552+0000] {processor.py:186} INFO - Started process (PID=133) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:52.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:52.555+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:52.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:53.843+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:53.871+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:53.870+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:53.902+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:53.901+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:53.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.384 seconds
[2025-12-13T11:07:26.178+0000] {processor.py:186} INFO - Started process (PID=146) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:07:26.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:07:26.182+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:26.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:55.301+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:55.323+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:55.323+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:55.343+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:55.343+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:55.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.367 seconds
[2025-12-13T11:05:55.413+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:55.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:55.417+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:55.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:56.645+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:56.668+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:56.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:56.689+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:56.688+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:56.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.299 seconds
[2025-12-13T11:05:56.762+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:56.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:56.765+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:56.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:57.918+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:05:57.939+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:57.939+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:05:57.957+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:57.957+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:05:57.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.216 seconds
[2025-12-13T11:05:58.021+0000] {processor.py:186} INFO - Started process (PID=185) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:05:58.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:05:58.025+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:05:58.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:08:11.286+0000] {processor.py:186} INFO - Started process (PID=213) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:08:11.287+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:08:11.290+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:08:11.289+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:06:40.662+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:06:40.686+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:06:40.686+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:06:40.711+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:06:40.710+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:06:40.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.632 seconds
[2025-12-13T11:07:11.034+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:07:11.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:07:11.038+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:11.038+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:07:12.213+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:07:12.236+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:12.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:07:12.256+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:12.256+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:07:12.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.244 seconds
[2025-12-13T11:09:01.378+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:09:01.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:09:01.382+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:09:01.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:07:30.654+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:07:30.679+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:30.679+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:07:30.703+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:30.702+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:07:30.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.535 seconds
[2025-12-13T11:09:21.386+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:09:21.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:09:21.390+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:09:21.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:07:50.677+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:07:50.701+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:50.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:07:50.724+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:07:50.724+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:07:50.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.551 seconds
[2025-12-13T11:08:20.933+0000] {processor.py:186} INFO - Started process (PID=289) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:08:20.934+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:08:20.936+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:08:20.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:08:22.198+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:08:22.223+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:08:22.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:08:22.245+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:08:22.244+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:08:22.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.336 seconds
[2025-12-13T11:08:52.533+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:08:52.534+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:08:52.538+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:08:52.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:08:53.847+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:08:53.870+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:08:53.870+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:08:53.891+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:08:53.891+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:08:53.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.383 seconds
[2025-12-13T11:09:24.118+0000] {processor.py:186} INFO - Started process (PID=327) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:09:24.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:09:24.121+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:09:24.121+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:09:25.475+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:09:25.505+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:09:25.505+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:09:25.543+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:09:25.543+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:09:25.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.455 seconds
[2025-12-13T11:11:02.854+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:11:02.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:11:02.857+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:02.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:09:32.045+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:09:32.069+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:09:32.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:09:32.092+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:09:32.091+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:09:32.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.448 seconds
[2025-12-13T11:10:02.338+0000] {processor.py:186} INFO - Started process (PID=359) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:10:02.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:10:02.342+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:02.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:03.816+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:03.843+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:03.842+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:10:03.865+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:03.864+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:10:03.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.551 seconds
[2025-12-13T11:11:41.584+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:11:41.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:11:41.590+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:41.589+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:11.133+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:11.162+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:11.162+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:10:11.195+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:11.194+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:10:11.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.825 seconds
[2025-12-13T11:12:06.589+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:12:06.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:12:06.592+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:06.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:35.697+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:35.719+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:35.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:10:35.740+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:35.740+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:10:35.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.358 seconds
[2025-12-13T11:10:39.467+0000] {processor.py:186} INFO - Started process (PID=404) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:10:39.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:10:39.471+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:39.470+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:40.802+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:10:40.826+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:40.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:10:40.854+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:10:40.853+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:10:40.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.417 seconds
[2025-12-13T11:11:11.096+0000] {processor.py:186} INFO - Started process (PID=423) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:11:11.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:11:11.100+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:11.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:12.158+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:12.180+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:12.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:11:12.199+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:12.198+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:11:12.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.124 seconds
[2025-12-13T11:11:42.281+0000] {processor.py:186} INFO - Started process (PID=443) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:11:42.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:11:42.285+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:42.284+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:43.377+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:43.399+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:43.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:11:43.417+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:43.417+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:11:43.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.166 seconds
[2025-12-13T11:13:21.719+0000] {processor.py:186} INFO - Started process (PID=462) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:13:21.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:13:21.723+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:13:21.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:50.887+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:50.917+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:50.917+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:11:50.941+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:50.941+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:11:50.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.436 seconds
[2025-12-13T11:11:54.612+0000] {processor.py:186} INFO - Started process (PID=475) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:11:54.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:11:54.620+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:54.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:55.775+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:11:55.804+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:55.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:11:55.826+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:11:55.826+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:11:55.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.249 seconds
[2025-12-13T11:12:26.169+0000] {processor.py:186} INFO - Started process (PID=494) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:12:26.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:12:26.173+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:26.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:12:27.231+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:12:27.252+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:27.252+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:12:27.271+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:27.270+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:12:27.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.130 seconds
[2025-12-13T11:12:57.458+0000] {processor.py:186} INFO - Started process (PID=513) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:12:57.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:12:57.462+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:57.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:12:58.568+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:12:58.591+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:58.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:12:58.612+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:58.612+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:12:58.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.184 seconds
[2025-12-13T11:12:59.683+0000] {processor.py:186} INFO - Started process (PID=526) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:12:59.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:12:59.687+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:12:59.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:15:00.085+0000] {processor.py:186} INFO - Started process (PID=564) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:15:00.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:15:00.088+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:15:00.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:15:01.295+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:15:01.519+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:15:01.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:15:01.538+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:15:01.538+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:15:01.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.484 seconds
[2025-12-13T11:15:31.859+0000] {processor.py:186} INFO - Started process (PID=583) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:15:31.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:15:31.862+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:15:31.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:15:33.068+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:15:33.090+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:15:33.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:15:33.111+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:15:33.110+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:15:33.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.277 seconds
[2025-12-13T11:16:03.436+0000] {processor.py:186} INFO - Started process (PID=602) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:16:03.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:16:03.438+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:03.438+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:04.462+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:04.486+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:04.486+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:16:04.506+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:04.506+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:16:04.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.091 seconds
[2025-12-13T11:16:34.604+0000] {processor.py:186} INFO - Started process (PID=621) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:16:34.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:16:34.607+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:34.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:35.754+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:35.776+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:35.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:16:35.793+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:35.793+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:16:35.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.216 seconds
[2025-12-13T11:18:17.109+0000] {processor.py:186} INFO - Started process (PID=634) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:18:17.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:18:17.112+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:18:17.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:46.089+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:46.159+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:46.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:16:46.231+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:46.230+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:16:46.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.386 seconds
[2025-12-13T11:16:50.011+0000] {processor.py:186} INFO - Started process (PID=653) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:16:50.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:16:50.014+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:50.014+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:51.211+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:16:51.240+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:51.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:16:51.264+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:16:51.263+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:16:51.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.290 seconds
[2025-12-13T11:17:00.102+0000] {processor.py:186} INFO - Started process (PID=666) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:17:00.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:17:00.106+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:17:00.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:17:01.355+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:17:01.415+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:17:01.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:17:01.475+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:17:01.474+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:17:01.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.435 seconds
[2025-12-13T11:17:01.644+0000] {processor.py:186} INFO - Started process (PID=679) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:17:01.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:17:01.648+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:17:01.647+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:18:13.013+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:18:13.015+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:18:13.017+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:18:13.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:20:18.135+0000] {processor.py:186} INFO - Started process (PID=114) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:20:18.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:20:18.139+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:18.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:20:19.933+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:20:19.973+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:19.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:20:19.994+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:19.994+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:20:20.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.885 seconds
[2025-12-13T11:20:25.257+0000] {processor.py:186} INFO - Started process (PID=127) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:20:25.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:20:25.261+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:25.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:20:26.448+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:20:26.470+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:26.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:20:26.490+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:26.489+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:20:26.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.256 seconds
[2025-12-13T11:20:29.294+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:20:29.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:20:29.299+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:29.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:20:30.574+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:20:30.600+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:30.600+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:20:30.626+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:20:30.626+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:20:30.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.357 seconds
[2025-12-13T11:21:00.932+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:21:00.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:21:00.936+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:00.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:02.151+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:02.175+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:02.175+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:21:02.196+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:02.195+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:21:02.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.289 seconds
[2025-12-13T11:22:37.471+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:22:37.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:22:37.475+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:22:37.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:06.475+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:06.500+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:06.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:21:06.522+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:06.522+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:21:06.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.264 seconds
[2025-12-13T11:21:10.360+0000] {processor.py:186} INFO - Started process (PID=185) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:21:10.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:21:10.365+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:10.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:11.565+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:11.589+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:11.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:21:11.610+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:11.610+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:21:11.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.274 seconds
[2025-12-13T11:21:42.302+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:21:42.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:21:42.306+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:42.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:43.667+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:21:43.689+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:43.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:21:43.710+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:21:43.710+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:21:43.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.430 seconds
[2025-12-13T11:22:14.262+0000] {processor.py:186} INFO - Started process (PID=223) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:22:14.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:22:14.266+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:22:14.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:22:15.496+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:22:15.519+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:22:15.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:22:15.541+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:22:15.541+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:22:15.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.304 seconds
[2025-12-13T11:22:45.483+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:22:45.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:22:45.488+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:22:45.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:22:46.854+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:22:46.902+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:22:46.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:22:46.953+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:22:46.948+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:22:46.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.508 seconds
[2025-12-13T11:23:17.226+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:23:17.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:23:17.230+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:23:17.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:23:18.456+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:23:18.477+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:23:18.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:23:18.496+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:23:18.496+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:23:18.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.292 seconds
[2025-12-13T11:23:49.224+0000] {processor.py:186} INFO - Started process (PID=287) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:23:49.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:23:49.228+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:23:49.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:23:50.401+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:23:50.424+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:23:50.424+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:23:50.445+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:23:50.444+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:23:50.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.249 seconds
[2025-12-13T11:24:21.056+0000] {processor.py:186} INFO - Started process (PID=306) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:24:21.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:24:21.059+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:24:21.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:24:22.121+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:24:22.142+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:24:22.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:24:22.159+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:24:22.159+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:24:22.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.124 seconds
[2025-12-13T11:24:52.456+0000] {processor.py:186} INFO - Started process (PID=325) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:24:52.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:24:52.459+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:24:52.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:24:53.623+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:24:53.644+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:24:53.644+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:24:53.662+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:24:53.661+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:24:53.679+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.230 seconds
[2025-12-13T11:26:42.853+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:26:42.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:26:42.856+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:42.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:25:11.865+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:25:11.890+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:11.890+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:25:11.911+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:11.911+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:25:11.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.277 seconds
[2025-12-13T11:25:42.155+0000] {processor.py:186} INFO - Started process (PID=357) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:25:42.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:25:42.158+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:42.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:25:43.256+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:25:43.278+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:43.278+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:25:43.298+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:43.298+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:25:43.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.170 seconds
[2025-12-13T11:25:57.409+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:25:57.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:25:57.412+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:57.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:25:58.622+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:25:58.642+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:58.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:25:58.660+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:25:58.660+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:25:58.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.274 seconds
[2025-12-13T11:27:32.937+0000] {processor.py:186} INFO - Started process (PID=389) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:27:32.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:27:32.940+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:32.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:26:01.834+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:26:01.855+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:01.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:26:01.872+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:01.872+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:26:01.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.151 seconds
[2025-12-13T11:26:05.786+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:26:05.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:26:05.790+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:05.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:26:06.961+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:26:06.986+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:06.985+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:26:07.008+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:07.008+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:26:07.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.245 seconds
[2025-12-13T11:26:37.312+0000] {processor.py:186} INFO - Started process (PID=421) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:26:37.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:26:37.315+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:37.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:26:38.754+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:26:38.786+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:38.786+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:26:38.808+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:26:38.808+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:26:38.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.522 seconds
[2025-12-13T11:27:09.208+0000] {processor.py:186} INFO - Started process (PID=440) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:27:09.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:27:09.212+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:09.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:10.334+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:10.356+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:10.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:27:10.376+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:10.375+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:27:10.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.196 seconds
[2025-12-13T11:28:53.023+0000] {processor.py:186} INFO - Started process (PID=459) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:28:53.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:28:53.027+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:53.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:22.163+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:22.186+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:22.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:27:22.207+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:22.207+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:27:22.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.404 seconds
[2025-12-13T11:27:26.055+0000] {processor.py:186} INFO - Started process (PID=472) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:27:26.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:27:26.058+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:26.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:27.195+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:27.218+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:27.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:27:27.240+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:27.240+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:27:27.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.215 seconds
[2025-12-13T11:29:18.095+0000] {processor.py:186} INFO - Started process (PID=491) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:29:18.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:29:18.099+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:18.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:47.058+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:27:47.084+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:47.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:27:47.105+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:27:47.104+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:27:47.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.234 seconds
[2025-12-13T11:29:33.079+0000] {processor.py:186} INFO - Started process (PID=504) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:29:33.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:29:33.083+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:33.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:28:02.073+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:28:02.097+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:02.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:28:02.118+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:02.118+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:28:02.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.260 seconds
[2025-12-13T11:28:05.936+0000] {processor.py:186} INFO - Started process (PID=517) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:28:05.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:28:05.940+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:05.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:28:06.975+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:28:06.998+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:06.997+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:28:07.018+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:07.017+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:28:07.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.106 seconds
[2025-12-13T11:28:37.219+0000] {processor.py:186} INFO - Started process (PID=536) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:28:37.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:28:37.222+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:37.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:28:38.406+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:28:38.428+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:38.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:28:38.449+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:28:38.449+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:28:38.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.253 seconds
[2025-12-13T11:29:08.686+0000] {processor.py:186} INFO - Started process (PID=555) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:29:08.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:29:08.690+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:08.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:29:10.265+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:29:10.288+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:10.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:29:10.310+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:10.310+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:29:10.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.651 seconds
[2025-12-13T11:30:55.156+0000] {processor.py:186} INFO - Started process (PID=573) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:30:55.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:30:55.160+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:55.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:29:24.047+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:29:24.068+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:24.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:29:24.086+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:24.085+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:29:24.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.143 seconds
[2025-12-13T11:31:03.236+0000] {processor.py:186} INFO - Started process (PID=586) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:31:03.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:31:03.240+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:03.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:29:32.286+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:29:32.308+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:32.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:29:32.327+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:29:32.327+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:29:32.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.318 seconds
[2025-12-13T11:30:02.482+0000] {processor.py:186} INFO - Started process (PID=605) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:30:02.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:30:02.486+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:02.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:30:03.707+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:30:03.729+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:03.729+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:30:03.750+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:03.749+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:30:03.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.300 seconds
[2025-12-13T11:31:55.153+0000] {processor.py:186} INFO - Started process (PID=624) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:31:55.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:31:55.157+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:55.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:30:24.087+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:30:24.111+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:24.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:30:24.132+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:24.132+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:30:24.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.194 seconds
[2025-12-13T11:32:18.323+0000] {processor.py:186} INFO - Started process (PID=643) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:32:18.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:32:18.327+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:32:18.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:30:47.167+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:30:47.190+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:47.190+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:30:47.223+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:30:47.223+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:30:47.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.122 seconds
[2025-12-13T11:31:17.368+0000] {processor.py:186} INFO - Started process (PID=663) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:31:17.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:31:17.372+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:17.372+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:18.620+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:18.642+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:18.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:31:18.664+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:18.664+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:31:18.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.326 seconds
[2025-12-13T11:31:48.950+0000] {processor.py:186} INFO - Started process (PID=683) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:31:48.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:31:48.954+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:48.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:50.096+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:50.122+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:50.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:31:50.141+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:50.141+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:31:50.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.215 seconds
[2025-12-13T11:33:23.431+0000] {processor.py:186} INFO - Started process (PID=696) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:33:23.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:33:23.434+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:33:23.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:52.311+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:52.337+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:52.337+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:31:52.365+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:52.364+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:31:52.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.172 seconds
[2025-12-13T11:31:56.280+0000] {processor.py:186} INFO - Started process (PID=709) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:31:56.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:31:56.284+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:56.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:57.355+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:31:57.379+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:57.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:31:57.399+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:31:57.399+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:31:57.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.144 seconds
[2025-12-13T11:32:27.561+0000] {processor.py:186} INFO - Started process (PID=728) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:32:27.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:32:27.567+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:32:27.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:32:28.782+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:32:28.804+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:32:28.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:32:28.826+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:32:28.825+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:32:28.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.287 seconds
[2025-12-13T11:32:58.899+0000] {processor.py:186} INFO - Started process (PID=747) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:32:58.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:32:58.903+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:32:58.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:32:59.978+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:33:00.015+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:33:00.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:33:00.037+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:33:00.037+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:33:00.054+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.162 seconds
[2025-12-13T11:33:30.274+0000] {processor.py:186} INFO - Started process (PID=766) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:33:30.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:33:30.278+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:33:30.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:03.526+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:03.550+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:03.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:33:31.376+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:33:31.375+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:33:31.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.122 seconds
[2025-12-13T11:35:08.549+0000] {processor.py:186} INFO - Started process (PID=779) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:35:08.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:35:08.554+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:08.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:33:37.402+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:33:37.430+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:33:37.430+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:33:37.452+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:33:37.452+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:33:37.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.119 seconds
[2025-12-13T11:34:07.732+0000] {processor.py:186} INFO - Started process (PID=798) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:34:07.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:34:07.736+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:07.736+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:34:09.078+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:34:09.106+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:09.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:34:09.129+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:09.128+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:34:09.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.420 seconds
[2025-12-13T11:35:55.120+0000] {processor.py:186} INFO - Started process (PID=817) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:35:55.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:35:55.124+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:55.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:34:23.993+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:34:24.015+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:24.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:34:24.036+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:24.036+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:34:24.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.138 seconds
[2025-12-13T11:34:54.599+0000] {processor.py:186} INFO - Started process (PID=836) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:34:54.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:34:54.602+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:54.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:34:55.743+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:34:55.767+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:55.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:34:55.792+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:34:55.792+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:34:55.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.215 seconds
[2025-12-13T11:35:26.193+0000] {processor.py:186} INFO - Started process (PID=855) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:35:26.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:35:26.198+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:26.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:27.288+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:27.311+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:27.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:35:27.330+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:27.330+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:35:27.348+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.139 seconds
[2025-12-13T11:37:08.694+0000] {processor.py:186} INFO - Started process (PID=868) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:37:08.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:37:08.697+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:08.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:37.601+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:37.623+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:37.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:35:37.640+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:37.640+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:35:37.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.168 seconds
[2025-12-13T11:35:41.576+0000] {processor.py:186} INFO - Started process (PID=887) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:35:41.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:35:41.579+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:41.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:42.630+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:35:42.651+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:42.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:35:42.669+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:35:42.669+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:35:42.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.115 seconds
[2025-12-13T11:36:12.865+0000] {processor.py:186} INFO - Started process (PID=906) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:36:12.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:36:12.868+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:12.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:36:13.920+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:36:13.942+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:13.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:36:13.961+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:13.960+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:36:13.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.125 seconds
[2025-12-13T11:36:44.255+0000] {processor.py:186} INFO - Started process (PID=925) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:36:44.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:36:44.258+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:44.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:36:45.297+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:36:45.321+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:45.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:36:45.343+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:45.343+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:36:45.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.111 seconds
[2025-12-13T11:38:23.549+0000] {processor.py:186} INFO - Started process (PID=938) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:38:23.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:38:23.553+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:23.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:36:52.390+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:36:52.412+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:52.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:36:52.432+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:36:52.432+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:36:52.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.113 seconds
[2025-12-13T11:38:38.815+0000] {processor.py:186} INFO - Started process (PID=951) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:38:38.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:38:38.819+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:38.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:07.860+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:07.883+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:07.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:37:07.903+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:07.903+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:37:07.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.318 seconds
[2025-12-13T11:37:11.670+0000] {processor.py:186} INFO - Started process (PID=970) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:37:11.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:37:11.675+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:11.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:12.744+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:12.768+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:12.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:37:12.789+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:12.788+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:37:12.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.144 seconds
[2025-12-13T11:37:21.734+0000] {processor.py:186} INFO - Started process (PID=983) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:37:21.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:37:21.738+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:21.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:22.876+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:22.902+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:22.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:37:22.922+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:22.922+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:37:22.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.211 seconds
[2025-12-13T11:37:53.241+0000] {processor.py:186} INFO - Started process (PID=1002) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:37:53.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:37:53.245+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:53.245+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:54.318+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:37:54.342+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:54.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:37:54.365+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:37:54.364+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:37:54.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.149 seconds
[2025-12-13T11:38:24.477+0000] {processor.py:186} INFO - Started process (PID=1021) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:38:24.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:38:24.481+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:24.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:38:25.549+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:38:25.571+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:25.571+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:38:25.591+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:25.590+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:38:25.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.136 seconds
[2025-12-13T11:40:08.913+0000] {processor.py:186} INFO - Started process (PID=1034) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:40:08.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:40:08.917+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:40:08.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:38:37.791+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:38:37.815+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:37.814+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:38:37.836+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:37.836+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:38:37.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.142 seconds
[2025-12-13T11:38:41.765+0000] {processor.py:186} INFO - Started process (PID=1053) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:38:41.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:38:41.769+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:41.768+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:38:42.893+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:38:42.914+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:42.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:38:42.932+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:38:42.932+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:38:42.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.191 seconds
[2025-12-13T11:39:13.162+0000] {processor.py:186} INFO - Started process (PID=1072) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:39:13.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:39:13.166+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:13.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:14.298+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:14.322+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:14.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:39:14.343+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:14.342+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:39:14.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.205 seconds
[2025-12-13T11:39:44.505+0000] {processor.py:186} INFO - Started process (PID=1091) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:39:44.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:39:44.508+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:44.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:45.624+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:45.647+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:45.647+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:39:45.670+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:45.669+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:39:45.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.195 seconds
[2025-12-13T11:41:24.026+0000] {processor.py:186} INFO - Started process (PID=1104) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:41:24.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:41:24.031+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:41:24.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:53.015+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:53.036+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:53.036+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:39:53.055+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:53.054+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:39:53.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.253 seconds
[2025-12-13T11:39:56.863+0000] {processor.py:186} INFO - Started process (PID=1117) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:39:56.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:39:56.867+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:56.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:58.015+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:39:58.039+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:58.039+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:39:58.060+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:39:58.060+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:39:58.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.221 seconds
[2025-12-13T11:41:53.372+0000] {processor.py:186} INFO - Started process (PID=1136) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:41:53.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:41:53.376+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:41:53.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:40:22.233+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:40:22.256+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:40:22.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:40:22.277+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:40:22.276+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:40:22.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.186 seconds
[2025-12-13T11:40:52.405+0000] {processor.py:186} INFO - Started process (PID=1155) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:40:52.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:40:52.409+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:40:52.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:40:53.436+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:40:53.458+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:40:53.458+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:40:53.478+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:40:53.478+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:40:53.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.094 seconds
[2025-12-13T11:41:23.727+0000] {processor.py:186} INFO - Started process (PID=1174) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:41:23.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:41:23.731+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:41:23.730+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:41:24.889+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:41:24.913+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:41:24.913+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:41:24.934+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:41:24.934+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:41:24.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.231 seconds
[2025-12-13T11:41:55.845+0000] {processor.py:186} INFO - Started process (PID=1194) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:41:55.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:41:55.848+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:41:55.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:41:56.873+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:41:56.894+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:41:56.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:43:29.107+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:29.106+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:43:20.817+0000] {processor.py:186} INFO - Started process (PID=1225) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:20.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:20.822+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:20.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:22.650+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:22.676+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:22.675+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:43:22.699+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:22.699+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:43:22.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.901 seconds
[2025-12-13T11:43:38.902+0000] {processor.py:186} INFO - Started process (PID=1238) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:38.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:38.908+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:38.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:40.276+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:40.266+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:40.277+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:40.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.403 seconds
[2025-12-13T11:43:40.358+0000] {processor.py:186} INFO - Started process (PID=1251) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:40.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:40.362+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:40.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:41.659+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:41.653+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:41.660+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:41.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.327 seconds
[2025-12-13T11:43:41.734+0000] {processor.py:186} INFO - Started process (PID=1270) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:41.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:41.738+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:41.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:42.790+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:42.784+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:42.791+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:42.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.077 seconds
[2025-12-13T11:43:42.867+0000] {processor.py:186} INFO - Started process (PID=1283) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:42.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:42.871+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:42.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:44.157+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:44.150+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:44.159+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:44.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.321 seconds
[2025-12-13T11:43:44.262+0000] {processor.py:186} INFO - Started process (PID=1296) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:44.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:44.267+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:44.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:45.421+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:45.415+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:45.422+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:45.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.182 seconds
[2025-12-13T11:43:45.487+0000] {processor.py:186} INFO - Started process (PID=1309) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:45.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:45.490+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:45.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:46.760+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:46.750+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:46.762+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:46.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.308 seconds
[2025-12-13T11:43:46.901+0000] {processor.py:186} INFO - Started process (PID=1322) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:46.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:46.909+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:46.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:48.477+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:48.471+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:48.478+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:48.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.612 seconds
[2025-12-13T11:43:48.581+0000] {processor.py:186} INFO - Started process (PID=1335) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:48.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:48.586+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:48.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:49.760+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:49.753+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:49.761+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:49.776+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.204 seconds
[2025-12-13T11:43:49.829+0000] {processor.py:186} INFO - Started process (PID=1348) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:49.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:49.833+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:49.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:50.999+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:50.987+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:51.000+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:51.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.205 seconds
[2025-12-13T11:43:51.079+0000] {processor.py:186} INFO - Started process (PID=1361) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:51.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:51.082+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:51.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:52.209+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:52.204+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:52.210+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:52.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.159 seconds
[2025-12-13T11:43:52.289+0000] {processor.py:186} INFO - Started process (PID=1374) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:52.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:52.293+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:52.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:53.398+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:53.392+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:53.399+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:53.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.132 seconds
[2025-12-13T11:43:53.464+0000] {processor.py:186} INFO - Started process (PID=1387) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:53.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:53.468+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:53.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:54.538+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:54.532+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:54.539+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:54.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.101 seconds
[2025-12-13T11:43:54.619+0000] {processor.py:186} INFO - Started process (PID=1400) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:54.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:54.624+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:54.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:55.671+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:55.666+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:55.672+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:55.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.074 seconds
[2025-12-13T11:43:55.738+0000] {processor.py:186} INFO - Started process (PID=1413) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:55.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:55.742+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:55.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:56.875+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:56.869+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:56.876+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:56.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.164 seconds
[2025-12-13T11:43:56.958+0000] {processor.py:186} INFO - Started process (PID=1426) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:56.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:56.962+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:56.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:58.149+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:58.140+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:58.150+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:58.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.204 seconds
[2025-12-13T11:43:58.219+0000] {processor.py:186} INFO - Started process (PID=1439) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:58.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:58.223+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:58.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:59.388+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:59.382+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:43:59.389+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:43:59.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.192 seconds
[2025-12-13T11:43:59.476+0000] {processor.py:186} INFO - Started process (PID=1452) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:43:59.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:43:59.480+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:43:59.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:00.594+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:00.586+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:00.595+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:00.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.143 seconds
[2025-12-13T11:44:00.667+0000] {processor.py:186} INFO - Started process (PID=1465) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:00.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:00.671+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:00.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:01.764+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:01.758+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:01.765+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:01.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.119 seconds
[2025-12-13T11:44:01.831+0000] {processor.py:186} INFO - Started process (PID=1478) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:01.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:01.836+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:01.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:02.849+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:02.843+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:02.850+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:02.864+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.043 seconds
[2025-12-13T11:44:02.918+0000] {processor.py:186} INFO - Started process (PID=1491) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:02.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:02.922+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:02.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:03.980+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:03.974+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:03.981+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:03.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.085 seconds
[2025-12-13T11:44:04.063+0000] {processor.py:186} INFO - Started process (PID=1504) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:04.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:04.066+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:04.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:05.223+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:05.216+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:05.223+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:05.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.181 seconds
[2025-12-13T11:44:05.288+0000] {processor.py:186} INFO - Started process (PID=1517) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:05.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:05.292+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:05.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:06.320+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:06.314+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:06.321+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:06.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.053 seconds
[2025-12-13T11:44:06.395+0000] {processor.py:186} INFO - Started process (PID=1530) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:06.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:06.400+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:06.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:07.514+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:07.508+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:07.515+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:07.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.150 seconds
[2025-12-13T11:44:07.581+0000] {processor.py:186} INFO - Started process (PID=1543) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:07.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:07.585+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:07.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:08.701+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:08.696+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:08.702+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:08.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.144 seconds
[2025-12-13T11:44:08.803+0000] {processor.py:186} INFO - Started process (PID=1556) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:08.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:08.811+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:08.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:09.950+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:09.946+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:09.951+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:09.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.173 seconds
[2025-12-13T11:44:10.019+0000] {processor.py:186} INFO - Started process (PID=1569) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:10.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:10.022+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:10.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:11.199+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:11.193+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:11.200+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:11.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.201 seconds
[2025-12-13T11:44:11.267+0000] {processor.py:186} INFO - Started process (PID=1582) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:11.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:11.271+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:11.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:12.370+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:12.363+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:12.371+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:12.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.122 seconds
[2025-12-13T11:44:12.439+0000] {processor.py:186} INFO - Started process (PID=1601) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:12.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:12.443+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:12.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:13.552+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:13.546+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:13.553+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:13.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.137 seconds
[2025-12-13T11:44:13.623+0000] {processor.py:186} INFO - Started process (PID=1614) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:13.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:13.627+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:13.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:14.744+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:14.738+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:14.745+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:14.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.142 seconds
[2025-12-13T11:44:14.811+0000] {processor.py:186} INFO - Started process (PID=1627) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:14.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:14.815+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:14.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:15.950+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:15.943+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:15.951+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:15.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.165 seconds
[2025-12-13T11:44:16.045+0000] {processor.py:186} INFO - Started process (PID=1640) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:16.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:16.050+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:16.049+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:17.229+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:17.223+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:17.230+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:17.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.209 seconds
[2025-12-13T11:44:17.314+0000] {processor.py:186} INFO - Started process (PID=1653) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:17.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:17.319+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:17.318+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:18.536+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:18.528+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:18.538+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:18.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.256 seconds
[2025-12-13T11:44:18.678+0000] {processor.py:186} INFO - Started process (PID=1666) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:18.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:18.686+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:18.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:19.730+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:19.725+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:19.731+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:19.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.079 seconds
[2025-12-13T11:44:19.796+0000] {processor.py:186} INFO - Started process (PID=1679) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:19.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:19.800+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:19.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:20.910+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:20.904+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:20.911+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:20.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.137 seconds
[2025-12-13T11:44:20.981+0000] {processor.py:186} INFO - Started process (PID=1692) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:20.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:20.985+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:20.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:22.001+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:21.996+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:22.002+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:22.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.042 seconds
[2025-12-13T11:44:22.068+0000] {processor.py:186} INFO - Started process (PID=1705) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:22.069+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:22.071+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:22.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:23.107+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:23.100+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:23.107+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:23.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.064 seconds
[2025-12-13T11:44:23.185+0000] {processor.py:186} INFO - Started process (PID=1718) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:23.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:23.189+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:23.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:24.298+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:24.293+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:24.299+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:24.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.141 seconds
[2025-12-13T11:44:24.383+0000] {processor.py:186} INFO - Started process (PID=1731) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:24.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:24.387+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:24.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:25.551+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:25.546+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:25.552+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:25.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.198 seconds
[2025-12-13T11:44:25.629+0000] {processor.py:186} INFO - Started process (PID=1744) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:25.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:25.633+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:25.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:26.716+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:26.709+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:26.717+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:26.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.116 seconds
[2025-12-13T11:44:26.788+0000] {processor.py:186} INFO - Started process (PID=1757) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:26.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:26.792+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:26.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:27.838+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:27.830+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:27.838+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:27.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.073 seconds
[2025-12-13T11:44:27.905+0000] {processor.py:186} INFO - Started process (PID=1770) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:27.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:27.909+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:27.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:29.092+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:29.086+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:29.093+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:29.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.215 seconds
[2025-12-13T11:44:29.166+0000] {processor.py:186} INFO - Started process (PID=1783) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:29.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:29.170+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:29.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:30.218+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:30.208+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:30.219+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:30.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.074 seconds
[2025-12-13T11:44:30.294+0000] {processor.py:186} INFO - Started process (PID=1796) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:30.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:30.299+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:30.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:31.418+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:31.413+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:31.419+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:31.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.154 seconds
[2025-12-13T11:44:31.494+0000] {processor.py:186} INFO - Started process (PID=1809) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:31.495+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:31.497+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:31.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:32.560+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:32.555+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:32.561+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:32.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.097 seconds
[2025-12-13T11:44:32.630+0000] {processor.py:186} INFO - Started process (PID=1822) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:32.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:32.634+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:32.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:33.748+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:33.741+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:33.749+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:33.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.141 seconds
[2025-12-13T11:44:33.828+0000] {processor.py:186} INFO - Started process (PID=1835) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:33.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:33.832+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:33.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:34.956+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:34.950+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:34.957+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:34.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.152 seconds
[2025-12-13T11:44:35.030+0000] {processor.py:186} INFO - Started process (PID=1848) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:35.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:35.035+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:35.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:36.144+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:36.137+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:36.145+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:36.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.142 seconds
[2025-12-13T11:44:36.218+0000] {processor.py:186} INFO - Started process (PID=1861) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:36.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:36.221+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:36.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:38.035+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:38.029+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:38.036+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:38.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.836 seconds
[2025-12-13T11:44:38.115+0000] {processor.py:186} INFO - Started process (PID=1874) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:38.116+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:38.119+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:38.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:39.398+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:39.391+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:39.399+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:39.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.313 seconds
[2025-12-13T11:44:39.484+0000] {processor.py:186} INFO - Started process (PID=1887) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:39.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:39.488+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:39.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:40.590+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:40.583+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:40.591+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:40.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.139 seconds
[2025-12-13T11:44:40.670+0000] {processor.py:186} INFO - Started process (PID=1900) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:40.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:40.674+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:40.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:41.737+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:41.731+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:41.738+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:41.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.094 seconds
[2025-12-13T11:44:41.817+0000] {processor.py:186} INFO - Started process (PID=1919) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:41.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:41.822+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:41.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:42.893+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:42.888+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:42.894+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:42.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.100 seconds
[2025-12-13T11:44:42.965+0000] {processor.py:186} INFO - Started process (PID=1932) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:42.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:42.969+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:42.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:44.055+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:44.049+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:44.056+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:44.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.119 seconds
[2025-12-13T11:44:44.134+0000] {processor.py:186} INFO - Started process (PID=1945) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:44.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:44.137+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:44.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:45.276+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:45.269+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:45.277+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:45.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.165 seconds
[2025-12-13T11:44:45.350+0000] {processor.py:186} INFO - Started process (PID=1958) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:45.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:45.354+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:45.354+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:46.621+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:46.614+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:46.622+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:46.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.296 seconds
[2025-12-13T11:44:46.697+0000] {processor.py:186} INFO - Started process (PID=1971) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:46.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:46.701+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:46.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:48.028+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:48.017+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:48.029+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:48.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.361 seconds
[2025-12-13T11:44:48.144+0000] {processor.py:186} INFO - Started process (PID=1984) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:48.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:48.151+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:48.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:50.131+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:50.124+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:50.132+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:50.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.058 seconds
[2025-12-13T11:44:50.443+0000] {processor.py:186} INFO - Started process (PID=1997) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:50.444+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:50.449+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:50.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:52.015+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:52.008+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:52.016+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:52.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.584 seconds
[2025-12-13T11:44:52.103+0000] {processor.py:186} INFO - Started process (PID=2010) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:52.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:52.107+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:52.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:53.618+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:53.613+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:53.619+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:53.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.553 seconds
[2025-12-13T11:44:53.687+0000] {processor.py:186} INFO - Started process (PID=2023) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:53.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:53.690+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:53.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:55.011+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:55.003+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:55.012+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:55.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.345 seconds
[2025-12-13T11:44:55.083+0000] {processor.py:186} INFO - Started process (PID=2036) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:55.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:55.086+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:55.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:56.211+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:56.205+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:56.211+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:56.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.149 seconds
[2025-12-13T11:44:56.375+0000] {processor.py:186} INFO - Started process (PID=2049) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:56.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:56.382+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:56.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:57.735+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:57.729+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:57.736+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:57.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.402 seconds
[2025-12-13T11:44:57.812+0000] {processor.py:186} INFO - Started process (PID=2062) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:57.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:57.815+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:57.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:59.416+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:59.406+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:44:59.417+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:44:59.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.813 seconds
[2025-12-13T11:44:59.766+0000] {processor.py:186} INFO - Started process (PID=2075) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:44:59.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:44:59.770+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:44:59.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:01.415+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:01.308+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:45:01.416+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:01.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.677 seconds
[2025-12-13T11:45:01.489+0000] {processor.py:186} INFO - Started process (PID=2088) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:01.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:01.493+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:01.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:03.045+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:03.035+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:45:03.047+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:03.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.586 seconds
[2025-12-13T11:45:03.218+0000] {processor.py:186} INFO - Started process (PID=2101) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:03.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:03.227+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:03.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:04.687+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:04.681+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:45:04.688+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:04.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.498 seconds
[2025-12-13T11:45:04.777+0000] {processor.py:186} INFO - Started process (PID=2114) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:04.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:04.781+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:04.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:05.957+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:05.949+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:45:05.959+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:05.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.212 seconds
[2025-12-13T11:45:06.039+0000] {processor.py:186} INFO - Started process (PID=2127) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:06.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:06.043+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:06.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:07.157+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:07.151+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow.py", line 857, in <module>
    run_spark_analytics_task = PythonOperator(
                               ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 967, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 250, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_analytics' has already been added to the DAG
[2025-12-13T11:45:07.158+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:39.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.145 seconds
[2025-12-13T11:45:09.090+0000] {processor.py:186} INFO - Started process (PID=2140) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:09.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:09.095+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:09.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:10.407+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:11.217+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:11.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:11.276+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:11.276+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:11.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.293 seconds
[2025-12-13T11:45:11.567+0000] {processor.py:186} INFO - Started process (PID=2153) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:11.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:11.575+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:11.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:12.975+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:12.986+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:12.986+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:13.006+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:13.006+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:13.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.474 seconds
[2025-12-13T11:45:13.075+0000] {processor.py:186} INFO - Started process (PID=2172) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:13.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:13.078+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:13.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:14.192+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:14.202+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:14.202+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:14.221+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:14.221+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:14.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.168 seconds
[2025-12-13T11:45:14.290+0000] {processor.py:186} INFO - Started process (PID=2185) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:14.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:14.293+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:14.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:15.415+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:15.425+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:15.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:15.446+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:15.446+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:15.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.179 seconds
[2025-12-13T11:45:15.524+0000] {processor.py:186} INFO - Started process (PID=2198) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:15.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:15.527+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:15.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:16.713+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:16.722+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:16.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:16.743+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:16.743+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:16.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.242 seconds
[2025-12-13T11:45:16.815+0000] {processor.py:186} INFO - Started process (PID=2211) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:16.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:16.818+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:16.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:17.769+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:17.782+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:17.782+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:17.976+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:17.976+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:17.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.345 seconds
[2025-12-13T11:45:18.062+0000] {processor.py:186} INFO - Started process (PID=2224) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:18.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:18.065+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:18.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:19.388+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:19.399+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:19.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:19.419+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:19.419+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:19.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.380 seconds
[2025-12-13T11:45:19.489+0000] {processor.py:186} INFO - Started process (PID=2237) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:19.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:19.491+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:19.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:20.661+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:20.672+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:20.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:20.694+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:20.694+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:20.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.228 seconds
[2025-12-13T11:45:20.786+0000] {processor.py:186} INFO - Started process (PID=2250) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:20.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:20.789+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:20.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:21.923+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:21.932+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:21.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:21.949+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:21.949+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:21.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.185 seconds
[2025-12-13T11:45:22.018+0000] {processor.py:186} INFO - Started process (PID=2263) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:22.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:22.021+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:22.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:23.243+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:23.255+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:23.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:23.276+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:23.276+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:23.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.288 seconds
[2025-12-13T11:45:23.348+0000] {processor.py:186} INFO - Started process (PID=2276) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:23.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:23.351+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:23.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:24.591+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:24.604+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:24.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:24.634+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:24.633+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:24.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.319 seconds
[2025-12-13T11:45:24.737+0000] {processor.py:186} INFO - Started process (PID=2289) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:24.738+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:24.740+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:24.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:25.893+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:25.903+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:25.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:25.924+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:25.923+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:25.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.212 seconds
[2025-12-13T11:45:26.000+0000] {processor.py:186} INFO - Started process (PID=2302) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:26.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:26.002+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:26.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:27.307+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:27.317+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:27.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:27.340+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:27.340+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:27.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.362 seconds
[2025-12-13T11:45:27.423+0000] {processor.py:186} INFO - Started process (PID=2315) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:27.424+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:27.425+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:27.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:28.759+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:28.768+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:28.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:28.795+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:28.794+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:28.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.402 seconds
[2025-12-13T11:45:28.889+0000] {processor.py:186} INFO - Started process (PID=2328) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:28.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:28.892+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:28.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:30.556+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:30.572+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:30.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:30.612+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:30.612+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:30.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.766 seconds
[2025-12-13T11:45:30.719+0000] {processor.py:186} INFO - Started process (PID=2341) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:30.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:30.724+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:30.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:32.446+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:32.462+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:32.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:32.495+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:32.495+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:32.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.801 seconds
[2025-12-13T11:45:32.577+0000] {processor.py:186} INFO - Started process (PID=2354) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:32.578+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:32.579+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:32.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:33.832+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:33.847+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:33.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:33.874+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:33.873+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:33.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.333 seconds
[2025-12-13T11:45:33.972+0000] {processor.py:186} INFO - Started process (PID=2367) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:33.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:33.975+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:33.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:35.514+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:35.525+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:35.525+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:35.546+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:35.546+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:35.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.597 seconds
[2025-12-13T11:45:35.622+0000] {processor.py:186} INFO - Started process (PID=2380) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:35.623+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:35.625+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:35.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:37.322+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:37.332+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:37.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:37.355+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:37.355+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:37.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.760 seconds
[2025-12-13T11:45:37.426+0000] {processor.py:186} INFO - Started process (PID=2393) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:37.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:37.429+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:37.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:39.711+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:39.721+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:39.721+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:39.741+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:39.741+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:39.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.340 seconds
[2025-12-13T11:45:39.822+0000] {processor.py:186} INFO - Started process (PID=2406) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:39.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:39.825+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:39.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:40.965+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:40.988+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:40.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:41.006+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:41.006+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:41.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.205 seconds
[2025-12-13T11:45:41.078+0000] {processor.py:186} INFO - Started process (PID=2419) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:41.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:41.081+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:41.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:42.352+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:42.376+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:42.375+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:42.394+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:42.394+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:42.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.339 seconds
[2025-12-13T11:45:42.465+0000] {processor.py:186} INFO - Started process (PID=2438) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:42.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:42.467+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:42.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:43.668+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:43.692+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:43.692+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:43.716+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:43.715+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:43.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.280 seconds
[2025-12-13T11:45:43.794+0000] {processor.py:186} INFO - Started process (PID=2451) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:43.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:43.796+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:43.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:44.992+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:45.016+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:45.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:45.035+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:45.035+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:45.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.269 seconds
[2025-12-13T11:45:45.110+0000] {processor.py:186} INFO - Started process (PID=2464) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:45.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:45.112+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:45.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:46.302+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:46.323+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:46.323+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:46.342+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:46.342+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:46.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.255 seconds
[2025-12-13T11:45:46.414+0000] {processor.py:186} INFO - Started process (PID=2477) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:46.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:46.417+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:46.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:47.638+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:47.667+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:47.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:47.688+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:47.688+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:47.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.316 seconds
[2025-12-13T11:45:47.785+0000] {processor.py:186} INFO - Started process (PID=2490) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:47.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:47.787+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:47.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:50.126+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:50.155+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:50.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:50.177+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:50.176+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:50.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.414 seconds
[2025-12-13T11:45:50.247+0000] {processor.py:186} INFO - Started process (PID=2503) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:50.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:50.250+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:50.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:51.598+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:45:51.622+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:51.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:45:51.641+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:51.641+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:45:51.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.420 seconds
[2025-12-13T11:45:51.730+0000] {processor.py:186} INFO - Started process (PID=2516) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:45:51.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:45:51.732+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:45:51.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:40.743+0000] {processor.py:186} INFO - Started process (PID=2534) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:40.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:40.746+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:40.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:42.003+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:42.097+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:42.096+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:42.118+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:42.117+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:42.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.415 seconds
[2025-12-13T11:46:42.217+0000] {processor.py:186} INFO - Started process (PID=2553) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:42.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:42.219+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:42.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:43.313+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:43.322+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:43.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:43.340+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:43.340+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:43.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.153 seconds
[2025-12-13T11:46:43.413+0000] {processor.py:186} INFO - Started process (PID=2566) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:43.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:43.415+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:43.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:44.902+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:44.921+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:44.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:44.964+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:44.964+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:45.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.605 seconds
[2025-12-13T11:46:45.134+0000] {processor.py:186} INFO - Started process (PID=2579) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:45.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:45.146+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:45.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:46.700+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:46.710+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:46.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:46.729+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:46.729+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:46.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.623 seconds
[2025-12-13T11:46:46.890+0000] {processor.py:186} INFO - Started process (PID=2592) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:46.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:46.893+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:46.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:48.018+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:48.027+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:48.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:48.046+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:48.046+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:48.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.177 seconds
[2025-12-13T11:46:48.113+0000] {processor.py:186} INFO - Started process (PID=2605) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:48.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:48.116+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:48.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:49.243+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:49.253+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:49.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:49.274+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:49.273+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:49.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.182 seconds
[2025-12-13T11:46:49.341+0000] {processor.py:186} INFO - Started process (PID=2618) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:49.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:49.344+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:49.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:50.391+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:50.400+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:50.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:50.419+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:50.418+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:50.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.106 seconds
[2025-12-13T11:46:50.501+0000] {processor.py:186} INFO - Started process (PID=2631) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:50.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:50.503+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:50.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:51.622+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:51.632+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:51.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:51.651+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:51.651+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:51.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.188 seconds
[2025-12-13T11:46:51.727+0000] {processor.py:186} INFO - Started process (PID=2644) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:51.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:51.729+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:51.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:52.785+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:52.794+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:52.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:52.814+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:52.813+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:52.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.107 seconds
[2025-12-13T11:46:52.892+0000] {processor.py:186} INFO - Started process (PID=2657) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:52.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:52.895+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:52.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:53.973+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:53.982+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:53.982+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:54.001+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:54.000+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:54.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.132 seconds
[2025-12-13T11:46:54.072+0000] {processor.py:186} INFO - Started process (PID=2670) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:54.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:54.074+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:54.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:55.119+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:55.127+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:55.127+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:55.145+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:55.145+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:55.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.095 seconds
[2025-12-13T11:46:55.213+0000] {processor.py:186} INFO - Started process (PID=2683) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:55.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:55.216+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:55.215+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:56.220+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:56.228+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:56.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:56.246+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:56.246+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:56.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.055 seconds
[2025-12-13T11:46:56.317+0000] {processor.py:186} INFO - Started process (PID=2696) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:56.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:56.319+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:56.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:29.543+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:29.566+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:29.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:29.584+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:29.584+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:57.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.085 seconds
[2025-12-13T11:46:57.450+0000] {processor.py:186} INFO - Started process (PID=2709) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:57.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:57.452+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:57.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:58.488+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:58.497+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:58.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:58.516+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:58.516+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:58.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.096 seconds
[2025-12-13T11:46:58.594+0000] {processor.py:186} INFO - Started process (PID=2722) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:58.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:58.597+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:58.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:59.783+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:46:59.795+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:59.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:46:59.815+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:59.815+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:46:59.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.244 seconds
[2025-12-13T11:46:59.884+0000] {processor.py:186} INFO - Started process (PID=2735) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:46:59.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:46:59.886+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:46:59.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:01.485+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:01.503+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:01.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:01.532+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:01.531+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:01.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.681 seconds
[2025-12-13T11:47:01.630+0000] {processor.py:186} INFO - Started process (PID=2748) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:01.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:01.633+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:01.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:03.591+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:03.602+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:03.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:03.627+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:03.626+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:03.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.024 seconds
[2025-12-13T11:47:03.702+0000] {processor.py:186} INFO - Started process (PID=2761) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:03.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:03.705+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:03.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:04.879+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:04.890+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:04.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:04.911+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:04.911+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:04.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.232 seconds
[2025-12-13T11:47:04.981+0000] {processor.py:186} INFO - Started process (PID=2774) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:04.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:04.984+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:04.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:06.136+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:06.145+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:06.145+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:06.164+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:06.164+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:06.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.206 seconds
[2025-12-13T11:47:06.234+0000] {processor.py:186} INFO - Started process (PID=2787) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:06.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:06.237+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:06.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:39.552+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:39.575+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:39.575+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:39.592+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:39.592+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:39.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.179 seconds
[2025-12-13T11:47:51.304+0000] {processor.py:186} INFO - Started process (PID=2812) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:51.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:51.308+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:51.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:52.545+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:52.568+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:52.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:52.588+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:52.587+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:52.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.323 seconds
[2025-12-13T11:47:52.662+0000] {processor.py:186} INFO - Started process (PID=2825) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:52.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:52.664+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:52.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:53.758+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:53.855+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:53.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:53.872+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:53.872+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:53.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.234 seconds
[2025-12-13T11:47:53.942+0000] {processor.py:186} INFO - Started process (PID=2838) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:53.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:53.944+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:53.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:55.071+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:55.081+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:55.081+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:55.102+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:55.102+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:55.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.192 seconds
[2025-12-13T11:47:55.183+0000] {processor.py:186} INFO - Started process (PID=2851) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:55.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:55.185+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:55.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:56.215+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:56.224+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:56.224+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:56.244+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:56.243+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:56.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.084 seconds
[2025-12-13T11:47:56.318+0000] {processor.py:186} INFO - Started process (PID=2864) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:56.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:56.320+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:56.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:57.355+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:57.364+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:57.364+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:57.382+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:57.382+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:57.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.086 seconds
[2025-12-13T11:49:29.651+0000] {processor.py:186} INFO - Started process (PID=2877) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:49:29.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:49:29.654+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:49:29.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:58.559+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:58.568+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:58.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:58.587+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:58.587+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:58.610+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.179 seconds
[2025-12-13T11:47:58.664+0000] {processor.py:186} INFO - Started process (PID=2890) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:58.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:58.666+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:58.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:59.756+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:47:59.768+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:59.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:47:59.798+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:59.798+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:47:59.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.160 seconds
[2025-12-13T11:47:59.876+0000] {processor.py:186} INFO - Started process (PID=2903) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:47:59.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:47:59.879+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:47:59.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:01.787+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:01.799+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:01.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:01.821+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:01.821+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:01.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.973 seconds
[2025-12-13T11:48:01.922+0000] {processor.py:186} INFO - Started process (PID=2916) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:01.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:01.926+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:01.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:03.688+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:03.699+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:03.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:03.723+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:03.723+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:03.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.825 seconds
[2025-12-13T11:48:03.817+0000] {processor.py:186} INFO - Started process (PID=2929) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:03.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:03.820+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:03.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:05.341+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:05.355+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:05.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:05.386+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:05.386+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:05.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.615 seconds
[2025-12-13T11:48:05.517+0000] {processor.py:186} INFO - Started process (PID=2942) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:05.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:05.520+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:05.519+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:07.303+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:07.313+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:07.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:07.335+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:07.334+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:07.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.846 seconds
[2025-12-13T11:48:07.418+0000] {processor.py:186} INFO - Started process (PID=2955) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:07.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:07.423+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:07.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:10.078+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:10.094+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:10.094+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:10.125+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:10.124+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:10.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.747 seconds
[2025-12-13T11:48:10.219+0000] {processor.py:186} INFO - Started process (PID=2968) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:10.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:10.222+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:10.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:11.356+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:11.365+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:11.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:11.386+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:11.386+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:11.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.191 seconds
[2025-12-13T11:48:11.461+0000] {processor.py:186} INFO - Started process (PID=2981) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:11.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:11.464+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:11.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:49:44.764+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:12.591+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:12.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:12.610+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:12.610+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:12.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.161 seconds
[2025-12-13T11:48:12.678+0000] {processor.py:186} INFO - Started process (PID=3000) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:12.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:12.680+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:12.680+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:13.714+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:13.723+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:13.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:13.741+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:13.741+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:13.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.086 seconds
[2025-12-13T11:48:13.811+0000] {processor.py:186} INFO - Started process (PID=3013) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:13.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:13.813+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:13.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:14.850+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:14.859+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:14.859+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:14.877+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:14.877+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:14.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.090 seconds
[2025-12-13T11:48:14.947+0000] {processor.py:186} INFO - Started process (PID=3026) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:14.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:14.949+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:14.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:16.029+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:16.039+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:16.039+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:16.058+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:16.058+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:16.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.137 seconds
[2025-12-13T11:48:16.134+0000] {processor.py:186} INFO - Started process (PID=3039) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:16.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:16.137+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:16.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:17.159+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:17.168+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:17.168+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:17.187+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:17.187+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:17.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.080 seconds
[2025-12-13T11:48:17.263+0000] {processor.py:186} INFO - Started process (PID=3052) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:17.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:17.266+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:17.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:18.350+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:18.360+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:18.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:18.383+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:18.383+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:18.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.166 seconds
[2025-12-13T11:48:18.480+0000] {processor.py:186} INFO - Started process (PID=3065) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:18.482+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:18.483+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:18.483+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:20.450+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:20.460+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:20.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:20.481+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:20.481+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:20.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 2.030 seconds
[2025-12-13T11:48:20.557+0000] {processor.py:186} INFO - Started process (PID=3078) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:20.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:20.560+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:20.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:21.693+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:21.703+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:21.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:21.727+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:21.727+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:21.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.188 seconds
[2025-12-13T11:48:21.805+0000] {processor.py:186} INFO - Started process (PID=3091) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:21.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:21.808+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:21.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:22.945+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:22.955+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:22.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:22.979+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:22.979+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:22.999+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.202 seconds
[2025-12-13T11:48:23.067+0000] {processor.py:186} INFO - Started process (PID=3104) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:23.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:23.070+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:23.069+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:24.160+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:24.180+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:24.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:24.201+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:24.201+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:24.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.166 seconds
[2025-12-13T11:48:24.278+0000] {processor.py:186} INFO - Started process (PID=3117) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:24.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:24.280+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:24.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:25.421+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:25.443+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:25.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:25.462+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:25.461+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:25.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.206 seconds
[2025-12-13T11:48:25.531+0000] {processor.py:186} INFO - Started process (PID=3130) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:25.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:25.533+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:25.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:26.688+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:26.710+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:26.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:26.730+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:26.730+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:26.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.221 seconds
[2025-12-13T11:48:26.803+0000] {processor.py:186} INFO - Started process (PID=3143) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:26.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:26.805+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:26.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:46.765+0000] {processor.py:186} INFO - Started process (PID=3162) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:46.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:46.768+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:46.768+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:47.832+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:47.854+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:47.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:47.877+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:47.877+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:47.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.165 seconds
[2025-12-13T11:48:47.962+0000] {processor.py:186} INFO - Started process (PID=3175) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:47.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:47.966+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:47.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:49.210+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:49.233+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:49.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:49.257+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:49.257+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:49.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.320 seconds
[2025-12-13T11:48:49.332+0000] {processor.py:186} INFO - Started process (PID=3188) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:49.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:49.335+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:49.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:50.417+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:50.438+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:50.438+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:50.459+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:50.459+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:50.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.156 seconds
[2025-12-13T11:48:50.535+0000] {processor.py:186} INFO - Started process (PID=3201) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:50.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:50.538+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:50.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:51.647+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:48:51.672+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:51.672+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:48:51.698+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:51.697+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:48:51.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.188 seconds
[2025-12-13T11:48:51.782+0000] {processor.py:186} INFO - Started process (PID=3214) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:48:51.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:48:51.789+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:48:51.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:50:54.919+0000] {processor.py:186} INFO - Started process (PID=3251) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:50:54.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:50:54.921+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:50:54.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
[2025-12-13T11:50:56.356+0000] {processor.py:925} INFO - DAG(s) 'stock_portfolio_pipeline_datafrogs' retrieved from /opt/airflow/dags/airflow.py
[2025-12-13T11:50:56.381+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:50:56.381+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-12-13T11:50:56.406+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:50:56.406+0000] {dag.py:4180} INFO - Setting next_dagrun for stock_portfolio_pipeline_datafrogs to 2025-12-13 00:00:00+00:00, run_after=2025-12-14 00:00:00+00:00
[2025-12-13T11:50:56.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/airflow.py took 1.522 seconds
[2025-12-13T11:51:26.760+0000] {processor.py:186} INFO - Started process (PID=3270) to work on /opt/airflow/dags/airflow.py
[2025-12-13T11:51:26.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/airflow.py for tasks to queue
[2025-12-13T11:51:26.763+0000] {logging_mixin.py:190} INFO - [2025-12-13T11:51:26.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/airflow.py
